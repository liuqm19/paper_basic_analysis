RESEARCH ARTICLE A POTATO SALAD WITH A LEMON TWIST:  USING A SUPPLY- SIDE SHOCK TO STUDY THE IMPACT OF OPPORTUNISTIC BEHAVIOR ON CROWDFUNDING PLATFORMS1 Hilah Geva, Ohad Barzilay, and Gal Oestreicher-Singer Coller School of Management, Tel-Aviv University, Ramat Aviv, Tel Aviv 69978 ISRAEL {hilahlev@mail.tau.ac.il}  {ohadbr@tau.ac.il}  {galos@post.tau.au.il} Crowdfunding platforms are peer-to-peer two-sided markets that enable amateur entrepreneurs to raise money online  for  their  ventures.    However,  in  allowing  practically  anyone  to  enter,  such  platforms  enable opportunistic suppliers to flood the market with offerings, many of which are of low quality.  This situation creates  choice  overload  for  potential  backers  and  may  thus  influence  their  investment  decisions.    To empirically study the implications of this phenomenon for crowdfunding performance, we use a quasi-natural experiment in the form of an exogenous media shock that occurred on Kickstarter.com.  The shock was followed by a sharp increase in the number of campaigns, particularly low-quality ones, offered on the supply side of the market; no such increase was observed on the demand side of the market.  These unique conditions enable us to estimate how crowdfunding platforms are affected by the presence of an atypically large number of low-quality campaigns, while controlling for fluctuations in demand.  We use two identification strategies, which enable us to control for changes in quality, to show that an increase in low-quality supply significantly decreases the performance of the average crowdfunding campaign, manifested in a lower likelihood of success (reaching funding goals) and less money raised per campaign.  We also offer a new measure to estimate campaign quality and study the moderating role of campaign quality in the observed effects.  We find that high- quality campaigns are less affected than low-quality campaigns by the influx of low-quality offerings.  We discuss theoretical implications as well as managerial implications for entrepreneurs and platform designers.  Keywords:   Crowdfunding, peer-to-peer platforms, peer economy, share economy, supply-side shocks, quasi- natural experiment, exogenous shock, choice overload, market of lemons Introduction 1 Crowdfunding platforms enable entrepreneurs to raise money online for their products or services (Agrawal et al. 2015; Belleflamme  et  al.  2014).    Such  platforms  serve  as  inter- mediaries in a two-sided market, bringing together entrepre- neurs on one side (the supply side) and potential investors, called backers, on the other side (the demand side; Mollick 1Bin Gu was the accepting senior editor for this paper.  Abhay Mishra served as the associate editor. The  appendices  for  this  paper  are  located  in  the  “Online  Supplements” section of MIS Quarterly’s website (https://misq.org). 2014).  The type of two-sided markets facilitated by crowd- funding platforms is referred to as the peer economy, or the share  economy (Fournier et al. 2013;  Sundararajan 2013).  Such markets are characterized as having amateurs on both sides (Howe 2008) and blurred dichotomy between the parties (Zvilichovsky et al. 2013). Crowdfunding  platforms  are  particularly  useful  for  novice entrepreneurs, providing off-the-shelf technology and frame- works that can streamline their first steps toward launching their  ventures  (Agrawal  et  al.  2015)  and,  in  some  cases, enable them to raise as much funding as more experienced entrepreneurs.  Indeed, accessibility to novices is not inci- dental but rather is inherent to the ideology underlying the DOI:  10.25300/MISQ/2019/14572 MIS Quarterly Vol. 43 No. 4, pp. 1227-1248/December 2019 1227 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms peer economy, which strives to encourage all members of the community to participate.  This principle of democratization manifests in the relatively open acceptance policies adopted by numerous crowdfunding platforms, which are implemented through various platform design choices.  For example, in order  to  launch  a  crowdfunding  campaign  on  the  popular platform Indiegogo.com, the entrepreneur is only required to fill out an online form; the campaign is then launched imme- diately without being subjected to any review process by the platform.  Kickstarter.com, the Internet’s largest and most popular  crowdfunding  platform,  has  been  implementing  a similar open access approach since June 2014, by relying on a  machine-learning  algorithm  that  automatically  approves campaigns that meet its basic quality criteria.  These stream- lined approval processes make it straightforward to launch new campaigns, and they support entrepreneurs’ agility and market responsiveness. Although  a  democratic  platform  creates  the  romantic  pos- sibility that a “diamond in the rough” might emerge (Agrawal et al 2014; Gleasure and Feller 2016), accessibility may come with a cost:  It effectively eliminates barriers to opportunistic behavior, wherein suppliers enter the market with the sole purpose  of  seizing  on  an  opportunity  to  profit,  with  little consideration for the value that they contribute to the com- munity.  Indeed, recent findings suggest that such behavior occurs in crowdfunding environments (Hildebrand et al. 2016; Kim et al 2017).  Opportunistic behavior, in turn, can expose a crowdfunding platform to the risk of being flooded with low-quality offerings. Herein, we explore how opportunistic behavior on the supply side of a crowdfunding platform—which is indeed shown to result in a flood of low-quality campaigns—influences the performance of campaigns on the platform.  We suggest that, in general, when faced with a large number of campaigns, investors may experience choice overload, in which excessive availability of options affects the decision-making process.  Choice overload has been shown to influence purchase deci- sions and, specifically, to diminish individuals’ likelihood of making any purchase at all (Schwartz 2004).  Accordingly, an influx of offerings may lead to a decrease in campaign perfor- mance across the platform.  This effect may be exacerbated when a large percentage of these offerings are of low quality.  Indeed, Akerlof (1970) showed that when a market is inun- dated  with  low-quality  offerings,  or  “lemons,”  and  when buyers cannot immediately tell the difference between high- quality  and  low-quality  offerings,  sellers  of  high-quality products  will  suffer,  as  they  are  unable  to  sell  their  high- quality products at an appropriate price.  However, this effect can  be mitigated, and market failure averted, when sellers have some means of signaling the quality of their products, thereby reducing information asymmetry (Brealey et al. 1977; 1228 MIS Quarterly Vol. 43 No. 4/December 2019 Spence 1973).  In light of the fact that crowd-based platforms provide quality signaling mechanisms (for example, as studied by Fort et al. (2011) and Ipeirotis and Paritosh (2011)), we propose that the use of such mechanisms may mitigate the detrimental effects of backers’ exposure to an overabundance of low-quality offerings, by enabling backers to differentiate between campaigns and to focus their attention on the smaller, more cognitively manageable subset of campaigns of higher quality.   To investigate these ideas, we use data from Kickstarter.com.  Specifically, we exploit a natural experiment in which a large number of opportunistic sellers entered the market after an unusual campaign on Kickstarter—which sought to raise $10 for making a potato salad—attracted a great deal of media attention and raised more than U.S. $50,000.  As we show in what follows, the new campaigns that were launched in the wake of this supply-side shock were generally of low quality (as compared  with the typical campaign during the period preceding the shock).   In our investigation we combine two sources of data.  The first is a comprehensive set of archival data from Kickstarter surrounding the period of the shock.  The second dataset is based on a large-scale survey by which we manually evaluated numerous features of each campaign in our dataset (including prospective  investors’  perceptions  of  the  entrepreneur’s competence and investment of resources such as time, money, and effort).  We use these features to develop new measures of quality that go beyond well-known quality signals that are embedded in the platform's structural characteristics (Burtch et  al.  2013;  Mollick  2014).    This  approach  enables  us  to provide a more comprehensive representation of the factors that individuals actually take into account when evaluating campaigns. We use two novel identification methods that enable us to control  for  quality  fluctuations.    The  first  identification method focuses on campaigns that started before the shock and utilizes variation in campaigns’ launch dates.  The second is an identification strategy based on matching campaigns that launched before the shock with campaigns that launched after the shock. We find that the atypically high number of low-quality cam- paigns entering the market had a significant negative effect on the average likelihood of a campaign to succeed, as well as on the average amount of money pledged per campaign.  Further- more,  the  influx  of  low-quality  campaigns  had  different effects on campaigns of different quality levels:  Specifically, lower-quality campaigns were particularly susceptible to the negative  effect,  with  respect  to  the  two  measurements  of performance considered. Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms From  a  theoretical  perspective,  this  research  adds  to  the growing body of work on the effects of supply-side factors on various crowdfunding outcomes.  As of today, relatively few works  have  focused  on  the  supply  side  of  crowdfunding platforms;  several  notable  exceptions  include  the  work  of Burtch et al. (2018), focusing on the shift in supply between crowdfunding and the gig economy; and works focusing on biases that influence sellers’ performance, such as gender bias (Marom et al. 2016) and racial bias (Rhue 2015; Younkin and Kuppuswamy 2017).  In particular, although previous studies have investigated demand-side shocks in two-sided markets (Liu et al. 2015; Shankar and Bayus 2003; Zhang and Liu 2012),  none,  to  our  knowledge,  has  examined  supply-side shocks.  The dearth of research in this vein is notable in light of  the  unique  dynamics  characterizing  the  supply  side  of crowdfunding platforms:  A large proportion of crowdfunding suppliers are individuals and amateur sellers, who are more likely  to  act  impulsively  and to  show  herding  behavior  as compared with suppliers in firm-based two-sided markets (see the following section for a more extensive discussion of such dynamics).    As  the  crowdfunding  industry  is  becoming increasingly inclusive to laypersons and to amateur suppliers, it is crucial for platform owners and market participants to better understand the supply-side phenomena that occur in these markets. Our work further links theories of choice overload and quality signaling and provides  empirical evidence of the interplay between the two constructs, with clear managerial implica- tions.  Specifically, our findings suggest that choice overload might cause campaign performance to suffer in the wake of a large influx of low-quality campaigns, and that the availability of quality signaling mechanisms can mitigate some of this damage by enabling potential investors to distinguish higher- quality campaigns from lower-quality campaigns.  Still, our results suggest that, when the market is currently flooded with low-quality campaigns, the average entrepreneur who wishes to  launch  a  crowdfunding  campaign  would  benefit  from waiting for the tide to turn. Literature Review and Hypothesis Building Context:  How Openness Facilitates Opportunism years, it seems that the peer economy, and specifically the crowdfunding  industry,  is  moving  toward  more  open  and democratic policies, with Indiegogo and Kickstarter’s (cur- rent)  acceptance  policies  being  notable  examples  in  the domain  of  crowdfunding.    In  effect,  a  platform’s  level  of openness—that is, the extent to which the platform refrains from enforcing control and allows all prospective entrepre- neurs to participate—is a design choice.  It is well established that design choices affect the dynamics and performance of digital platforms (Overby et al. 2010; Tiwana et al. 2010).  Crowdfunding platforms’ governance decisions such as the funding  models  (Burtch  et  al.  2017)  and  the  information disclosure policies (Burtch et al. 2015, 2016; Kim et al. 2019 influence various outcomes on these platforms, including the number  of  campaigns  launched  and  the  success  of  those campaigns.   In  our  context,  the design  feature  of a  platform’s  level  of openness is inherently expected to affect the mix of offers and their performance on the platform.  In particular, the presence of a relaxed acceptance policy can easily lead to the introduc- tion  of  opportunistic  sellers  with  low-quality  offerings.  Recent  studies  have  provided  evidence  that  opportunistic behavior  indeed  takes  place  on  crowdfunding  platforms (Burtch et al. 2018; Hildebrand et al 2016; Kim et al 2017).  Hypothetically,  if  these  platforms  were  to  impose  stricter entry barriers for suppliers, much of this behavior would be eliminated.    Furthermore,  we  suggest  that  crowdfunding settings promote both the existence of low-quality offerings and rapid fluctuations in their number.  These fluctuations result  from  the  fact  that  many  suppliers  on  crowdfunding platforms are individuals (rather than firms), and are therefore susceptible to herding behaviors and may react instantly to new business opportunities. On the basis of this reasoning, we suggest that sharp increases in the supply in digital markets, and  specifically sharp in- creases in the availability of low-quality offerings, constitute a  novel  phenomenon,  facilitated  by  the  particular  charac- teristics of contemporary peer economy platforms.  This work provides the first in-depth analysis of the implications of this phenomenon for the performance of the market.   Hypothesis Building  Competition and Choice Overload Before developing our hypotheses, it is important to charac- terize  the unique environment  that enables the phenomena they describe to occur:  the context of an open two-sided mar- ket, which virtually anyone can enter (i.e., launch a campaign) in  a  quick  and  straightforward  manner.    Indeed,  in  recent Our first hypothesis aims to establish how supply-side shocks involving a large influx of low-quality offerings affect the per- formance of crowdfunding campaigns.  In general, a large increase  in  the  number  of  offerings  creates  a  market  with intense competition, which, as noted in the introduction, can MIS Quarterly Vol. 43 No. 4/December 2019 1229 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms prompt choice overload (also referred to in the literature as over-choice effect, the tyranny of choice, and the too-much- choice  effect).    Choice  overload  is  a  situation  in  which individuals faced with an overabundance of options to choose from experience adverse consequences (for an overview of the literature,  see  Scheibehenne  et al.  2010).    To  quote  Barry Schwartz’s  The  Paradox  of  Choice:    “As  the  number  of choices grows further, the negatives escalate until we become overloaded.    At  this  point,  choice  no  longer  liberates,  but debilitates” (2004, p. 2).  This effect occurs when “there is no obviously  dominant  option  in  the  choice  set  and  if  the proportion of nondominated options is large” (Scheibehenne et al. 2010).  This description is likely to be applicable to the market we consider, in which a large number of the offerings available are of low quality, yet still continue to compete for the attention of potential backers (Davenport and Beck 2001; Dellarocas et al. 2013).   Choice  overload  effects  on  individuals’  decision-making processes  have  been  studied  extensively  in  the  fields  of marketing and psychology (e.g., Iyengar and Lepper 2000; Scheibehenne et al. 2010; Schwartz 2004).  Studies in this vein have shown that choice overload may lead to confusion and anxiety (Lipowski 1970), and may decrease individuals’ motivation to make any choice at all, preventing consumers from making a purchase (Iyengar et al. 2004; Iyengar and Lepper 2000).  Applied to our context, these observations suggest that, when faced with an influx of low-quality cam- paigns, a prospective backer may experience choice overload and become less likely to invest in a given campaign that she would  have  invested  in  prior  to  the  shock.    Formally,  we hypothesize: H1: In  open  crowdfunding  platforms,  a substantial increase in the number of low- quality  campaigns,  will,  on  average, reduce a given campaign’s performance, as  reflected  the  campaign’s likelihood to succeed (achieve its funding goal),  and  (2)  the  amount  of  money pledged to the campaign. (1)  in  Quality Signaling in Crowdfunding Platforms Our  second  hypothesis  aims  to  establish  how  campaign quality moderates the effect of choice overload on campaign performance.    To  develop  this  hypothesis,  we  turn  to  the literature on signaling.  As noted above, Akerlof (1970) used the metaphor of a market of lemons to describe how a market characterized by low-quality offerings and information asym- metry may hurt high-quality sellers, ultimately causing them to leave a marketplace.  Inspired by the market of used cars, 1230 MIS Quarterly Vol. 43 No. 4/December 2019 in  which  only  sellers  know  the  true  quality  of  their  cars, Akerlof described a scenario in which some (dishonest) sellers are tempted to sell low-quality cars (lemons) at the price of a good car (known as moral hazard and adverse selection).  In such a market, sellers of high-quality products will suffer as well, as they are unable to sell their high-quality cars at an appropriate price.  In order to disarm the threat of the “market of  lemons,”  and  to  gain  a  competitive  edge,  high-quality agents  must  seek  out  means  of  signaling  their  quality  to potential buyers (Spence 1973; for a more recent review of the literature, see Kirmani and Rao 2000).  Theoretical works have  argued  that  implementation  of  appropriate  signaling mechanisms may reduce information asymmetry and mitigate the risks associated with a “lemonized” market (Ibrahim 2015; Tomboc 2013). On the basis of this literature, we infer that signaling can lead to differentiation.  Notably, differentiation is known to be a key element in mitigating the effect of choice overload on buyers (Scheibehenne et al. 2010).  Therefore, we propose that  if a  platform facilitates  strong  quality  signaling,  cam- paigns  taking  advantage  of  these  features  can  stand  out, thereby enabling backers to reduce their choice sets and to focus their investment decisions on higher-quality campaigns.  In other words, a campaign’s reliance on quality signaling has the  potential  to  alleviate  the  detrimental  effects  of  choice overload on campaign performance. Indeed, crowdfunding platforms incorporate signaling mech- anisms as part of their design.  Thus far, research on crowd- funding  platforms  has  identified  three  main  categories  of signals that  can express the quality of a campaign or of a campaign’s owner.  These quality signals have been shown to be associated with campaign performance:  (1) Campaign-related information (Mollick 2014):  This category  of  signals  includes  features  such  as  (a)  the inclusion of a video in the campaign page, which serves as a proxy for the level of time, effort, and resources that the entrepreneur has invested in preparing her campaign (Mollick 2014;  Zvilichovsky et  al.  2013),  and  (b)  the number of words in the campaign description, which is also widely used as a proxy for the entrepreneur’s level of investment in a campaign and, consequently, the cam- paign’s quality (Gafni et al. 2017; Greenberg et al. 2013).  These features have been shown to predict the success of reward-based crowdfunding campaigns (see Burtch et al. 2013;  Mollick 2014). (2) Entrepreneur-related  information:    This  category includes features such as (a) the number of campaigns previously backed by the entrepreneur and (b) the num- ber of campaigns the owner created that were funded.  Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms These  characteristics  have  been  positively  linked  to  a campaign’s  likelihood  to  succeed  (Zvilichovsky  et  al. 2013).    The  relationship  between  these  features  and campaign performance is also in line with previous litera- ture on entrepreneurial financing, which has shown that an  entrepreneur’s  reputation  and  social  capital,  both offline and online, serve as signals to other market parti- cipants  (Krumme  and  Herrero  2009;  Lin  et  al.  2013; Packalen 2007). low-quality campaigns on the performance of  a  given  campaign—as  reflected  in (1)  likelihood  to  succeed  (achieve  the funding goal) and (2) the amount of money pledged to the campaign—is moderated by the  campaign’s  quality,  such  that  low- quality campaigns are affected more than high-quality campaigns. (3) Campaign dynamics:  This category includes the fol- lowing features: (a) Fundraising progression:  Previous work in the con- text of microloans has shown that the progression of a campaign’s funding influences subsequent backing decisions, due to herding and observational learning.  Specifically, well-funded listings tend to accumulate more funding, and lenders take into consideration peer  lending  decisions  while  using  observable borrower characteristics to moderate their inferences (Zhang and Liu 2012). (b) Contribution frequency by others:  In the context of a  public  good  crowdfunding  marketplace,  studies have shown that contributors are less likely to con- tribute when they feel the contribution is less impor- tant  to  the  recipient  (i.e.,  when  the  frequency  of backing is high; Burtch et al. 2013).  (c) eWOM:    In  the  context  of  reward-based  crowd- funding, it has been shown that social media buzz (in the form of posts on Twitter and Facebook) has a positive  impact  on  subsequent  campaign  support.  That is, prospective backers look to social media to find quality cues (Thies et al. 2014). (d) Experience of previous backers:  In the context of a crowdfunding platform for mobile  applications, it has been shown that early investors who have plat- form  experience  (specifically,  investors  with  app development  experience  or  investors  with  app investment experience) influence other investors in the crowd (Kim and Viswanathan 2019). Drawing from the idea that differentiation can mitigate the detrimental  effects  of  choice  overload,  coupled  with  the observation that backers indeed make use of quality signals, we suggest that campaigns that signal themselves as being of high quality are less likely than lower-quality campaigns to be negatively influenced (in terms of performance) by a sharp increase in the number of low-quality offerings available on the platform.  Formally, we hypothesize: H2: In open crowdfunding platforms, the effect of a substantial increase in the number of Empirical Context Kickstarter.com Since  Kickstarter’s  founding  in  2009,  more  than  290,000 campaigns  have  been  launched  on  the  platform,  raising pledges from over 10 million users.  In 2016, a total of 57,440 Kickstarter campaigns were launched, raising approximately U.S. $650 million.  Kickstarter follows the “all or nothing” funding model, in which a minimum campaign financing goal is set, and a limited time period is given for achieving the goal.  The owner of the campaign receives the funds pledged to his campaign only if the campaign is “successful” (i.e., reaches or exceeds the targeted amount within the specified time period; Burch et al. 2016).  Kickstarter’s financial model is  based  on  charging  campaign  owners  a  5%  fee  from  all funds successfully raised on the platform.2  Kickstarter is a reward-based platform;3 its rules specify that each campaign must  create  something  to  share  with  others  in  one  of  15 categories:  art, comics, crafts, dance, design, fashion, film and  video,  food,  games,  journalism,  music,  photography, publishing, technology, or theater.4  Campaign success rates range from 21% for technology campaigns to 65% for dance campaigns, with an average success rate of 36% across all categories. 2https://www.kickstarter.com/help/fees?country=US 3There  are  several  types  of  crowdfunding  platforms:    (1)  reward-based crowdfunding, such as Kickstarter, where backers contribute a relatively small amount of money in exchange for a reward, (2) donation-based crowd- funding, such as GoFundMe or Crowdrise, where backers contribute small amounts of money without expecting a return beyond the gratitude of the campaign’s  creator,  (3)  equity  crowdfunding,  such  as  AngelList  and Crowdfunder, where investors give rather large amounts of money in return for a small piece of equity in the company itself, and (4) debt crowdfunding, such as LendingClub, where a crowd of lenders make a loan with the expec- tation to make back their principal plus interest. 4https://www.kickstarter.com/rules MIS Quarterly Vol. 43 No. 4/December 2019 1231 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms Potato Salad Shock  On July 3, 2014, Zack “Danger” Brown, a first-time entrepre- neur  from  Columbus,  Ohio,  started  a  Kickstarter  crowd- funding  campaign  asking  for  $10  for  a  campaign  titled “Potato Salad,” the stated purpose of which was:  “Basically I’m just making potato salad.  I haven’t decided what kind yet.”    Surprisingly,  this  unusual  campaign  raised  $55,492 from 6,911 backers, and attracted the interest of mainstream televised  media  outlets such as  “Good  Morning  America” (July 8, 2014).  This media attention was followed by a spike in the number of visitors to the campaign’s page, and in the number of searches for the keyword “Kickstarter” on Google (see Figures 1 and 2, respectively).  The media coverage also created a spike in the number of new campaigns opened for funding on Kickstarter (see Figure 3).  For example, on July 2,  2014,  a  total  of  151  new  campaigns  were  launched  on Kickstarter, whereas on July 9, a total of 927 new campaigns were initiated.  As would be expected, during the weeks fol- lowing  the  launches  of  these  campaigns,  a  corresponding increase  was  observed  in  the  number  of  live  campaigns available on the platform (see Figure 4).  Kickstarter con- firmed  in  a  correspondence  that  the  sudden  spike  in  new campaigns was attributable exclusively to the buzz created by the potato salad campaign.  This interpretation indeed seems plausible, given that prospective entrepreneurs were not likely to  have  been  aware  of  the  spike  per  se,  and  thus  to  be influenced  by  it:    at  the  time,  Kickstarter  did  not  publicly emphasize the massive influx in the number of campaigns, such that in order for an individual to observe this spike, he or she would have had to systematically monitor the site on a daily basis with this aspect in mind. We consider this media-exposure-driven spike in the number of  campaigns  to be  a  supply-side shock  to  the  Kickstarter platform.  Given that the media coverage of the potato salad campaign was the source of the shock, we define the start day of  the  shock  as  July  8  (the  day  of  the  “Good  Morning America” appearance) and not July 3 (the launch day of the potato salad campaign).  Indeed, Figure 3 suggests that July 8 marks the beginning of the sharp increase in the number of campaigns launched on Kickstarter. Data and Preliminary Observational Analysis Data Collection Archival Kickstarter Data For  this  work,  we  needed  data  about  campaigns  launched before and after the media shock.  Collecting such data is 1232 MIS Quarterly Vol. 43 No. 4/December 2019 challenging because Kickstarter does not provide an API, nor does it provide access to a directory of past campaigns and users.    Furthermore,  its  web  interface  does  not  allow  for exhaustive searches.  However, we have been systematically capturing and archiving Kickstarter dynamics, using a desig- nated  web  crawler,  which  runs  in  parallel  on  multiple machines.  Every 10.2 hours on average, this crawler records a  snapshot comprising all the data associated with all live campaigns.  The crawler was initiated on September 12, 2013, and has been running constantly since.  Hence, it collected data both before and after the shock, providing us with the unique opportunity to study this media shock.   For the purpose of this study, we use data collected about campaigns that were launched between June 3, 2014 and July 14, 2014 (i.e., in proximity to the high-profile media coverage described above).  This dataset contains 9,588 campaigns.5  The following campaign attributes were collected for each campaign and were used in our analyses. • • Campaign data:  Each campaign’s description, finan- cing goal, financing duration, use of a video (yes/no), amount of money pledged to the campaign, whether the campaign was successful, the amount collected on each day, and the category to which the campaign belongs. Campaign owner’s data:  Number of days from when the  campaign  owner  joined  Kickstarter  until  the  cam- paign creation day; a list of campaigns the campaign’s owner  previously  created  or  backed,  from  which  we derive two variables indicating (1) the number of cam- paigns  the  campaign  owner  previously  backed,  and (1)  the  number  of  successful  campaigns  he  or  she previously owned. Detailed  descriptions  and  descriptive  statistics  for  our variables are presented in Table 1.  Survey Data Using Amazon Mechanical Turk To complement the data extracted by the crawler, and to bet- ter capture the subtle signals of quality provided in the cam- paign page, we developed a questionnaire regarding respon- dents’ perceptions of campaign features that we considered to be indicative of campaign quality, and that were not covered in our Kickstarter data.  (For a full description of the devel- opment  of  the  questionnaire,  see  the  “Quality  Measures” section and Appendix A.)  We then surveyed individuals 5We remove blockbuster projects, defined as projects that raised over U.S. $100,000 (roughly of campaigns).  Campaigns included in this count are campaigns from week 5 that ended prior to the shock, campaigns from weeks 1–4, and all campaigns that launched in shock week. Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms Figure 1.  Unique Visitors to the Potato Salad Campaign’s Page in the One-Month Period Beginning on July 4, 2014 Figure 2.  Search Trends (as Taken from the Google Trends Website) for the Search Term “Kickstarter” for June and July 2014 Figure 3.  Number of Campaigns Launched on Kickstarter by Date MIS Quarterly Vol. 43 No. 4/December 2019 1233 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms (a)  Number of Live Campaigns (blue; upper line) and Number of Launched Campaigns (green; lower line) by Day (b)  Normalized Number of Live Campaigns (blue; lower line at start) and Normalized Number of Launched Campaigns (green; upper line at start) by Day Note:  We used feature scaling to normalize the data.  That is, we brought all values to the range of [0, 1] using the following formula:   of launched campaigns. Figure 4.  for the Simple Model (Uncorrelated LVs)   This is done separately for the two data sets, number of live campaigns, and number Table 1.  Descriptive Statistics for the Variables in the Kickstarter Dataset NumBacked NumSucceeded HasVideo NumWordsIn Description lnNumWords Duration DayJoinFromStartDate OwnerTenure Goal lnGoal RatioGoalFirstDay IsSuccessful AmountPledged lnAmountPledged Description Mean Median Min Number of campaigns previously backed by the campaign’s owner Number of successful campaigns previously created by the campaign’s owner Whether the campaign has a video (1 = yes, 0 = no) 2.03 0.11 0.54 0.00 0.00 1.00 0.00 0.00 0.00 Max 221.00 24.00 1.00 Number of words in the campaign description  1048.23 798.0 143.0 13294.0 Ln (Number of words in the campaign description) Duration of the campaign (days) Number of days from when the campaign owner joined Kickstarter until the campaign creation day   Ln(dayJoinFromStartDate)  Target amount of the campaign in USD  Ln(goal) Ratio of goal attainment on the first day of the campaign.  This variable serves as a proxy for campaign pre-shock momentum.   Whether the campaign was successful Amount of money pledged to the campaign in USD Ln(AmountPledged+1) 6.72 32.27 240.74 6.68 30.00 34.00 3.47 61720.30 8.19 3.53 5000.00 8.52 0.46 0.27 4283.70 3399.38 0.00 0.00 125.00 120.00 4.96 1.00 0.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 9.50 60.00 5305.00 8.58 168M 18.95 2150.36 1.00 194574.0 0 95031.1 1234 MIS Quarterly Vol. 43 No. 4/December 2019 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms Table 2.  Survey Questions and Descriptive Statistics for Participants’ Responses Q# Notation Question Mean Median Q1 How long, in your opinion, does it take to put together a campaign page like this, on a scale of 1–7 (1:   small amount of time; 7:  large amount of time)? Q4 Q3 Q2 Would you say the page looks sloppy or professional?  on a scale of 1–7 (1:   sloppy; 7:  professional)? How much effort was invested in the campaign page, on a scale of 1–7?  (1:  No investment; 7:  high investment) How much money do you think the owner spent on the project before creating the campaign page, on a scale of 1–7?  (1:  No money; 7:  large amount) Does the project have a website (besides the page on Kickstarter)?  (binary) Does it seem like the awards were carefully planned?  (binary:  yes/no) Do you think the owner of the project (service) is a professional in his field? [Possible answers: Q5 Q6 Q7 The owner has no experience in this field (1)   The owner is an amateur/hobbyist (2) The owner is a Professional (3)] TimeInvestment PageQuality Effort 3.54 3.64 3.47 MoneyInvestment 2.84 HasWebsite Rewards 0.21 0.62 3.67 3.67 3.33 2.67 0.00 0.67 Professionalism 2.03 2.00 regarding  each  of  the  9,588  campaigns  in  our  dataset  (of which 5,502 launched in the 5-week window before the shock, and 4,086 launched in the 1-week window after the shock).  The  questionnaires  were  administered  via  Amazon Mechanical Turk (MTurk).  We assigned three  Turkers to evaluate each campaign.  The score for each question for each campaign was computed as the average response across the three evaluators.  Table 2 presents the full list of questions (i.e., quality features), the response options for each question, and descriptive statistics. Shock Statistics To obtain a preliminary characterization of the supply-side shock  created  by  the  media  coverage  of  the  potato  salad campaign, we first compared campaigns that launched in the week immediately following the shock (July 8–July 14, 2014; hereby referred to as shock_week) with campaigns launched during the four weeks prior to July 8.  We separately exam- ined the supply-side effects (Table 3) and the demand-side effects (Table 4). Supply-Side Descriptive Statistics  As shown in Table 3, the number of campaigns offered on the platform during shock_week was 328% to 355% greater than the  number  of  campaigns  offered  during  each  of  the  four weeks preceding the shock (“Count” in Table 3).  As for the effect of the shock on campaign performance, we observe that the campaign success rate decreased substantially (success rates of 31% to 37% in the weeks before the shock versus 17% in the week of the shock), as did the amount of money pledged per campaign (a median of $429 to $967 in the weeks before the shock versus a median of $15 in the week of the shock). Demand-Side Descriptive Statistics Table 4 presents descriptive statistics regarding the changes in demand in the wake of the shock.  Notably, according to our observations, the spike in supply in the wake of the shock was not accompanied by a corresponding increase in demand.  For  example,  the  total  amounts  pledged  per  week  were between $6,552,491 and $10,383,634 in the weeks before the shock, as compared with $7,404,882 in the week after the shock.  Most other demand-side metrics remained similarly stable during shock_week (see Table 4).  The sharp increase in the number of campaigns coupled with the relatively stable demand provides us with an opportunity to study our hypothe- ses  without  having  to  account  for  potentially  confounding demand-related effects. We note that in order to provide further robustness to our results, we searched for additional situations on Kickstarter in which supply increased sharply with no significant effect on demand.    We  identified  several  events  where  there  was  a sharp increase in supply.  However, the dates surrounding MIS Quarterly Vol. 43 No. 4/December 2019 1235 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms Table 3.  Supply:  Descriptive Statistics by Week of Campaign Launch  June 24– June 17– June 10– June 16, 2014 (four weeks before the shock) 1233 June 23, 2014 (three weeks before the June 30, 2014 (two weeks before the Count Successful launched campaigns count IsSuccessful (mean) AmountPledged (mean) lnAmountPledged (mean) AmountPledged (median) lnAmountPledged (median) Goal (median) lnGoal (median) shock) 1144 shock) 1182 424 0.34 5115.08 5.83 656 6.49 6100 8.72 419 0.37 5540.87 6.1 943.5 6.85 6434 8.77 361 0.31 4628.41 5.6 449.5 6.11 6053 8.71 Table 4.  Demand:  Descriptive Statistics by Week of Campaign Launch June 10– June 16, 2014 (four weeks before the shock) June 17–  June 23, 2014 (three weeks before the shock) June 24– June 30, 2014 (two weeks before the shock) Money pledged (in millions of USD) Number of pledges Percentage of money (out of total money pledged) that was pledged to successful campaigns Percentage of successful pledges from total pledges 8.28 119,978 76% 80% 5.98 86,182 78% 82% 5.74 83,683 77% 80% June 31– July 7, 2014 (one week before the shock) 1168 405 0.35 4088.82 5.53 423.5 6.05 5000 8.52 June 31– July 7, 2014 (one week before the shock) 5.36 73,478 77% 80% July 8–  July 14, 2014 (shock_week) 4086 689 0.17 1574.22 3.17 15 2.71 3000 8.01 July 8–  July 14, 2014 (shock_week) 6.16 91,332 79% 81% these events overlapped substantially with one another.  This overlap prevented us from ascertaining whether the demand remained stable during the events (see Appendix B for full details).   Quality Measures for Crowd- funding Campaigns Derivation of Quality Measures In  this section, we describe in detail how we derived new measures  for  evaluating  campaign quality.   Measuring the inherent quality of a crowdfunding campaign is a challenging task.  Established firm-related quality criteria from the finance literature  are  often  inappropriate  for  early-stage  ventures (Stuart et al. 1999).  However, as discussed in the “Literature Review and Hypothesis Development” section, recent work has shown that crowdfunding platforms provide entrepreneurs with structural features that enable them to signal the quality of  their  ventures.    These  features  are  embedded  in  Kick- starter’s designated campaign pages, in which entrepreneurs describe their ventures and also present their personal bios (in a designated area on the page).  Indeed, measures based on these quality signaling features have been shown to predict the success  of  reward-based  crowdfunding  campaigns  (see  Burtch et al. 2013; Mollick 2014). In our study, we take the following established measures into account when evaluating campaign quality:  (1) the inclusion of a video in the campaign page (denoted HasVideo in our 1236 MIS Quarterly Vol. 43 No. 4/December 2019 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms econometric models) (see Mollick 2014; Zvillichovsky et al 2013) and (2) the number of words in the campaign descrip- tion  (NumWords)  (see  Gafni  et  al  2017;  Greenberg  et  al 2013).  Notably, studies considering the number of words as a measure of campaign quality typically log-transform this variable to account for its variance (Burch et al 2013). We have taken one step further to enrich our variable set to gain  a  more  comprehensive  and  accurate  measurement  of campaign quality.  As we describe below, in the spirit of prior work, we consider the extent to which the entrepreneur has invested effort and resources in the campaign, and the level of professionalism of the entrepreneur.  Although Kickstarter does not provide a structured format in which to report these characteristics, we suggest that a potential backer can deduce them from the campaign page and the online biography of the entrepreneur (or the entrepreneurial team).  On the basis of this rationale, we developed seven new variables that reflect entrepreneurial investment and professionalism and thus have the potential to signal a campaign’s quality.  We then manu- ally  evaluated  all  9,652  campaigns  in  our  dataset  (using Amazon Mechanical Turk) along these variables.  The use of manual (layperson-driven) evaluation enabled us to account for perceived campaign quality, in a process comparable to the evaluation made by actual site visitors during the period of the study. Table 2 in the “Data and Preliminary Observations” section shows the exact phrasing of the seven questions used to build our quality measures.  We emphasize that we focus on the quality  of  the  campaign  rather  than  on  the  quality  of  the product or service being funded because our dependent vari- ables are related to the performance of the campaign (rather than  the  successful  production  of  the  product  or  service).  Below we describe the derivation of the seven questions.  Full details can be found in Appendix A. Mollick  (2013)  has  suggested  that  venture  capitalists  and crowdfunders act to rationally assess project quality, of which the entrepreneur’s level of preparation is a key indicator.  He hypothesizes that entrepreneurs who demonstrate more pre- paredness are more likely to be funded.  We suggest that, in the domain of crowdfunding, entrepreneurial preparation is manifested in the effort and resources invested by the entre- preneur in preparation for launching a campaign.  Addition- ally, marketing literature suggests that potential consumers take  sellers’  (perceived)  effort  and  expense  into  account (Modig et al. 2014).  In the context of crowdfunding, we can assume that  consumers are sufficiently literate to deduce the levels of expense and effort invested by the seller, which they then use to infer whether the product is of better quality.   Thus,  to  measure  potential  backers’  perceptions  of  such investment, we focused on the following campaign attributes, which a potential backer can deduce from viewing a cam- paign’s page. • Money spent by the entrepreneur before launching the campaign (Q4 in Table 2). • • Time and effort spent in creating the campaign page (Q1 and Q3 in Table 2, respectively). Careful planning of the reward structure (Q6 in Table 2).  We further draw from literature showing that potential con- sumers use website design as a manifestation of the seller’s ability, and that this assessment in turn impacts their online purchase intentions (Schlosser et al 2006).  Thus, we also asked about • • The level of professionalism of the design of the cam- paign page (Q2 in Table 2). The use of an additional website outside of Kickstarter domain (Q5 in Table 2).  Human capital is associated with entrepreneurial success and quality (Ahlers et al 2015; Unger et al 2011).  However, the operationalization of human capital may be challenging within the context of Kickstarter, owing to the diversity of campaign categories,  which  range  from  art  and  food  to  design  and technology.  Hence, in building our quality measurements, we directly  asked  evaluators  (perceived) professionalism of the entrepreneurs in the field in which they operate (Q7 in Table 2).  The answers will provide insights into the degree to which the campaign page signals profes- sionalism  within  the  context  of  the  specific  campaign category. rank  to  the  Thus, our two datasets (the Kickstarter campaign data and the survey data) provided us with nine quality variables.  Taken together,  these  variables  constitute  a  more  comprehensive quality measure than what has been previously used in the literature. Assessment of Campaign Quality and Creation of All-Encompassing Quality Variable  In Table 5, we present a comparison of the nine quality vari- ables corresponding to campaigns in the weeks before and after the shock.  As can be seen, the shock brought with it a substantial  decrease  in  the  quality  of  campaigns  offered.  Specifically, the percentage of campaigns accompanied by a video  decreased  from  68%–73%  to  35%,  and  the  average number of words decreased from 1,168–1,293 to 790.  Addi- tionally, we see a post-shock decrease in the values of all our MIS Quarterly Vol. 43 No. 4/December 2019 1237 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms Table 5.  Mean Campaign Quality by Launch Week June 17- June 10- June 16, 2014 (four weeks before the June 23, 2014 (three weeks before the HasVideo NumWords lnNumWords TimeInvestment PageQuality Effort MoneyInvestment HasWebsite Rewards Professionalism shock) 0.7 1246.21 6.93 3.82 3.88 3.71 3.11 0.26 0.69 2.12 shock) 0.71 1281.27 6.97 4.08 4.16 3.95 3.29 0.27 0.73 2.19 June 24– June 30, 2014 (two weeks before the shock) 0.68 1248.87 6.93 3.91 4.03 3.84 3.15 0.25 0.68 2.14 June 31– July 7, 2014 (one week before the shock) 0.63 1166.18 6.86 3.91 3.98 3.79 3.04 0.25 0.69 2.15 July 8–  July 14, 2014 (shock_week) 0.33 787.24 6.44 2.96 3.07 2.92 2.37 0.14 0.5 1.85 newly  created  variables.    For  example,  when  considering ratings of the perceived amount of time invested in the cam- paign, we see a decrease from 3.84–4.09 to 2.97.  2017; Bonaccorsi et al. 2006; Sahoo et al. 2012).  In this work we define QualityPca as the first principal component of the fitted model.6 These patterns suggest that the average quality of the cam- paigns  launched  during  the  week  after  the  shock  deviated from, and was lower  than, the typical (pre-shock) average quality of campaigns on Kickstarter.   This decrease  might indicate that many of the campaigns that launched in the wake of the shock were opportunistic in nature.  Accordingly, our preliminary observations that campaign performance during shock_week was weaker than that during the period preceding the shock are potentially attributable to one of two explana- tions:  (1) the effect is endogenous (i.e., campaigns launched during such a period are of lower quality and hence less likely to succeed and raise money) or (2) the intense competition among low-quality offerings that emerged in the wake of the shock created choice overload and had a harmful effect on the performance of campaigns that would otherwise have been more successful.  Hence, it is necessary to use an identifica- tion strategy that enables us to estimate how a given campaign of  “typical”  pre-shock  quality  would  be  affected  by  an increase in the number of low-quality campaigns on the plat- form  as  if  all  else  remained  equal.    As  elaborated  in  the “Methodology” section, we used two complementary identifi- cation strategies to achieve this goal.   Finally,  we  used  principal  component  analysis  (PCA)  to reduce the dimensionality and to transform the nine variables into  one  all-encompassing  quality  variable,  denoted QualityPca (the use of PCA in this manner is widely recog- nized in the IS literature and other social science disciplines; see, for example, Allport and Kerler 2003; Ayabakan et al. 1238 MIS Quarterly Vol. 43 No. 4/December 2019 Methodology Identification Strategies Here, we present two identification strategies to address the identification challenge outlined above:  namely, the need to isolate the effect of choice overload on campaigns’ perfor- mance from the effect of the inherently lower quality of the campaigns  themselves.    Our  first  identification  strategy focuses on pre-shock campaigns and is built on variation in the time proximity to the shock.  The second strategy focuses on comparing pre-shock campaigns to post-shock campaigns using propensity score matching (PSM).  Both methods are used to study both hypotheses, and rely on our newly devel- 6Seeing as our empirical investigation included two types of identification strategies, each using different campaigns for estimation, we fit two PCA models, once for each identification strategy.  When implementing the “time proximity” identification we fit a PCA model on the nine quality features of the 4,453 campaigns used in our estimations.  Seeing as PCA is sensitive to large variances in features, prior to fitting the model, we standardized the nine quality features.  The first principal component captures 64% of the variation of our features.  When implementing the “matching identification,” we fit a PCA model on the beforecampaigns and then transformed the after campaigns using the fitted model.  As with the time proximity method, here too we standardized the features prior to fitting the model.  The first principal component captures 59% of the variation of our features.  To fit the models, we used a Python implementation of PCA (see http://scikit-learn.org/stable/ modules/generated/sklearn.decomposition.PCA.html). Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms oped quality measures.  We note that the two identification strategies have slightly different advantages, and are hence complementary and provide robustness.  In what follows, we discuss  the  two  identification  methods,  their  relative advantages, and how they  are  used to address each of the hypotheses. Identification Method 1:  Time Proximity to the Shock  The premise of our first identification method was to focus on campaigns whose inherent quality was not likely to have been influenced by the shock, but whose performance was likely to have been influenced by the post-shock environment.  To this end,  we  examined  campaigns  that  were  launched  briefly before the shock—such that their creation (and hence quality) was independent of the shock—yet were open for funding for some time after the shock commenced.  As the average life- span of a campaign is 32 days, we focused on campaigns that started  during  the  four  weeks  immediately  preceding  the shock and ended after the shock (4,453 campaigns in total). The variation needed for identification comes from the dif- ferent  launch  dates;  we  assume  that  campaigns  launched closer to the shock are more likely to have been affected by the  post-shock  environment  of  intensified,  low-quality competition, as they spent more of their “lives” in that envi- ronment.  To better understand our identification strategy, consider the following illustration:  Assume that campaign A was launched on July 1, 2014 (seven days before the shock), and that campaign B was launched two days later, on July 3, 2014 (five days before the shock).  Given that both campaigns were launched before the shock, they are likely to be of com- parable quality (or drawn from the same pre-shock quality distribution).  However, campaign B may be more strongly influenced by the effect of the shock, as the shock occurred earlier in the campaign’s life.  Hence, any variation explained by proximity to the shock can be attributed to the effect of competing in a market of lemons.  This example is illustrated in Appendix C. An important property of this identification strategy is the fact that, by comparing among pre-shock campaigns, rather than comparing pre-shock campaigns with post-shock campaigns, we are able to control for the overall decrease in campaign quality following the shock.  Further, we are able to control for any additional unobserved changes in the campaign mix that the shock might have brought.  For example, some sup- pliers might have chosen to intensify their signaling efforts after the shock began, to better differentiate themselves from the crowd.  Our identification strategy enables us to control for such unobserved changes. We implemented this strategy to test both H1 and H2.  Speci- fically, we created a variable that measures how many days before  the  shock  the  campaign  launched,  denoted  as DaysFromShockDay.  We estimated its impact on the cam- paign performance variables (H1) as well as the moderating effect  of  quality  on  the  effect  of  the  shock  (H2),  and  we quantified the effect of each additional day of exposure to the post-shock conditions. Identification Method 2:  Propensity Score Matching  In our second identification method, we used PSM to match campaigns launched before the shock (before campaigns) to campaigns  launched  immediately  after  the  shock  (after campaigns).    Briefly,  we  first  compared  the  two  matched groups to study the effect of the shock (i.e., the impact of being a pre-shock campaign as opposed to being a post-shock campaign)  on  the  performance  variables  of  interest  (H1).  Then, using the quality measures we developed, we conducted subsample regression analysis to test the moderating effect of quality (H2). As mentioned, the weeks after the shock were characterized by campaigns of atypically low quality (as compared with the period before the shock).  Yet, our goal is to understand the effect of the shock on campaigns of typical quality.  Hence, the  purpose  of  the  matching  procedure  was  to  find  two comparable  groups,  one  that  included  “typical”  pre-shock campaigns, and one that included campaigns that started after the shock and that are similar in their characteristics to the pre-shock campaigns.  Specifically, for the before group, we used campaigns that were launched 5 or 4 weeks before the shock (between June 3 and June 16, 2014) and finished before the shock (959 campaigns); for the after group we used cam- paigns launched the week after the shock, between July 8 and July 14.  For each before campaign we matched one after campaign using PSM.7  Because the PSM procedure ensured that  the  two  groups  would  comprise  similar  campaigns, performance differences between them were not susceptible to biases due to post-shock changes in the inherent charac- teristics of campaigns available on the platform. The specific choice of the before period was made for a few reasons:  First, clearly, we needed to choose a time period that would include a large number of campaigns that began and ended  before  the  shock.    At  the  same  time,  we  sought  to 7We conduct PSM (without replacements) to find the closest match for each project in weeks 4 and 5.  For each project in weeks 4 and 5, we use 1- nearest neighbor to find the project that is nearest to it in terms of propensity score. MIS Quarterly Vol. 43 No. 4/December 2019 1239 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms ensure that the launch criteria for the campaigns selected from this period would be comparable to those of the campaigns launched during the after period.  On June 3, 2014, Kick- starter implemented a policy change in the platform that made it easier for campaigns to be accepted and launched.8  This change  in  the  platform  may  have  affected  performance measures as well as quality (Wessel et al. 2015).  In order to avoid potential confounding effects resulting from the change in launch criteria, we chose campaigns that launched after the policy change went into effect, and limited our choice only to campaigns that ended prior to the shock.   We performed PSM by matching campaigns on the following three types of variables: • • • General  campaign  characteristics,  including  category, duration, and goal. Campaign  quality,  including  the  established  quality measures (video inclusion, number of words in the cam- paign description) as well as our seven newly developed measures (see Table 2).  Project  owner’s  on-platform  tenure  and  experience.  Previous works have shown that the experience that a project  owner  has  on  the  platform  may  influence  the likelihood of a project to succeed (Inbar and Barzilay 2014; Zvilichovsky et al. 2013).  Entrepreneurs’ tenure is often translated  into  social  proof,  which  is one of the factors for entrepreneurial success (Bapna 2019; Vester- lund 2003).  Hence, we include the following three  mea- sures:  the number of projects the owner has previously backed, the number of successful projects that the owner has previously launched on the platform, and the tenure of  the  project  owner  on  the  platform  at  the  time  of creating the project (measured in days). Estimation Equations  Outcome Variables of Interest  regression,9 and we analyzed the latter using OLS.10  For the latter,  we  estimate  the  logarithm  of  the  amount  of  money pledged rather than the absolute amount, as the large range of different  types  of campaigns  leads  to high  variance  in  the amount of money pledged per campaign.  In what follows, we present our empirical strategy and the estimation equations used to study our hypotheses.  Recall that each hypothesis is tested twice, once with each of the identification methods. Identification Method 1:  Time Proximity to the Shock Studying H1:  The Average Effect of the Shock on Cam- paign  Performance.    Recall  that  our  first  identification method focuses on the effect of a campaign’s time distance from  the  shock  (DaysFromShockDay)  on  its performance.  The literature indicates that backing activity is U-shaped; that is, it deteriorates toward the middle of the campaign fund- raising period (Kuppuswamy and Bayus 2015).  Hence, in our estimations we use the logarithm of DaysFromShockDay. We first focus on the likelihood of success, using a logistic regression (with category-specific fixed effects).  If the post- shock environment affects success rate, we should expect to see a higher success rate among campaigns launched earlier in the examined time period (i.e., at a greater distance from the shock).  Note that we control for various factors, including the following:  the funding target (goal) of the campaign, the on-platform experience and tenure of the owner, the category of the campaign, and the duration of the campaign.  Another factor that may influence campaign performance is the cam- paign momentum achieved prior to the shock.  It is reasonable to believe that a campaign that has accumulated a significant portion of its goal prior to the shock will succeed indepen- dently of the shock.  Hence, as a proxy for a campaign’s pre- shock  momentum,  we  accounted  for  the  ratio  of  the  goal attained on the campaign’s first day.  Accordingly, our full regression equation is as follows: In this work we focus on two outcome variables that represent campaign performance.  The first is whether the campaign was  successful,  that  is,  achieved  its  funding  goal  (IsSuc- cessful, a binary variable), and the second is the amount of money raised (AmountPledged).  We used both performance variables  when  implementing  both  identification  methods.  IsSuccessful is a binary variable and AmountPledged is a con- tinuous variable; thus, we analyzed the former using logistic 8For the policy change, see https://www.kickstarter.com/blog/introducing- launch-now-and-simplified-rules-0. 9Note  that  all  results  presented  in  the  paper  for  measuring  likelihood  to succeed use a logit model; however, results were consistent in direction and significance when using a probit model as well. 10 We use OLS to estimate the effect on ln(AmountPledged).  OLS is a good measurement tool for our hypothesis structure:  First, we are measuring the effects on a continuous variable and as such should use an analytical tool that deals with continuous variables (such as OLS, as opposed to a regression model, which studies effects on binary or multiclass outcomes).  Second, as our identification strategies (time proximity and propensity score matching), together with our control parameters, provide sufficient assurance that E[å|X] = 0, it is safe to use OLS without fear of violating the exogeneity assumption. 1240 MIS Quarterly Vol. 43 No. 4/December 2019 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms (1) We  ran  this  equation  with  two  operationalizations  for  the Quality variable.  In the first we used QualityPca, the all- encompassing quality variable constructed using PCA (see the subsection  on  “Derivation  of  Quality  Measures”).    In  the second, we used QualityBinary—a binary representation of QualityPca,  where  the  median  of  QualityPca  serves  as  a threshold:  observations with quality < median (QualityPca) are  assigned  the  value  0  and  are  regarded  as  low-quality, whereas observations with quality > median (QualityPca) are assigned the value 1 and are regarded as high-quality.   to  Next, we estimated the impact of a campaign’s distance from the  shock  (DaysFromShockDay)  on  the  logarithm  of  the amount  of  money  pledged  the  campaign (ln(AmountPledged+1)),  using  an  OLS  regression  (with category-specific  fixed  effects).    If  the  shock  environment indeed  affects  the  amount  of  money  pledged,  we  expect campaigns launched further from the shock to receive higher pledges  compared  with  campaigns  launched  closer  to  the shock.  The control variables were the same as in equation (1).  As before, we ran this equation with two operationalizations for the Quality variable. Studying  H2:    The  Moderating  Effect  of  Quality.    To estimate  the  moderating  effect  of  quality  on  each  of  the performance  variables  (likelihood  to  succeed  and  amount pledged),  we  estimated  equation  (1),  specified  above,  by term  between  Quality  and adding  an  lnDaysFromShockDay.  Once again, we estimated these equa- tions  twice,  once  using  QualityBinary  and  once  using QualityPca. interaction  Identification Method 2:  Propensity Score Matching  Studying H1:  The Average Effect of the Shock on Cam- paign Performance.  As with the first identification strategy, we  used  logistic  regression  when  estimating  likelihood  to succeed  and  OLS  when  estimating  the  amount  of  money pledged.  The variable of interest is before, which is a binary variable denoting whether the campaign started (and ended) in the pre-shock period (in which case before equals 1) or during the week immediately following the shock (in which case before equals 0).  If the shock indeed had a negative effect on the average campaign performance, we expect the coefficient of before to be positive and significant.  The con- trol  variables  are  the  same  as  in  equation  (1)  with  the exclusion of RatioGoalFirstDay.  This variable is no longer relevant, as in the PSM identification strategy we compare campaigns before the shock to campaigns that started during the  shock,  assuming  that  the  shock  has  an  effect  on  the amount pledged and specifically on the amount pledged in the first  day  (whereas  in  the  first  identification  method,  the amount pledged in the first day is not affected by the shock).  As with the first identification strategy, here too we used two the  Quality  variable,  namely, operationalizations  of  QualityBinary and QualityPca.  Equation (2) is the logistic regression  equation  estimating  the  effect  on  likelihood  to succeed; the control variables for the OLS regression esti- mating  the  effect  on  AmountPledged  are  the  same  as  in equation (2).  (2) Studying H2:  The Moderating Effect of Quality.  To esti- mate the moderating effect of quality on each of the perfor- mance variables (likelihood to succeed and amount pledged), we  estimated  equation  (2),  specified  above,  by  adding  an interaction term between Quality and Before.  For each per- formance  variable,  we  estimated  this  equation  twice,  once using QualityBinary and once using QualityPca.  Given our hypothesis that quality moderates the effect of the shock, we expected  the  interaction  term of  Before  and  Quality  to  be negative and significant, indicating that lower-quality cam- paigns were influenced more by the shock. To improve matching accuracy, our matching was not per- formed  on  the  variable  QualityPca,  but  rather  on  the individual variables attributed to quality, as well as additional campaign characteristics (as explained above in the “Identi- fication Strategies” section).  Thus we had to make sure that, for  each  low-  and  high-quality  subsample  (created  by QualityBinary), QualityPca was balanced between the before and  after  groups.    For  the  balancing  test  performed,  see Appendix D. Results Identification Method 1:  Time Proximity to the Shock The results for the estimations using the first identification method are presented in Table 6.  In the table, models (1) and MIS Quarterly Vol. 43 No. 4/December 2019 1241 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms Table 6.  Time Proximity Identification:  H1 + H2 Regressions  Model 1 0.155*** (0.046) 0.629*** (0.028) Model 2 Model 3 Model 4 Model 5 Model 6 Model 7 Model 8 0.147*** 0.160*** (0.044) (0.039) 0.822*** (0.038) 0.166*** (0.048) 0.685*** (0.054) 0.143*** (0.039) 0.845*** (0.017) 0.180*** (0.042) 0.265*** (0.056) 0.305*** (0.071) 1.912*** (0.099) 2.509*** (0.246) -0.244*** (0.091) 3.211*** (0.085) 3.671*** (0.217) -0.192** (0.083) lnDaysFromShockDay QualityPca QualityBinary lnDaysFromShockDay ×QualityBinary lnDaysFromShockDay ×QualityPca lnGoal lnDayJoinFromStartDate NumSucceeded NumBacked Duration -0.602*** (0.036) 0.054** (0.023) 0.106 (0.082) 0.024*** (0.007) -0.005 (0.004) 4.246*** (0.339) 5.607 4,453 -0.396*** (0.031) 0.090*** (0.022) 0.108 (0.085) 0.029*** (0.007) -0.007* (0.004) 5.155*** (0.347) 9.051 4,453 -0.407*** (0.031) 0.088*** (0.022) 0.103 (0.084) 0.029*** (0.007) -0.007* (0.004) 5.148*** (0.346) 10.524 4,453 -0.024 (0.020) -0.608*** (0.037) 0.054** (0.023) 0.105 (0.082) 0.024*** (0.007) -0.005 (0.004) 4.241*** (0.339) 8.638 4,453 -0.029 (0.023) 0.114*** (0.019) 0.199*** (0.054) 0.023*** (0.005) -0.005 (0.003) -0.001 (0.001) 6.289 4,453 0.459 0.456 2.383 0.094*** (0.025) 0.206*** (0.021) 0.191*** (0.058) 0.027*** (0.005) -0.009** (0.004) -0.000 (0.001) 9.9 4,453 0.368 0.364 2.575 0.089*** (0.025) 0.204*** (0.021) 0.190*** (0.058) 0.028*** (0.005) -0.009** (0.004) -0.001 (0.001) 11.245 4,453 0.368 0.365 2.574 0.010 (0.015) -0.026 (0.024) 0.114*** (0.019) 0.198*** (0.054) 0.022*** (0.005) -0.005 (0.003) -0.001 (0.001) 9.281 4,453 0.459 0.456 2.383 RatioGoalFirstDay CategoriesFixedEffects Num. obs. R2 Adj. R2 RMSE ***p <.01, **p < .05, *p < 0.1 Note:  Models 1–4 correspond to logistic regressions in which the dependent variable is IsSuccessful.  Models 5–8 correspond to OLS regressions in which the dependent  variable is lnAmountPledged.   For robustness, we ran models 5–8 with robust standard errors.  Results were significant and in the same direction. (2) correspond to the estimations of success likelihood.  Each model uses a different operationalization of “quality,” as dis- cussed above:  Model (1) uses QualityPca, the continuous quality  variable  constructed  using  PCA;  model  (2)  uses QualityBinary, the binary representation of QualityPca.  As can be observed, in both models, the coefficient of the number of days between the launch date of a campaign and the shock is positive and significant.  This means that campaigns that were open for longer periods of time in the pre-shock envi- ronment had a greater likelihood of being successful, sug- gesting that the shock environment led to a decrease in the likelihood of success.  Specifically, the odds of being suc- cessful increase by a factor of 1.0149–1.0154 for a 10% in- crease in the distance from the shock (in terms of the number of days from the shock).11  These results support H1(A). 11For a complete calculation of the economic impacts reported in the paper, see Appendix E. Models (5) and (6) correspond to the estimations of amount pledged, using QualityPca and QualityBinary, respectively, to operationalize Quality.  As shown in Table 6, the effect is significant for both models, suggesting that, after controlling for quality, the shock environment decreased the amount of money a campaign was able to raise in its lifetime.  These results support H1(B).  Specifically, for a 10% increase in distance from the shock, we see an increase of 1.4%–1.7% in the amount of money pledged; for a 50% increase in distance from the shock, we see an increase of 6%–7.6% in the amount pledged.    For  example,  an  average  campaign  that  was launched on day 2 prior to the shock and raised approximately U.S.  $3,000  would have  raised  $180  to $228  more  had  it started on day 3 prior to the shock, and it would have raised $780 to $1020 (26%–34%) more had it started on day 10 prior  to  the  shock.    Clearly,  when  considering  the  overall effect on all campaigns, these observations have significant implications  for  entrepreneurs  and  for  the  platform, 1242 MIS Quarterly Vol. 43 No. 4/December 2019 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms particularly  in  light  of  the  large  number  of  campaigns involved:  During the week before the shock, over 1,000 new campaigns launched, and more broadly, over 4,200 campaigns launched before the shock and were open for funding during the  post-shock  period.    All  of  these  campaigns  were potentially affected by the shock. interaction  Models (3) and (7) correspond to the estimations that include term  between  QualityBinary  and the  lnDaysFromShockDay, for likelihood to succeed and amount pledged, respectively.  As can be observed, in both cases the interaction coefficients are negative, suggesting that campaign quality moderates the effect of distance from the shock on likelihood to succeed and on amount pledged.  Notably, in the presence  of  the  interaction  term,  the  main  effect  (i.e., lnDaysFromShockDay) is still significant and positive.  These results support H2(A) and H2(B).  When considering like- lihood  to  succeed,  these  results  imply  that  for  low-quality campaigns, the odds of being successful increase by a factor of 1.03 for a 10% increase in the distance from the shock, whereas for high-quality campaigns the odds increase by a factor of 1.006.  When considering amount pledged, we find that for low-quality campaigns a 10% increase in distance from the shock is expected to yield a 2.6% increase in the amount pledged, whereas for high-quality campaigns a 10% increase in distance is expected to yield only a 0.7% increase in the amount pledged.  Thus, quality moderates the effect by a factor of over 3.  Models (4) and (8) correspond to the esti- mations that include the interaction term between QualityPca and  lnDaysFromShockDay,  for  likelihood  to  succeed  and amount pledged, respectively.  As can be observed, while the main effects remain significant, the interaction terms are not.  Identification Method 2:  Propensity Score Matching  The result of the  estimations using the PSM identification method are presented in Table 7.  Models (1) and (2) corre- spond to the estimation of success likelihood, and models (5) and (6) correspond to the estimation of the amount of money pledged.  As above, each model uses a different operationa- lization  of  Quality:    Models  (1)  and  (5)  use  QualityPca; models (2) and (6) use QualityBinary, As can be observed, in all models the coefficient of Before (the variable of interest) for both performance measures is positive and significant, suggesting that the post-shock environment decreased cam- paigns’ likelihood to succeed and the amount that they were able to raise.  These results support both H1(A) and H1(B).  Specifically, we observe that campaigns launched before the shock were 1.3 times more likely to succeed compared with (similar)  campaigns  launched  after  the  shock  (both  when controlling for QualityPca , model (1), and when controlling for QualityBinary, model (2)).  Similarly, campaigns launched before the shock raised 36%–43% more, on average, com- pared with campaigns launched after the shock. Models (3) and (7) correspond to the estimations that include the interaction term between QualityBinary and Before, for likelihood to succeed and amount pledged, respectively.  As can be observed, in both cases the interaction coefficients are negative,  suggesting  that  campaign  quality  moderates  the effect of being a before campaign on likelihood to succeed and on amount pledged, such that campaigns of lower quality are more negatively affected by the shock environment than campaigns  of higher  quality.    Specifically,  for  low-quality campaigns, we observe that campaigns launched before the shock are 1.67 times more likely to succeed compared with campaigns launched after the shock.  For high-quality cam- paigns, campaigns launched before the shock are only 1.11 times  more  likely  to  succeed  compared  with  campaigns launched after the shock.  Similarly, low-quality campaigns launched  before  the  shock  raised,  on  average,  86%  more money than did low-quality campaigns launched during the week of the shock; in contrast, among high-quality campaigns, pre-shock campaigns raised only 10% more compared with post-shock  campaigns.    Notably,  in  the  presence  of  the interaction term, the main effect (i.e., Before) is still signi- ficant and positive.  These results support H2(A) and H2(B). Models (4) and (8) correspond to the estimations that include the  interaction  term  between  QualityPca  and  Before,  for likelihood to succeed and amount pledged, respectively.  As can be observed, as with models (3) and (7) the interaction coefficients are  negative, suggesting that campaign quality moderates the effect of being before the shock on likelihood to succeed and on amount pledged.  Specifically, when ob- serving the effect on likelihood to succeed we see that a one- unit increase in QualityPca decreases the effect of being a before campaign by a factor  of  0.887.  That is, as quality increases, the effect of being launched and completed before the shock decreases.  The same is observed when considering the effect on lnAmountPledged.  Specifically, we see that a one-unit increase in quality decreases the effect of being a before campaign by a factor of 0.89. We note that the results obtained via the PSM identification method may seem somewhat different in terms of the effect size  than  those  obtained  using  the  time  proximity  identi- fication.  This difference may be attributed to the fact that each identification method quantifies a somewhat different effect.    The  time  proximity  identification  measures  the strength of the effect (degree of exposure to the post-shock environment) on the campaign outcome, whereas the PSM identification measures the average effect over two groups of campaigns that ran either before or after the shock. MIS Quarterly Vol. 43 No. 4/December 2019 1243 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms Table 7.  Propensity Score Matching Identification:  H1 + H2 Regressions Before QualityPca QualityBinary Before×QualityPca Before×QualityBinary lnGoal lnDayJoinFromStart Date NumSucceeded NumBacked Duration Model 1 Model 2 Model 3 Model 4 Model 5 Model 6 Model 7 Model 8 0.310*** 0.276** (0.120) (0.111) 0.872*** 0.64*** (0.040) (0.036) 0.338*** (0.124) 0.710*** (0.052) 0.310*** (0.111) 0.814*** (0.027) 0.511*** (0.177) 0.360*** (0.119) 0.621*** (0.167) 0.279** (0.114) 1.968*** (0.139) 2.187*** (0.190) 3.037*** (0.131) 3.307*** (0.179) -0.120** (0.057) -0.769*** (0.053) 0.099*** (0.032) 0.143* (0.084) 0.030*** (0.011) -0.000 (0.010) -0.403* (0.233) -0.591*** (0.046) 0.135*** (0.030) 0.151* (0.083) 0.037*** (0.012) 0.014 (0.009) -0.76*** (0.052) 0.100*** (0.032) 0.154* (0.086) 0.03*** (0.011) 0.001 (0.010) -0.588*** (0.046) 0.136*** (0.030) 0.155* (0.084) 0.037*** (0.012) 0.015* (0.009) 0.010 (0.038) 0.137*** (0.029) 0.079 (0.055) 0.023*** (0.008) 0.004 (0.009) 0.077* (0.040) 0.225*** (0.030) 0.092 (0.059) 0.025*** (0.009) 0.026*** (0.009) -0.116** (0.047) 0.010 (0.037) 0.134*** (0.029) 0.078 (0.055) 0.023*** (0.008) 0.002 (0.009) -0.528** (0.238) 0.077* (0.040) 0.223*** (0.030) 0.093 (0.059) 0.025*** (0.009) 0.025*** (0.009) 4.002 1,918 1.441 1,918 5.041 CategoriesFixed Effects Num. obs. R2 Adj. R2 RMSE ***p <.01, **p < .05, *p < .1 Note:  Models 1–4 correspond to logistic regressions in which the dependent variable is IsSuccessful.  Models 5–8 correspond to OLS regressions in which the dependent variable is lnAmountPledged.  For robustness we ran models 5–8 with robust standard errors.  Results were significant and in the same direction. 1,918 0.451 0.445 2.417 1,918 0.371 0.364 2.588 1,918 0.372 0.365 2.585 1,918 0.453 0.446 2.414 10.843 4.431 1,918 1,918 6.377 9.842 9.313 Discussion In this paper, we have studied the implications of flooding an open  crowdfunding  marketplace  with  opportunistic  low- quality offerings.  We developed a new approach to charac- terizing  the  quality  of  a  campaign  by  factoring  in  the resources invested by the entrepreneur (such as time, money, and effort) and his or her perceived professionalism.  Doing so, we were able to estimate how signaling differentiates be- tween high-quality and low-quality campaigns and mitigates the effect of choice overload.  Our analysis exploited a short- term  period  of  highly  visible  media  exposure  given  to Kickstarter following the launch of an unusual campaign (the “potato salad campaign”), which enabled us to avoid temporal and seasonal bias in our empirical estimates. We suggest that a sudden influx of low-quality offerings into a  marketplace  represents  more  than  just  an  identification opportunity.  The very fact that such an event occurred high- lights some of the unique characteristics that distinguish peer economy platforms from other firm-based two-sided platforms (hence, our findings may be applicable to other peer-economy platforms such as Airbnb, Uber, and Ebay).  On peer-to-peer crowd-based platforms, particularly during their first years, the “crowd” occupies both sides of the marketplace.  Hence, suppliers  in  these  marketplaces  may  be  more  likely  than suppliers in more traditional marketplaces to be susceptible to exogenous stimuli and to manifest herding behavior.  These characteristics—coupled with an “open admissions” policy in which the platform does not strictly moderate the content that suppliers  can  offer—may  lead  to  situations  in  which exogenous events that draw attention to a platform trigger flooding of the market with low-quality offerings.  Similar supply-side shocks may not be as intense in firm-based two- sided  markets,  in  which  established companies  react  more slowly, and have substantial opportunity costs.  Yet, we stress 1244 MIS Quarterly Vol. 43 No. 4/December 2019 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms that our work was conducted in the context of crowdfunding, and studying similar situations in other peer-to-peer platforms constitutes an interesting avenue for future work. Our analyses show that the sharp increase in the number of low-quality campaigns triggered by the media exposure shock had, on average, a negative effect on the performance of the campaigns  launched  on  the  platform,  manifested  in  their success rate and the money they raised, in line with phenom- ena observed in research on choice overload.  These effects, however, were moderated by campaign quality:  Entrepre- neurs  who  signaled  higher  levels  of  professionalism  and investment of resources in developing their campaigns were less affected by  the flooding than were  entrepreneurs who launched  lower-quality  campaigns.    Our  estimations  con- trolled for diverse factors that may affect campaign perfor- mance (and may be differentially affected by an influx of low- quality offerings), including the entrepreneur’s tenure on the platform,  experience,  campaign  category,  and  target  goal.  Our results were consistent across two complementary identi- fication strategies; the first considered only campaigns starting before  the  influx  occurred,  and  the  other  used  a  matching procedure to compare campaigns with similar characteristics launched before- versus after the flooding began. Contribution and Implications  Our paper offers methodological, theoretical, and managerial contributions.  From a methodological perspective, we present a novel identification method—the time proximity method— to  control  for  quality  fluctuations  when  studying  natural experiments based on exogenous shocks.  Indeed, in many cases, an exogenous shock not only changes the conditions under which observations (in our case, crowdfunding cam- paigns) operate but also affects the inherent characteristics (quality distribution) of the population.  Our identification strategy eliminates this bias by considering only observations that  were  generated  before  the  exogenous  shock  occurred (such that their characteristics were independent of the shock), yet whose performance was likely to have been influenced by the shock.  The variation needed for identification comes from the  different  launch  dates;  in  our  case,  we  assumed  that campaigns launched closer to the shock were more likely to have been affected by the post-shock environment.  Second, we  contribute  a  richer  approach  to  measuring  quality  in crowdfunding  platforms.    We  went  beyond  the  platform’s structured features (used in previous research) and, using a manual evaluation approach, sought to incorporate additional subtle  quality  signals  that  backers  take  into  account  when making  including  entrepreneurs’ resource  investment  (time,  money,  effort)  and  (perceived) competence. investment  decisions,  Third, our work adds to the literature on the effects of crowd- funding platform design decisions by informing the debate on open versus closed platform acceptance policies.  Previous research in IS has examined this issue in several contexts.  Specifically, Boudreau et al. (2010) examined the effects of different levels of platform openness in the context of com- puting  platforms.    More  recently,  Niculescu  et  al.  (2018) explored  the  strategic  decision  of  an  incumbent  platform owner to open the core technology of its platform to other competitors on the same side of the ecosystem.  In the context of the peer economy, Wessel et al. (2017) have shown that market  openness  raises  the  revenues  of  the  platform  but lowers the performance of the individual seller.  We add to this literature by demonstrating that platform openness can lead to the emergence of supply-side phenomena that are not possible in markets with strict barriers for entry—such as an influx in low-quality offers—and that these phenomena affect platform dynamics and performance. From a theoretical perspective, this work is among the first to focus on supply-side shocks in share economy platforms.  As elaborated above, these shocks warrant investigation in light of the particular characteristics of sellers on peer economy platforms, who are individuals (rather than firms) who watch TV  and  consume  content  online,  and  who  act  instantly  to capitalize on what they consider to be business opportunities.  Additionally, our work links the theory of choice overload with  signaling  theories,  by  stipulating  and  empirically showing that reliance on quality signaling can mitigate the detrimental effects of choice overload, by allowing for differ- entiation between offers in crowdfunding markets. Finally, our paper has several important managerial impli- cations:  For entrepreneurs, we show that, on average, the performance  of  crowdfunding  campaigns  suffers  when  the market  is  flooded  with  low-quality  campaigns.    Although high-quality campaigns are somewhat less susceptible to this effect compared with lower-quality campaigns, the average entrepreneur who wishes to launch a crowdfunding campaign is advised to wait for the influx of low-quality campaigns to subside.  For platform designers, we provide empirical evi- dence that a platform can succeed in signaling the quality of its  campaigns,  and  thereby  mitigate  some  of  the  damage caused  by  flooding  the  marketplace  with  low-quality offerings. Limitations and Future Work We acknowledge that our work has certain limitations.  First, the setting of our paper and the data available to us do not enable  us  to  empirically  conclude  whether  the  negative influence of the post-shock environment on performance was MIS Quarterly Vol. 43 No. 4/December 2019 1245 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms specifically due to the increase in low-quality campaigns, or whether it might have been due to the increase in the number of campaigns in general.  That is, we cannot say how a steep increase in the number of high-quality campaigns would have affected the performance of campaigns on the platform.  That being said, seeing as peer economy platforms keep moving toward  more  open  and  democratic  policies  that  allow  lay- persons and amateurs to enter the market, it is crucial for both platform  owners  and  participants  in  the  market  to  better understand the implications of being flooded with low-quality offerings.  Second, as elaborated above, a sharp increase in low-quality offerings  on  crowdfunding  platforms  is condi- tioned on the platform having a lenient acceptance policy that enables opportunistic entrepreneurs to enter the market.  Plat- forms with more restrictive policies may be characterized by different dynamics that are not covered in the current investi- gation.  Another limitation is that our empirical investigation relies on a single media shock that brought with it a sharp increase in the number of low-quality campaigns.  As noted above, we did not identify any other comparable shocks on Kickstarter.    Future  research  should  seek  to  identify  and analyze additional shocks of this nature, both on Kickstarter and on other platforms, in order to evaluate the robustness and generalizability  of  our  conclusions.    Finally,  our  limited observational data do not enable us to carry out an in-depth study of backers’ full decision processes.  Future work could delve into this further.  Another interesting avenue for future research would be to model additional supply-side signaling constructs, beyond quality—such as owner signaling effort and signaling costs—and examine how they are affected by an influx of low-quality offerings. Acknowledgments We would like to thank the senior editor, the associate editor and three reviewers for their constructive and insightful comments and suggestions.  We also thank participants of  SCECR 2016, CIST 2016, WISE 2016, and ICIS 2017, for their valuable comments and feedback.  Additionally, we would like to thank Karen Marron for her editorial assistance.  This study benefitted from the support of Israel Science Foundation (Grant No. 1570/15), the Kadar Family Foundation, the Blavatnik Interdisciplinary Cyber Research Center, and the Henry Crown Institute of Business Research in Israel. References Agrawal, A., Catalini, C., and Goldfarb, A.  2014.  “Some Simple Economics  of  Crowdfunding,”  Innovation  Policy  and  the Economy (14:1), pp. 63-97. Agrawal, A., Catalini, C., and Goldfarb, A.  2015.  “Crowdfunding:  Geography, Social Networks, and the Timing of Investment Deci- sions,” Journal of Economics & Management Strategy (24:2), pp. 253-274.  1246 MIS Quarterly Vol. 43 No. 4/December 2019 Ahlers, G. K., Cumming, D., Günther, C., and Schweizer, D.  2015.  “Signaling in Equity Crowdfunding,” Entrepreneurship Theory and Practice (39:4), pp. 955-980. Akerlof, G.  1970.  “‘The Market for “Lemons’:  Quality Uncertainty and  the  Market  Mechanism,”  The  Quarterly  Journal  of  Eco- nomics (84:3), pp. 488-500. Allport,  D.  C.,  and  Kerler,  W.  A.    2003.    “A  Research  Note Regarding the Development of the Consensus on Appropriation Scale,” Information Systems Research (14:4), pp. 356-359. Ayabakan,  S.,  Bardhan,  R.  I.,  and  Zheng,  Z.    2017.    “A  Data Envelopment Analysis Approach to Estimate IT-Enabled Produc- tion Capability,” MIS Quarterly (33:4), pp. 763-783.   Bapna,  S.    2019.    “Complementarity  of  Signals  in  Early  Stage Equity  Investment  Decisions:    Evidence  from  a  Randomized Field Experiment,” Management Science (65:2), pp. 933-952. Belleflamme,  P.,  Lambert,  T.,  and  Schwienbacher,  A.    2014.  “Crowdfunding:  Tapping the Right Crowd,” Journal of Business Venturing (29:5), pp. 585-609. Bonaccorsi,  A.,  Giannangeli,  S.,  and  Rossi.,  C.    2006.    “Entry Strategies Under Competing Standards:  Hybrid Business Models in the Open Source Software Industry,” Management Science (52:7), pp. 1085-1098. Boudreau, K. J.  2010.  “Open Platform Strategies and Innovation:  Granting Access vs. Devolving Control,” Management Science (56:10), pp. 1849-1872. Brealey, R., Leland, H. E., and Pyle, D. H.  1977.  “Informational Asymmetries, Financial Structure, and Financial Intermediation,” The Journal of Finance (32:2), pp. 371-387. Burtch, G., Carnahan, S., and Greenwood, B.  2018.  “Can You Gig It?  An Empirical Examination of the Gig-Economy and Entre- preneurial  Activity,”  Management  Science  (64:12),  pp. 5497-5520. Burtch,  G.,  Ghose,  A.,  and  Wattal,  S.    2013.    “An  Empirical Examination of the Antecedents and Consequences of Contri- bution Patterns in Crowd-Funded Markets,” Information Systems Research (24:3), pp. 499-519. Burtch, G., Ghose, A., and Wattal, S. 2015.  “The Hidden Cost of Accommodating Crowdfunder Privacy Preferences:  A Random- ized Field Experiment,” Management Science (61:5), pp. 949-962. Burtch, G., Ghose, A., and Wattal, S.  2016.  “Secret Admirers:  An Empirical Examination of Information Hiding and Contribution Dynamics  in  Online  Crowdfunding,”  Information  Systems Research (27:3), pp. 478-496. Burtch, G., Hong, Y., and Liu, D.  2017.  “The Role of Provision Point in Online Crowdfunding,” Journal of Management Infor- mation Systems (35:1), pp. 117-144. Davenport, T. H., and Beck, J. C.  2001. The Attention Economy:  Understanding the New Currency of Business, Cambridge, MA:  Harvard Business Press.   Dellarocas, C., Katona, Z., and Rand, W.  2013.  “Media, Aggre- gators, and the Link Economy:  Strategic Hyperlink Formation in Content  Networks,”  Management  Science  (59:10),  pp. 2360-2379.   Fort, K., Adda, G., and Cohen, K.  B.  2011.  “Amazon Mechanical Turk:  Gold Mine or Coal Mine?,” Computational Linguistics (37:2), pp. 413-420. Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms Fournier, S., Eckhardt, G., and Bardhi, F.  2013.  “Learning to Play in the New ‘Share’ Economy,” Harvard Business Review (91:7), pp. 2701-2703. Gafni, H., Marom, D., and Sade, O.  2017.  “Are the Life and Death of an Early Stage Venture Indeed in the Power of the Tongue?  Lessons  from  Online  Crowdfunding  Pitches,”  Working  Paper (http://dx.doi.org/10.2139/ssrn.2255707). Gleasure, R., and Feller, J.  2016.  “Emerging Technologies and the Democratisation of Financial Services:  A Metatriangulation of Crowdfunding Research,” Information and Organization (26:4), pp. 101-115. Greenberg, M. D., Pardo, B., Hariharan, K., and Gerber, E.  2013.  “Crowdfunding Support Tools:  Predicting Success & Failure,” in CHI’13 Extended Abstracts on Human Factors in Computing Systems, New York:  ACM, pp. 1815-1820. Hildebrand,  T.,  Puri,  M.,  and  Rocholl,  J.    2016.    “Adverse Incentives in Crowdfunding,” Management Science (63:3), pp. 587-608. Howe, J.  2008.  Crowdsourcing:  How the Power of the Crowd Is Driving the Future of Business, New York:  Random House. Ibrahim,  D.  M.    2015.    “Equity  Crowdfunding:    A  Market  for Lemons?,” Minnesota Law Review (100:2), pp. 561-607. Inbar, Y., and Barzilay, O.  2014.  “Estimating Community Impact on  Crowdfunding  Performance:    A  Granularity-Driven  Ap- proach,”  paper  presented  at  the  Workshop  in  Information Systems and Economics. Ipeirotis,  P.  G.,  and  Paritosh,  P.  K.    2011.    “Managing  Crowd- sourced Human Computation:  A Tutorial,” in Proceedings of the 20th International Conference Companion on World Wide Web, New York:  ACM, pp.  287-288. Iyengar, S. S, Huberman, G., and Jiang, W., 2004.  “How Much Choice  Is  Too  Much?    Contributions  to  401(k)  Retirement Plans,” in Pension Design and Structure:  New Lessons from Behavioral  Finance,  O.  S.  Mitchell  and  S.  P.  Utkus  (eds.), Oxford, UK:  Oxford University Press, pp.84-87. Iyengar,  S.  S.,  and  Lepper,  M.  R.    2000.    “When  Choice  Is Demotivating:  Can One Desire Too Much of a Good Thing?,” Journal  of  Personality  and  Social  Psychology  (79:6),  pp. 995-1006. Kim, K., Park, J., Pan, Y., Zhang, K., and Zhang X.  2019.  “Risk Disclosure in Crowdfunding,” SSRN (http://dx.doi.org/10.2139/ srn.2942685). Kim, K., and Viswanathan, S.  2019.  “The Experts in the Crowd:  The Role of Expert Investors in a Crowdfunding Market,” MIS Quarterly (43:2), pp. 347-372. Kirmani, A., and Rao, A. R., 2000.  “No Pain, No Gain:  A Critical Review  of  the  Literature  on  Signaling  Unobservable  Product Quality,” Journal of Marketing (64:2), pp. 66-79. Krumme, K., and Herrero, S.  2009.  “Lending Behavior and Com- munity Structure in an Online Peer-to-Peer Economic Network,” in Proceedings of the 12th International Conference on Computa- tional  Science  and  Engineering,  Washington,  DC:    IEEE Computer Society, pp. 613-618. Kuppuswamy, V., and Bayus, B. L.  2015.  “Crowdfunding Creative Ideas:    The  Dynamics  of  Project  Backers  in  Kickstarter,” University of North Carolina Kenan-Flagler Research Paper No.  2013-15. Lipowski, Z. J.  1970.  “The Conflict of Buridan’s Ass or Some Dilemmas  of  Affluence:    The  Theory  of  Attractive  Stimulus Overload,” American Journal of Psychiatry (127:3), pp. 49-55. Lin, M., Prabhala, N. R., and Viswanathan, S.  2013.  “Judging Borrowers by the Company They Keep:  Friendship Networks and Information Asymmetry in Online Peer-to-Peer Lending,” Management Science (59:1), pp. 17-35. Liu, J., Yang, L., Wang, Z., and Hahn, J.  2015.  “Winner Takes All?  The  ‘Blockbuster  Effect’  in  Crowdfunding  Platforms,”  in Proceedings of the 36th International Conference on Information Systems, Fort Worth, TX.   Marom, D., Robb, A., and Sade, O.  2016.  “Gender Dynamics in Crowdfunding (Kickstarter):  Evidence on Entrepreneurs, Inves- tors,  Deals  and  Taste-based  Discrimination,”  Working  Paper (https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2442954). Modig,  E.,  Dahlén,  M.,  and  Colliander,  J.    2014.    “Consumer- Perceived Signals of ‘Creative’ Versus ‘Efficient’ Advertising:  Investigating  the  Roles  of  Expense and Effort,”  International Journal of Advertising (33:1), pp. 137-154. Mollick, E.  R.  2013.  “Swept Away by the Crowd?  Crowdfunding, Venture Capital, and the Selection of Entrepreneurs,” Working Paper, Wharton School, University of Pennsylvania Mollick, E.  2014.  “The Dynamics of Crowdfunding:  An Explora- tory Study,” Journal of Business Venturing (29:1), pp. 1-16. Niculescu, M. F., Wu, D. J., and Xu, L.  2018.  “Strategic Intellec- tual  Property  Sharing:    Competition  on  an  Open  Technology Platform Under Network Effects.” Information Systems Research (29:2), pp. 498-519. Overby, E., Slaughter, S.  A., and Konsynski, B.  2010.  “Research Commentary—The Design, Use, and Consequences of Virtual Processes,” Information Systems Research (21:4), pp. 700-710. Packalen, K.  2007.  “Complementing Capital:  The Role of Status, Demographic Features, and Social Capital in Founding Teams’ Abilities to Obtain Resources,” Entrepreneurship Theory and Practice (31:6), pp. 837-891. Rhue, L.  2015.  “Who Gets Started on Kickstarter?  Demographic Variations in Fundraising Success,” Research-in-Progress Paper, in  Proceedings  of  the  36th  International  Conference  on Information Systems, Fort Worth, TX Sahoo, N., Krishnan, R., Duncan, G., and Callan, J.  2012.  “Research Note—The  Halo  Effect  in  Multicomponent  Ratings  and  Its Implications  for  Recommender  Systems:    The  Case  of  Yahoo! Movies,” Information Systems Research (23:1), pp. 231-246. Scheibehenne, B., Greifeneder, R., and Todd, P. M.  2010.  “Can There Ever Be Too Many Options?  A Meta-analytic Review of Choice Overload,” Journal of Consumer Research (37:3), pp. 409-425. Schlosser, A. E., White, T. B., and Lloyd, S. M.  2006.  “Converting Web  Site  Visitors  into  Buyers:    How  Web  Site  Investment Increases  Consumer  Trusting  Beliefs  and  Online  Purchase Intentions,” Journal of Marketing (70:2), pp. 133-148. Schwartz, B., 2004.  The Paradox of Choice:  Why More Is Less, New York:  Harper Perennial. Shankar, V., and Bayus, B. L.  2003.  “Network Effects and Compe- tition:    An  Empirical  Analysis  of  the  Home  Video  Game Industry,” Strategic Management Journal (24:4), pp. 375-384. Spence, M.  1973.  “Job Market Signaling,” The Quarterly Journal of Economics (87:3), pp. 355-374. MIS Quarterly Vol. 43 No. 4/December 2019 1247 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms Stuart, T. E., Hoang, H., and Hybels, R. C.  1999.  “Interorgani- zational Endorsements and the Performance of Entrepreneurial Ventures,” Administrative Science Quarterly (44:2), pp. 315-349. Sundararajan, A.  2013.  “From Zipcar to the Sharing Economy,” Harvard Business Review (https://hbr.org/2013/01/from-zipcar- to-the-sharing-eco). Thies, F., Wessel, M., and Benlian, A.  2014.  “Understanding the Dynamic Interplay of Social Buzz and Contribution Behavior Within and Between Online Platforms-Evidence from Crowd- funding,” in Proceedings of the 35th International Conference on Information Systems, Auckland, New Zealand. Tiwana,  A.,  Konsynski,  B.,  and  Bush,  A.  A.    2010.    “Research Commentary—Platform  Evolution:    Coevolution  of  Platform Architecture,  Governance,  and  Environmental  Dynamics,” Information Systems Research (21:4), pp. 675-687. Tomboc, G. F. B.  2013.  “Lemons Problem in Crowdfunding,” The John Marshall Journal of Information Technology & Privacy Law (30:2), pp. 253-279. Unger, J. M.,  Rauch, A., Frese, M.,  and Rosenbusch, N.  2011.  “Human Capital and Entrepreneurial Success:  A Meta-Analytical Review,” Journal of Business Venturing (26:3), pp. 341-358. Vesterlund,  L.    2003.    “The  Informational  Value  of  Sequential Fundraising,” Journal of Public Economics (87:3), pp. 627-657. Wessel, M., Thies, F., and Benlian, A.  2015.  “The Effects of Relin- quishing Control in Platform Ecosystems:  Implications from a Policy Change on Kickstarter,” in Proceedings of the 36th Inter- national Conference on Information Systems, Fort Worth, TX. Younkin, P., and Kuppuswamy, V.  2016.  “The Colorblind Crowd?  Founder Race and Performance in Crowdfunding,” Management Science (64:7), pp. 3269-3287). Zhang,  J.,  and  Liu,  P.    2012.    “Rational  Herding  in  Microloan Markets,” Management Science (58:5), pp. 892-912 Zvilichovsky, D., Inbar, Y., and Barzilay, O.  2013.  “Playing Both Sides of the Market:  Success and Reciprocity on Crowdfunding Platforms,” in Proceedings of the 34th International Conference on Information Systems, Milan, Italy. About the Authors Hilah Geva is a Ph.D. student in the Department of Management of Information and Technology at the Coller School of Management at Tel  Aviv  University.    Hilah  hold  a  B.Sc.  (magna  cum  laude)  in Computer Science and Cognitive Science from the Hebrew University of Jerusalem and an M.A. (summa cum laude) in Philosophy from Tel-Aviv University.  In her research Hilah focuses on the effects of branding and signaling in online social and economic platforms. Ohad Barzilay is an assistant professor of information and tech- nology management in the Coller School of Management in Tel Aviv University.  Ohad holds a Ph.D. in Computer Science, and he studies the economics of digital platforms, electronic markets, and crowdfunding.    His  studies  are  supported  by  the  Israeli  Science Foundation, the Collet Foundation, and the Blavatnik Interdisci- plinary Center for Cyber Research.  Ohad also served at the Israeli Chief Scientist Office at the Ministry of Economy at the committee for incubator and early stage company funding. Gal Oestreicher-Singer is a professor of Management of Infor- mation and Technology at the Coller School of Management at Tel Aviv University in Israel.  She also heads the school’s Management of Information and Technology group.  She received her Ph.D. from the Stern School of Business at New York University.  Her research focuses on the effects of social media, consumer engagement, and peer influence on electronic commerce outcomes and on the business models of content websites.  Her work has been published in the top journals in the fields of both Information Systems and Marketing.  She currently serves as a senior editor at MIS Quarterly.  She has also been the recipient of several prestigious grants and awards, most recently the ERC grant. 1248 MIS Quarterly Vol. 43 No. 4/December 2019 RESEARCH ARTICLE A POTATO SALAD WITH A LEMON TWIST:  USING A SUPPLY- SIDE SHOCK TO STUDY THE IMPACT OF OPPORTUNISTIC BEHAVIOR ON CROWDFUNDING PLATFORMS Hilah Geva, Ohad Barzilay, and Gal Oestreicher-Singer Coller School of Management, Tel-Aviv University, Ramat Aviv, Tel Aviv 69978 ISRAEL {hilahlev@mail.tau.ac.il}  {ohadbr@tau.ac.il}  {galos@post.tau.au.il} Appendix A Deriving Quality Measures We have made an effort and have taken one step further to enrich our variable set to gain a more comprehensive and accurate measurement of campaign quality.  In the spirit of prior work, we consider the extent to which the entrepreneur has invested effort and resources in the campaign, and the level of professionalism of the entrepreneur. Mollick (2013) has suggested that venture capitalists and crowdfunders assess entrepreneurial quality in similar ways.  Specifically, both ultimately act to rationally assess project quality, of which the entrepreneur’s level of preparation is a key indicator.  Thus, Mollick hypothesizes that entrepreneurs who demonstrate more preparedness are more likely to be funded.  We suggest that, in the domain of crowdfunding, entrepreneurial preparation is manifested in the effort and resources invested by the entrepreneur in preparation for launching a campaign.  Additionally, marketing literature suggests that potential consumers take sellers’ (perceived) effort and expense into account (Modig et al. 2014).  In the context of crowdfunding, we can assume that consumers are literate enough to deduce the levels of expense and effort invested by the seller, and use them to infer whether the product is of better quality.   Thus, to measure potential backers’ perceptions of such investment, we focused on the following campaign attributes, which a potential backer can deduce from viewing a campaign's page. • Money spent by the entrepreneur before launching the campaign (Q4 in Table 2 in the paper). • • Time and effort spent in creating the campaign page (Q1 and Q3 in Table 2, respectively). Careful planning of the reward structure (Q6 in Table 2).  This may indicate the level of detail in which the product or service was planned, and the consideration that the campaign creator has given to what is feasible to promise. We further draw from literature showing that potential consumers use website design as a manifestation of the seller's ability, and that this assessment in turn impacts their online purchase intentions (Schlosser et al. 2006).  Thus, in addition to Q3, which captures the effort invested by the entrepreneur in designing the campaign page, we also asked about:   • • The level of professionalism of the design of the campaign page (Q2 in Table 2).  The use of an additional website outside of Kickstarter domain (Q5 in Table 2).   Human capital is associated with entrepreneurial success and quality (Ahlers et al. 2015; Unger et al. 2011).  However, the operationalization of human capital may be challenging within the context of Kickstarter, owing to the diversity of campaign categories, which range from art and food to design and technology.  For example, for entrepreneurs in the technology category, an academic degree may provide a strong MIS Quarterly Vol. 43 No. 4—Appendices/December 2019 A1 Doms, M., Lewis, E., and Robb, A.  2010.  “Local Labor Force Education, New Business Characteristics, and Firm Performance,”  Journal Levie, J., and Gimmon, E.  2008.  “Mixed Signals:  Why Investors May Misjudge First Time High Technology Venture Founders,” Venture Practice (39:4), pp. 955-980. of Urban Economics (67:1), pp. 61-77. Capital (10:3), pp. 233-256. Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms indication of “high” human capital (Doms et al. 2010; Levie and Gimmon 2008).  However, a degree may be less useful as an indication of the quality of a dance act.  Hence, in building our quality measurements, we directly asked evaluators to rank the (perceived) professionalism of the entrepreneurs in the field in which they operate (Q7 in Table 2).  Again, assuming that the evaluators are not very different from the average Kickstarter backer, the answers will provide insights into the degree to which the campaign page signals professionalism within the context of the specific campaign category. References Ahlers, G. K., Cumming, D., Günther, C., and Schweizer, D.  2015.  “Signaling in Equity Crowdfunding,” Entrepreneurship Theory and Modig, E., Dahlén, M., and Colliander, J.  2014.  “Consumer-Perceived Signals of ‘Creative’ Versus ‘Efficient’ Advertising:  Investigating the Roles of Expense and Effort,” International Journal of Advertising (33:1), pp. 137-154. Mollick, E.  R.  2013.  “Swept Away by the Crowd?  Crowdfunding, Venture Capital, and the Selection of Entrepreneurs,” Working Paper, Wharton School, University of Pennsylvania. Schlosser, A. E., White, T. B., and Lloyd, S. M.  2006.  “Converting Web Site Visitors into Buyers:  How Web Site Investment Increases Consumer Trusting Beliefs and Online Purchase Intentions,” Journal of Marketing (70:2), pp. 133-148. Unger, J. M., Rauch, A., Frese, M., and Rosenbusch, N.  2011.  “Human Capital and Entrepreneurial Success:  A Meta-Analytical Review,” Journal of Business Venturing (26:3), pp. 341-358. Appendix B Additional Supply Shocks Our paper investigates the effects of a sharp increase in low-quality competition using one media shock that brought about a unique state on the Kickstarter platform.  Specifically, following the shock, the supply on the platform (i.e., the number of campaigns offered) grew sub- stantially, whereas the demand did not change significantly.  To provide further robustness to our results, we searched for additional situations on Kickstarter in which supply increased sharply with no significant effect on demand.  To this end, we identified dates in the platform’s history on which spikes in supply occurred.  We defined a “spike” as a day on which the number of campaigns launched was two standard deviations higher than the average number of campaigns launched in the days of the preceding two months.  When searching for such dates we used data collected about all campaigns that were launched after June 3, 2014, when Kickstarter implemented a policy that lowered the entry barriers for new campaigns, and before May 2015.  This dataset contained 75,872 campaigns.  We identified eight events (unique days) in which there was a substantial increase in supply.  These events took place on the following dates:  January 20, 2015; January 21, 2015; January 26, 2015; January 27, 2015; February 2, 2015; February 9, 2015; February 17, 2015; and March 2, 2015.  However, none of those events possessed the required characteristics.  As can be observed, there was substantial overlap between the dates surrounding the different events.  Thus, we could not correctly distinguish the demand in the weeks prior to each shock from the demand in the weeks following each shock, seeing as those weeks were influenced not only by the current shock being evaluated but most likely by other shocks as well. A2 MIS Quarterly Vol. 43 No. 4—Appendices/December 2019 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms Appendix C Illustration of Time Proximity Identification Method Figure C1.  Illustration of Time Proximity Identification Method Appendix D PSM Identification:  Balancing Tests for H2 Our matching was not performed on the variable QualityPca, but rather on the individual variables attributed to quality, as well as additional campaign characteristics.  Thus we had to make sure that, for each low- and high-quality subsample (created by QualityBinary), QualityPca was balanced between the “before” and “after” groups.  We tested this using both the Mann-Whitney rank test and the Wilcoxon rank-sum test.  The results in Table D1 show that QualityPca was balanced for both the low-quality subsample and the high-quality subsample. Table D1.  Balancing Test of QualityPca Between “Before” and “After” Campaigns Low quality  High quality  Mann-Whitney Rank Test Wilcoxon Rank-Sum Test Statistic = 115996 ; p = 0.79 Statistic = 114845 ; p = 0.99 Statistic = 0.25 ; p = 0.79 Statistic = -0.01; p = 0.99 Appendix E Interpretation of Coefficients and Economic Effects In this appendix, we provide details about the calculation of the economic impacts reported in the paper.  We first provide the calculations for all regression analyses in which a campaign’s likelihood of success (IsSuccessful) was the dependent variable.  Then we provide calculations for all regression analyses in which the amount pledged (lnAmountPledged) was the dependent variable.  For each performance variable, we first present the regressions estimated using the time proximity identification, and then those estimated using the PSM identification. For convenience of presentation, in what follows, the variable notation DaysFromShockDay has been shortened to days, IsSuccessful has been shortened to success, and AmountPledged has been changed to pledged. MIS Quarterly Vol. 43 No. 4—Appendices/December 2019 A3 Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms      Logistic Regressions Focusing on the Success Rate    Time Proximity Identification:    (a)  Effect of ln(days) on success, no interaction term    Let success be the binary outcome variable indicating failure/success with 0/1, and let p be the probability of success to be 1, p =  prob(success=1). Let ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑), and X2 … Xk be a set of predictor variables. Then the logistic regression of success on ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)  logit(p) = log(p/(1-p))= β0 + β1*ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑) + … + βk*Xk  and X2 … Xk estimates parameter values for β0, β1, …, βk using the following equation.        All else being held equal, if days increases by 10%, that is, by a factor of 1.1, then:    𝑝𝑝1−𝑝𝑝= 𝑒𝑒𝛽𝛽0+ 𝛽𝛽1ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)+ 𝛽𝛽2:𝑘𝑘𝑿𝑿=𝑒𝑒𝛽𝛽0(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝛽𝛽1𝑒𝑒𝛽𝛽2:𝑘𝑘𝑿𝑿  𝑝𝑝1−𝑝𝑝= 𝑒𝑒𝛽𝛽0(1.1𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝛽𝛽1𝑒𝑒𝛽𝛽2:𝑘𝑘𝑿𝑿=𝑒𝑒𝛽𝛽0(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝛽𝛽1𝑒𝑒𝛽𝛽2:𝑘𝑘𝑿𝑿(𝟏𝟏.𝟏𝟏)𝜷𝜷𝟏𝟏  (b)  Effect of ln(days) on success, with binary interaction term      Continuing with the logic above, we examine the following equation:      All else being held equal, when QualityBinary = 0 then:    That is, all else being held equal, for a 10% increase in days the odds of being successful change by a factor of (𝟏𝟏.𝟏𝟏)𝜷𝜷𝟏𝟏   For our data this means that for a 10% increase in days, the odds of being successful increase by a factor of (1.1)0.155 = 1.0149  when controlling for QualityPca and by a factor of (1.1)0.16= 1.0154 when controlling for QualityBinary.  logit(p) = log(p/(1-p))= 𝛽𝛽0+ 𝛽𝛽1ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)+ 𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑+ 𝛽𝛽3ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑+ 𝛽𝛽4:𝑘𝑘𝑿𝑿  𝑝𝑝1−𝑝𝑝= 𝑒𝑒𝛽𝛽0+ 𝛽𝛽1ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)+ 𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑+ 𝛽𝛽3ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑 + 𝛽𝛽4:𝑘𝑘𝑿𝑿 =𝑒𝑒𝛽𝛽0(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝛽𝛽1𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑𝑒𝑒𝛽𝛽3ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  [ 𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=0]= 𝑒𝑒𝛽𝛽0(𝒅𝒅𝒅𝒅𝒅𝒅𝒅𝒅)𝜷𝜷𝟏𝟏𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿    That is, all else being held equal, when considering low-quality campaigns, a 10% increase (that is an increase by a factor of 1.1)  in days changes the odds of being successful by a factor of (𝟏𝟏.𝟏𝟏)𝜷𝜷𝟏𝟏.  [ 𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=1]= 𝑒𝑒𝛽𝛽0(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝛽𝛽1𝑒𝑒𝛽𝛽2𝑒𝑒𝛽𝛽3ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿=𝑒𝑒𝛽𝛽0+𝛽𝛽2(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝛽𝛽1(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝛽𝛽3𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿=  successful by a factor of (𝟏𝟏.𝟏𝟏)𝜷𝜷𝟏𝟏+𝜷𝜷𝟑𝟑  For our data this means that for low-quality campaigns, the odds of being successful increase by a factor of (𝟏𝟏.𝟏𝟏)𝟎𝟎.𝟑𝟑𝟎𝟎𝟑𝟑 = 1.03 for  (𝟏𝟏.𝟏𝟏)𝟎𝟎.𝟑𝟑𝟎𝟎𝟑𝟑−𝟎𝟎.𝟐𝟐𝟐𝟐𝟐𝟐 =1.006.    That is, all else being held equal, when considering high-quality campaigns, a 10% increase in days changes the odds of being    All else being held equal, when QualityBinary = 1 then:    a 10% increase in the distance from the shock. In contrast, for high-quality campaigns the odds increase by a factor of  𝑒𝑒𝛽𝛽0+𝛽𝛽2(𝒅𝒅𝒅𝒅𝒅𝒅𝒅𝒅)𝜷𝜷𝟏𝟏+𝜷𝜷𝟑𝟑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿                A4    MIS Quarterly Vol. 43 No. 4‒Appendix/December 2019  Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms      Matching:                (a)  Effect of before on success, no interaction term  All else being held equal, when QualityBinary = 0 then:      All else being held equal, when QualityBinary = 1 then:    logit(p) = log(p/(1−p))= 𝛽𝛽0+ 𝛽𝛽1𝑏𝑏𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒+ 𝛽𝛽2:𝑘𝑘𝑿𝑿    𝑝𝑝1−𝑝𝑝= 𝑒𝑒𝛽𝛽0+ 𝛽𝛽1𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏+ 𝛽𝛽2:𝑘𝑘𝑿𝑿  𝑝𝑝1−𝑝𝑝= 𝑒𝑒𝛽𝛽0+ 𝛽𝛽1𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏+ 𝛽𝛽2:𝑘𝑘𝑿𝑿=𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒𝛽𝛽2:𝑘𝑘𝑿𝑿  [ 𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0]= 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  [ 𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1]= 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 =𝑒𝑒𝛽𝛽1→[ 𝑝𝑝1−𝑝𝑝�𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1]=[ 𝑝𝑝1−𝑝𝑝�𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0]∗𝒆𝒆𝜷𝜷𝟏𝟏   𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1 𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0=𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 (b)  Effect of before on success, with binary interaction term    This means that, all else being held equal, launching a campaign before the shock changes the odds of being successful by a    For our data, this means, that that the odds that a campaign launched before the shock will succeed are greater by a factor of  factor of 𝒆𝒆𝜷𝜷𝟏𝟏.  𝒆𝒆0.276=1.3 compared with the odds that a (similar) campaign launched after the shock will succeed.  logit(p) = log(p/(1−p))= 𝛽𝛽0+ 𝛽𝛽1𝑏𝑏𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒+𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑+ 𝛽𝛽3𝑏𝑏𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒∗𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑+ 𝛽𝛽2:𝑘𝑘𝑿𝑿  𝑝𝑝1−𝑝𝑝= 𝑒𝑒𝛽𝛽0+ 𝛽𝛽1𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏+𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑+ 𝛽𝛽3𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏∗𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑+ 𝛽𝛽4:𝑘𝑘𝑿𝑿  =𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑𝑒𝑒𝛽𝛽3𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏∗𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿    All else being held equal, when before = 0 and QualityBinary = 0 then:      All else being held equal, when before = 1 and QualityBinary = 0 then:      All else being held equal, when before = 0 and QualityBinary = 1 then:    [ 𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0;𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=0] = 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  [ 𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1;𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=0]= 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  [ 𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0;𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=1]= 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽2𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  [ 𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1;𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=1]= 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽2𝑒𝑒𝛽𝛽3𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿    All else being held equal, when before = 1 and QualityBinary = 1 then:      When considering low-quality campaigns (QualityBinary = 0):    MIS Quarterly Vol. 43 No. 4‒Appendix/December 2019     A5  Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms      𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1;𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=0 𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0;𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=0=𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 =𝑒𝑒𝛽𝛽1   𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1;𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=1 𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0;𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=1=𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽2𝑒𝑒𝛽𝛽3𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽2𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 =𝑒𝑒𝛽𝛽1𝒆𝒆𝜷𝜷𝟑𝟑     When considering high-quality campaigns (QualityBinary = 1):    𝒆𝒆𝜷𝜷𝟏𝟏.        That is, when considering low-quality campaigns, being a  “before” campaign changes the odds of being successful by a factor of    That is, when considering high-quality campaigns, launching a campaign before the shock changes the odds of being successful  by a factor of  𝒆𝒆𝜷𝜷𝟏𝟏+𝜷𝜷𝟑𝟑. Additionally, this means that compared to the change in low-quality campaigns, the effect of before on the  odds to succeed differs by a factor of 𝒆𝒆𝜷𝜷𝟑𝟑.  For our data this means that for a low-quality campaign, the odds of being successful increase by a factor of 𝒆𝒆0.511 = 1.67 if the  campaign is launched before the shock, whereas for a high-quality campaign the odds increase only by a factor of 𝑒𝑒𝟎𝟎.𝟑𝟑𝟏𝟏𝟏𝟏−𝟎𝟎.𝟐𝟐𝟎𝟎𝟑𝟑 =      1.11.    (c)  Effect of before on success, with continuous interaction term  logit(p) = log(p/(1−p))= 𝛽𝛽0+ 𝛽𝛽1𝑏𝑏𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒+𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑+ 𝛽𝛽3𝑏𝑏𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒∗𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑑𝑑+ 𝛽𝛽2:𝑘𝑘𝑿𝑿  𝑝𝑝1−𝑝𝑝= 𝑒𝑒𝛽𝛽0+ 𝛽𝛽1𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏+𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑+ 𝛽𝛽3𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏∗𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑑𝑑+ 𝛽𝛽4:𝑘𝑘𝑿𝑿  =𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽3𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏∗𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿    All else being held equal, when before = 0 then:      All else being held equal, when before = 1 then:    [ 𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0] = 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  [ 𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1]= 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽3𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1 𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0=𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽3𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1 𝑝𝑝1−𝑝𝑝|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0=𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑑𝑑+1𝑒𝑒𝛽𝛽3𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑑𝑑+1𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 =𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽3𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑑𝑑𝒆𝒆𝜷𝜷𝟑𝟑  factor of 𝒆𝒆𝜷𝜷𝟑𝟑.   effect of being before the shock by a factor of 𝒆𝒆−0.120=𝟎𝟎.𝟖𝟖𝟖𝟖𝟖𝟖. That is, as the quality increases the effect of being before the    That is, for a 1-unit increase in quality, the ratio between the odds of being successful before and after equals:       For our data, this means that when observing the effect on the odds to succeed, a 1-unit increase in QualityPca decreases the  =𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽3(𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑑𝑑+1)= 𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽3𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑑𝑑+𝛽𝛽3   This means that for a 1-unit increase in the quality, the ratio between the odds of being successful before and after changes by a  =𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽3𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑑𝑑   𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 shock decreases. That is, high quality campaigns are less affected.           A6    MIS Quarterly Vol. 43 No. 4‒Appendix/December 2019      OLS Regressions Focusing on the Amount of Money Pledged    Time Proximity Identification:    Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms        (a)  Effect of ln(days) on ln(pledged), no interaction term    All else being held equal, if days increases by 10%, that is, by 1.1, then:    𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑= 𝑒𝑒𝛽𝛽0(1.1𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝛽𝛽1𝑒𝑒𝛽𝛽2:𝑘𝑘𝑿𝑿=𝑒𝑒𝛽𝛽0(𝟏𝟏.𝟏𝟏)𝜷𝜷𝟏𝟏(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝛽𝛽1𝑒𝑒𝛽𝛽2:𝑘𝑘𝑿𝑿  ln(𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑)= 𝛽𝛽0+ 𝛽𝛽1ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)+ 𝛽𝛽2:𝑘𝑘𝑿𝑿  𝑒𝑒ln(𝑝𝑝𝑞𝑞𝑏𝑏𝑑𝑑𝑝𝑝𝑏𝑏𝑑𝑑)= 𝑒𝑒𝛽𝛽0+ 𝛽𝛽1ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)+ 𝛽𝛽2:𝑘𝑘𝑿𝑿  𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑= 𝑒𝑒𝛽𝛽0+ 𝛽𝛽1ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)+ 𝛽𝛽2:𝑘𝑘𝑿𝑿=𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝑒𝑒𝛽𝛽2:𝑘𝑘𝑿𝑿=𝑒𝑒𝛽𝛽0(𝑒𝑒(ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)))𝛽𝛽1𝑒𝑒𝛽𝛽2:𝑘𝑘𝑿𝑿=𝑒𝑒𝛽𝛽0(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝛽𝛽1𝑒𝑒𝛽𝛽2:𝑘𝑘𝑿𝑿  That is, all else being held equal, for a 10% increase in days, the amount of money pledged increases by (𝟏𝟏.𝟏𝟏)𝜷𝜷𝟏𝟏.  For our data this means that for a 10% increase in distance from the shock, we see an increase by a factor of (1.1)0.143= 1.014 when controlling for QualityPca and by a factor of (1.1)0.18= 1.017 when controlling for QualityBinary. In other words,  If we consider a 50% increase in distance from the shock, we see an increase by a factor of (1.5)0.143=1.06   - (1.5)0.18=  (b)  Effect of ln(days) on ln(𝒑𝒑𝒑𝒑𝒆𝒆𝒅𝒅𝒑𝒑𝒆𝒆𝒅𝒅) with interaction term  1.076, that is, an increase of  6-7.6% in the average amount pledged.     we see an increase of 1.4-1.7% in the average amount pledged.         ln(𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑)= 𝛽𝛽0+ 𝛽𝛽1ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)+ 𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑+ 𝛽𝛽3ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑 + 𝛽𝛽4:𝑘𝑘𝑿𝑿  𝑒𝑒ln(𝑝𝑝𝑞𝑞𝑏𝑏𝑑𝑑𝑝𝑝𝑏𝑏𝑑𝑑)= 𝑒𝑒𝛽𝛽0+ 𝛽𝛽1ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)+ 𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑+ 𝛽𝛽3ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑 + 𝛽𝛽4:𝑘𝑘𝑿𝑿  𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑= 𝑒𝑒𝛽𝛽0+ 𝛽𝛽1ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)+ 𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑+ 𝛽𝛽3ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑 + 𝛽𝛽4:𝑘𝑘𝑿𝑿 =𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑𝑒𝑒𝛽𝛽3ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)∗𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 =𝑒𝑒𝛽𝛽0(𝑒𝑒(ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)))𝛽𝛽1𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑𝑒𝑒𝛽𝛽3ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 =𝑒𝑒𝛽𝛽0(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝛽𝛽1𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑𝑒𝑒𝛽𝛽3ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=0= 𝑒𝑒𝛽𝛽0(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝛽𝛽1𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿    All else being held equal, when QualityBinary = 0 then:      That is, all else being held equal, for a 10% increase in days, the amount of money pledged to low-quality campaigns increases  by a factor of (𝟏𝟏.𝟏𝟏)𝜷𝜷𝟏𝟏.    All else being held equal, when QualityBinary = 1 then:      For our data this means that for low-quality campaigns a 10% increase in distance from the shock is expected to yield an increase    That is, all else being held equal, for a 10% increase in days, the amount of money pledged to high-quality campaigns increases  𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=1= 𝑒𝑒𝛽𝛽0(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝛽𝛽1𝑒𝑒𝛽𝛽2𝑒𝑒𝛽𝛽3ln(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿=𝑒𝑒𝛽𝛽0+𝛽𝛽2(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝛽𝛽1(𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑)𝛽𝛽3𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿=  𝑒𝑒𝛽𝛽0+𝛽𝛽2(𝒅𝒅𝒅𝒅𝒅𝒅𝒅𝒅)𝜷𝜷𝟏𝟏+𝜷𝜷𝟑𝟑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  by a factor of (𝟏𝟏.𝟏𝟏)𝜷𝜷𝟏𝟏+𝜷𝜷𝟑𝟑.  by a factor of (1.1)0.265= 𝟏𝟏.𝟎𝟎𝟐𝟐𝟎𝟎 (2.6%), whereas for high-quality campaigns a 10% increase in distance is expected to yield  only a (1.1)0.265−0.192 =𝟏𝟏.𝟎𝟎𝟎𝟎𝟖𝟖 (0.7%) increase in the amount pledged.   (a)  Effect of before on ln(𝒑𝒑𝒑𝒑𝒆𝒆𝒅𝒅𝒑𝒑𝒆𝒆𝒅𝒅), no interaction term  ln(𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑)= 𝛽𝛽0+ 𝛽𝛽1𝑏𝑏𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒+ 𝛽𝛽2:𝑘𝑘𝑿𝑿  𝑒𝑒ln(𝑝𝑝𝑞𝑞𝑏𝑏𝑑𝑑𝑝𝑝𝑏𝑏𝑑𝑑)= 𝑒𝑒𝛽𝛽0+ 𝛽𝛽1𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏+ 𝛽𝛽2:𝑘𝑘𝑿𝑿  𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑= 𝑒𝑒𝛽𝛽0+ 𝛽𝛽1𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏+ 𝛽𝛽2:𝑘𝑘𝑿𝑿=𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒𝛽𝛽2:𝑘𝑘𝑿𝑿      Matching:    MIS Quarterly Vol. 43 No. 4‒Appendix/December 2019     A7  Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms      All else being held equal, when QualityBinary = 0 then:      All else being held equal, when QualityBinary = 1 then:      These results mean that, all else being held equal, being a “before” campaign increases the amount of money pledged by a factor  controlling for QualityPca) compared with those of (similar) campaigns launched after the shock (when controlling for    All else being held equal, when before = 0 and QualityBinary = 0 then:    𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0=𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1 𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0= 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1= 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 =𝑒𝑒𝛽𝛽1→[𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1]=[𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0]∗𝑒𝑒𝛽𝛽1   of 𝒆𝒆𝜷𝜷𝟏𝟏.  For our data, this means that the odds of a “before” campaign succeeding are greater by a factor of 𝒆𝒆0.310=1.36 (when  QualityBinary we see an increase by a factor of 𝒆𝒆0.360=1.43).  (b)  Effect of before on ln(𝒑𝒑𝒑𝒑𝒆𝒆𝒅𝒅𝒑𝒑𝒆𝒆𝒅𝒅), with binary interaction term  ln(𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑)= 𝛽𝛽0+ 𝛽𝛽1𝑏𝑏𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒+𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑+ 𝛽𝛽3𝑏𝑏𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒∗𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑+ 𝛽𝛽2:𝑘𝑘𝑿𝑿  𝑒𝑒ln(𝑝𝑝𝑞𝑞𝑏𝑏𝑑𝑑𝑝𝑝𝑏𝑏𝑑𝑑)= 𝑒𝑒𝛽𝛽0+ 𝛽𝛽1𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏+𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑+ 𝛽𝛽3𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏∗𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑+ 𝛽𝛽4:𝑘𝑘𝑿𝑿  𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑= 𝑒𝑒𝛽𝛽0+ 𝛽𝛽1𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏+𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑+ 𝛽𝛽3𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏∗𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑+ 𝛽𝛽4:𝑘𝑘𝑿𝑿 =𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑𝑒𝑒𝛽𝛽3𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏∗𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑏𝑏𝑏𝑏𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  [𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0;𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=0] = 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  [𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1;𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=0]= 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  [𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0;𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=1]= 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽2𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  [𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1;𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=1]= 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽2𝑒𝑒𝛽𝛽3𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1;𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=0 𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0;𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=0=𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 =𝑒𝑒𝛽𝛽1   𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0;𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=1=𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽2𝑒𝑒𝛽𝛽3𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1;𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑏𝑏𝑞𝑞𝑏𝑏𝑑𝑑𝑏𝑏𝑑𝑑=1 =𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽3   𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽2𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 That is, for high-quality campaigns, being a “before” campaign increases the average amount pledged by a factor of  𝒆𝒆𝜷𝜷𝟏𝟏+𝜷𝜷𝟑𝟑.  pledged to high-quality campaigns is greater by a factor of 𝒆𝒆𝜷𝜷𝟑𝟑.  That is, for low-quality campaigns, being a “before” campaign increases the average amount pledged by a factor of  𝒆𝒆𝜷𝜷𝟏𝟏.    All else being held equal, when before = 0 and QualityBinary = 1 then:      All else being held equal, when before = 1 and QualityBinary = 0 then:      All else being held equal, when before = 1 and QualityBinary = 1 then:      When considering low-quality campaigns (QualityBinary = 0):      When considering high-quality campaigns (QualityBinary=1):    Additionally, this means that when compared to the increase in low quality campaigns, the effect of before on the amount                  A8    MIS Quarterly Vol. 43 No. 4‒Appendix/December 2019  For our data this means that for low-quality campaigns, being a “before” campaign increases the amount of money pledged by a  Geva et al./The Impact of Opportunistic Behavior on Crowdfunding Platforms    All else being held equal, when before = 0 then:        All else being held equal, when before = 1 then:    factor of 𝒆𝒆0.621 = 1.86, whereas for high-quality campaigns, being a “before” campaign increases the amount of money pledged  by a factor of only 𝑒𝑒𝟎𝟎.𝟎𝟎𝟐𝟐𝟏𝟏−𝟎𝟎.𝟑𝟑𝟐𝟐𝟖𝟖 =1.10.  (c)  Effect of before on ln(𝒑𝒑𝒑𝒑𝒆𝒆𝒅𝒅𝒑𝒑𝒆𝒆𝒅𝒅), with a continuous interaction term  ln(𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑)= 𝛽𝛽0+ 𝛽𝛽1𝑏𝑏𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒+𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑+ 𝛽𝛽3𝑏𝑏𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒∗𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑞𝑞𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑+ 𝛽𝛽2:𝑘𝑘𝑿𝑿  𝑒𝑒ln(𝑝𝑝𝑞𝑞𝑏𝑏𝑑𝑑𝑝𝑝𝑏𝑏𝑑𝑑)= 𝑒𝑒𝛽𝛽0+ 𝛽𝛽1𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏+𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑+ 𝛽𝛽3𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏∗𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑+ 𝛽𝛽4:𝑘𝑘𝑿𝑿  𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑= 𝑒𝑒𝛽𝛽0+ 𝛽𝛽1𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏+𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑+ 𝛽𝛽3𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏∗𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑+ 𝛽𝛽4:𝑘𝑘𝑿𝑿=𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽3𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏∗𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  [𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0] = 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿  𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1 𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0=𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽3𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 =𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽3𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑𝒆𝒆𝜷𝜷𝟑𝟑  𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1 𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=0=𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽3𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 after the shock changes by a factor of 𝒆𝒆𝜷𝜷𝟑𝟑.  effect of being a “before” campaign by a factor of 𝒆𝒆−0.116=𝟎𝟎.𝟖𝟖𝟖𝟖. That is, as the quality increases, the effect of being a “before”    That is, for a 1-unit increase in quality, the ratio between money pledged before and money pledged after equals:     [𝑝𝑝𝑞𝑞𝑒𝑒𝑑𝑑𝑝𝑝𝑒𝑒𝑑𝑑|𝑞𝑞𝑒𝑒𝑏𝑏𝑏𝑏𝑏𝑏𝑒𝑒=1]= 𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽3𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿    This means that for a 1-unit increase in quality, the ratio between the amount pledged before the shock and the amount pledged    For our data, this means that when observing the effect on the amount pledged, a 1-unit increase in QualityPca decreases the  𝑒𝑒𝛽𝛽0𝑒𝑒𝛽𝛽2𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑𝑒𝑒𝛽𝛽4:𝑘𝑘𝑿𝑿 =𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽3(𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑+1)= 𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽3𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑+𝛽𝛽3               =𝑒𝑒𝛽𝛽1𝑒𝑒𝛽𝛽3𝑞𝑞𝑞𝑞𝑑𝑑𝑞𝑞𝑏𝑏𝑞𝑞𝑑𝑑_𝑝𝑝𝑞𝑞𝑑𝑑   campaign decreases, such that higher-quality campaigns are less affected.  MIS Quarterly Vol. 43 No. 4‒Appendix/December 2019     A9  Copyright of MIS Quarterly is the property of MIS Quarterly and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. 