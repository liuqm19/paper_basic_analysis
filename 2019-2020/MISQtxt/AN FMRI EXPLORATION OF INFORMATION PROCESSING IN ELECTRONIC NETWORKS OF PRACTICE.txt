RESEARCH ARTICLE AN FMRI EXPLORATION OF INFORMATION PROCESSING IN ELECTRONIC NETWORKS OF PRACTICE1 Thomas O. Meservy Information Systems Department, Marriott School of Business, Brigham Young University, Provo, UT  84602  U.S.A.  {tmeservy@byu.edu} Kelly J. Fadel Department of Management Information Systems, Utah State University, Logan, UT  84322  U.S.A.  {Kelly.Fadel@usu.edu} C. Brock Kirwan Department of Psychology and Neuroscience Center, Brigham Young University, Provo, UT  84602  U.S.A.  {kirwan@byu.edu} Rayman D. Meservy Information Systems Department, Marriott School of Business, Brigham Young University, Provo, UT  84602  U.S.A.  {meservy@byu.edu} Online forums sponsored by electronic networks of practice have become an important source of information for individuals seeking solutions to problems online.  However, not all information available in a forum is helpful or accurate, requiring knowledge seekers to evaluate and filter the solutions they encounter.  Most forums offer contextual cues to help knowledge seekers make evaluation decisions, yet little is understood about the cognitive processes and neural mechanisms that underlie how information on these forums is filtered and evaluated.  This paper draws on literature in cognitive neuroscience and NeuroIS to develop exploratory research questions about the role of both content and contextual cues in forum filtering tasks, the comparative and interactive effects of different types of contextual cues, and the neural functions associated with filtering processes.  These questions are explored using an fMRI experimental study that captured forum information filtering  behaviors  and  measured  the  neural  correlates involved  in  evaluating  both  solution  content  and contextual cues.  Results show that both content and contextual cues influence final filtering decisions, with community-based cues factoring more heavily than expert-based cues.  Moreover, we observe distinct neural activation  patterns  when  forum  knowledge  seekers  encounter  certain  cue  combinations.      Based  on  our observations, we derive a theoretical model comprising testable research propositions about both behavioral and neural facets of forum information filtering. Keywords:  fMRI, electronic network of practice, information filtering, online forum, programming experiment 1 1James Thong was the accepting senior editor for this paper.  Eric Walden served as the associate editor.  The appendices for this paper are located in the “Online Supplements” section of MIS Quarterly’s website (https://misq.org). DOI:  10.25300/MISQ/2019/15093 MIS Quarterly Vol. 43 No. 3, pp. 851-872/September 2019 851 Meservy et al./An fMRI Exploration of Information Processing Introduction hello,  my  fuel  pump  will  not  turn  on  when  the ignition key is in on position.  relays and fuses are fine.    the  thing  is  when  it  decides  to  work,  truck starts and runs great.  it will be ok for a day or 10 days.  park it in the driveway but the pump will not activate so it will not start the next morning.  this has happened 3 times in the past month.  please help.  thank you!  (https://community.cartalk.com/t/fuel- pump-issues/42922) Recently I bought some dark roasted coffee, but it turned out the roast wasn’t dark enough for my taste.  While  sipping  the  insipid  brew,  I  asked  myself, ‘Why can’t I take these beans and roast them some more?’  Now I’m asking you, the coffee mavens.  Can this be done?  And how might be the best way to do it?  Thanks! (http://www.cheftalk.com/t/59866/ re-roasting-coffee-beans-can-it-be-done) I am having trouble figuring out where to get started in this proof.  Let πi be the inclusion probability of unit i in some sample scheme for drawing n units out of  a  population  of  size  N.    How  can  I  go  about showing that the sum of all πi for i from 1 to N is equal  to  the  sample  size  n?    Any  help  would  be appreciated.    (http://mathhelpforum.com/statistics/ 239922-proving-sum-inclusion-probabilities-equals- sample-size-n.html) Every day, people all over the world ask millions of questions like  these.    To  whom  are  these  questions  addressed?  Although  some  are  directed  to  family,  friends,  or  trusted experts, a vast and growing proportion (including the three examples above) are posed to the masses via internet-enabled platforms that support networks of individuals with shared interests or information needs.  Termed electronic networks of practice, these networks comprise a set of loosely affiliated individuals who share a common practice and communicate via technology-mediated channels (Wasko and Faraj 2005).  Electronic  networks  of  practice  have  become  a  primary information source for millions of knowledge seekers, with topics ranging from animals and automotive to finance and food  to  technology  and  travel,  just  to  name  a  few  (“The Biggest Boards” 2017). One of the most common tools used by an electronic network of practice (hereafter simply network) is the online knowledge forum, a virtual bulletin board where network participants can post  and  retrieve  knowledge  about  topics  relevant  to  their shared practice.  Research indicates that network forums are important  sources  of  knowledge  for  both  individuals  and 852 MIS Quarterly Vol. 43 No. 3/September 2019 firms (Beck et al. 2014).  Forums are popular tools among network  participants  because  they  support  knowledge  ex- change centered on problem solving (Meyer-Gossner 2013).  For example, software developers searching for a solution to a programming problem might access an online forum such as stackoverflow.com or dreamincode.net to request information from  other  network  participants  or  to  search  for  existing queries  that  match  their  own.    In  response,  other  network participants  post  potential  solutions,  often  in  the  form  of actual code blocks.  Surrounding these solutions, most forums offer  additional  contextual  cues  to  the  information  seeker, such  as  characteristics  of  the  respondent  (e.g.,  expertise level), endorsement of the solution by an expert participant, or validation of the solution by other members of the com- munity.  Therefore, individuals who turn to network forums as a knowledge source must filter and evaluate different types of information as they decide which solution(s) to ultimately adopt,  a  process  referred  to  herein  as  forum  information filtering. Research has begun to explore how information on network forums is filtered by examining which cues people attend to when evaluating forum information (Meservy et al. 2014) and how attentional switching patterns among these cues affect filtering outcomes (Fadel et al. 2015).  However, the actual cognitive processes that underlie how people evaluate these cues remain unclear.  Do people engage in qualitatively dif- ferent types of thinking as they evaluate different types of information  on  network  forums?    Do  certain  cues  exhibit interaction effects that influence subsequent evaluation pat- terns?    And  do  some  types  of  processing  lead  to  more accurate information filtering outcomes?  Answering these questions extends our theoretical understanding beyond what happens  during  information  filtering  to  why  it  happens,  a critical step in establishing a theoretical and practical founda- tion  for  knowledge  exchange  via  electronic  networks  of practice. Explicating the cognitive processes that underlie information processing  has  long  been  an  occupation  of  the  domain  of cognitive neuroscience (Anderson 1990; Gazzaniga 2004).  Information  Systems  (IS)  researchers  have  recognized  the potential value of applying neuroscience tools and techniques to better understanding the cognitive processes that underlie IS  phenomena.    Known  as  NeuroIS  (Dimoka  et  al.  2011; Riedl et al. 2014; Riedl and Léger 2016), this branch of IS research is concerned with the application of cognitive neuro- science  literature  and  functional  brain  imaging  tools  to “further advance our knowledge of the complex interplay of IT  and  information  processing,  decision  making,  and  be- havior” (Dimoka et al. 2011, p. 687).  In this paper, we report the results of an exploratory NeuroIS study aimed at better understanding the cognitive processes involved when people filter  information  found  in  online  network  forums.    Our approach  is  exploratory  because,  to  our  knowledge,  little research  has  examined  forum  information  filtering  from  a neurocognitive perspective.  Although some inferences may be  drawn  from  general  neuroscience  research,  a  testable theory about the neurocognitions and behaviors involved in this type of information filtering does not yet exist.  We there- fore adopt a theory-building approach in which we formulate general research questions, examine experimental data asso- ciated  with  these  questions,  and  use  our  results  to  infer theoretical propositions for future research.  Although some- what uncommon in the IS domain, this approach has prece- dent in neuroscience research (e.g., Kolling et al. 2012) and lays a conceptual foundation for future studies.  Ultimately, establishing information filtering behaviors along with their neural  correlates  can  lead  to  better  theory  and  practice  to support both the design of technology-mediated channels and the filtering strategies employed by those who use them. The rest of this paper is organized as follows.  First, we out- line key characteristics of online network forums, including the types of cues that knowledge seekers typically encounter.  We  then  formulate  exploratory  research  questions  about different  types  of  cognition  involved  in  evaluating  and filtering forum solutions.  We report our exploration of these questions  using  data  collected  from  a  functional  magnetic resonance imaging (fMRI) experiment that measured neural hemodynamic response as participants completed an infor- mation evaluation task using a mock network forum.  Based on our analysis, we derive a series of theoretical propositions about forum information filtering behaviors and the possible neurological mechanisms that underlie these behaviors.  We conclude  by  discussing  implications  of  our  findings  for research and practice. Background  An electronic network of practice is formally defined as a collection of loosely affiliated individuals who form a “self- organizing, open activity system focused on a shared practice that exists primarily through computer-mediated communi- cation” (Wasko and Faraj 2005, p. 37).  Although most such networks comprise hundreds or even thousands of partici- pants,  knowledge  exchange  on  a  network  forum  typically occurs in the form of dyadic information exchanges between knowledge seekers and knowledge contributors.  Importantly, the roles of knowledge seeker and knowledge contributor are fluid and interchangeable; a given participant may use the forum to seek knowledge in one case and to contribute exper- tise in another. Meservy et al./An fMRI Exploration of Information Processing Unlike  other  commonly  studied  platforms  of  technology- mediated information exchange such as email (Sussman and Siegal 2003) or internal knowledge repositories (Fadel et al. 2009;  Zhang  and  Watts  2008),  the  loose  and  unstructured nature  of  participation  in  a  network  poses  several  unique information  processing  challenges  for  knowledge  seekers.  Because  queries  can  usually  be  answered  by  any  and  all network participants, knowledge seekers often face the task of evaluating several unique and possibly conflicting answers.  Because seekers do not know contributors personally, they may have difficulty evaluating the expertise of the knowledge contributor and, by extension, the validity of the response.  Moreover,  depending  on  the  nature  of  the  query  and  the background of the knowledge seeker, it may be difficult or impossible for the seeker to evaluate the content of posted solutions on their own merits due to inexperience or lack of adequate technical expertise.   To assist knowledge seekers in overcoming these difficulties, forums  typically  offer  additional  contextual  cues  to  help seekers evaluate the solutions they find.  For example, many forums provide information about the expertise of the solution contributors, such as the total time contributors have parti- cipated  in  the  network,  the  number  of  queries  they  have answered, or an expertise rating provided by forum moder- ators or other network participants.  Contributor expertise is one type of contextual cue that has been studied in various technology-mediated information exchange contexts (Fadel et al. 2009; Sussman and Siegal 2003; Zhang and Watts 2008).  However,  another  important  cue  that  has  received  less research attention but has been shown to be even more influ- ential in filtering decisions is validation:  the endorsement (or lack thereof) of a solution by one or more individuals other than  the  author  (Fadel  et  al.  2015;  Meservy  et  al.  2014).  Many forums provide a mechanism that allows subject matter experts  and/or  other  participants  to  provide  validation  of specific  solutions,  such  as  star  ratings,  up/down  votes,  or “accepted solution” designations.  Although these cues might not accurately reflect the quality of the solution content itself, they offer ancillary information to seekers to help them judge the potential validity of posted solutions and decide which, if any, to ultimately adopt.  Therefore, seekers who either post their own queries to a forum or search for answers to others’ queries must evaluate several potentially competing candidate solutions by examining (1) the content of the solutions them- selves, (2) the contextual cues surrounding each solution, or (3) a combination of both.  In this paper, our objective is to explore the cognitive differences between filtering based on these cues.  Our work is situated within recent IS research that has  begun  to  explore  forum  information  filtering  (see Appendix A for more details). MIS Quarterly Vol. 43 No. 3/September 2019 853 Meservy et al./An fMRI Exploration of Information Processing Exploratory Questions Our  inquiry  into  cognitions  and  behaviors  associated  with forum  information  filtering  stems  from  basic  observations about the nature of these forums and the types of cues therein.  We enumerate these observations in this section and, consis- tent with our theory-building approach, identify five explora- tory research questions that probe cognitions and behaviors involved in forum information filtering.  These questions are organized into three overarching themes:  (1) the individual effects  of  different  forum  elements  (solution  content  and surrounding contextual cues), (2) the comparative effects of these elements in relation to each other, and (3) the combined effects of these elements when they are congruent/incongruent in their indications. Individual Effects As  noted  above,  forum  users  can  attend  to  various  forum elements when evaluating a solution.  These elements can be broadly categorized as consisting of either (1) the contextual cues surrounding a solution or (2) the solution content itself.  Contextual cues associated with a solution offer indications that  are  either  positive  (i.e.,  favorable)  or  negative  (i.e., unfavorable) toward the solution.  For example, positive cues may include endorsement by an ostensible expert, a favorable ratio of up/down votes from the community, or being tagged as an accepted solution, whereas negative cues would include opposite indicators (Bhattacherjee and Sanford 2006).  Evi- dence from the neuroscience literature suggests the possibility of  distinct  neural  mechanisms  for  processing  positive  and negative information (for a review, see Lindquist et al. 2015); however, how and whether these mechanisms operate in the context  of  forum  information  filtering  remains  an  open question.  Question  1:    How  does  contextual  cue  valence (positive versus negative) affect forum information filtering  decisions?    Are  different  neural  systems responsible for processing positive/negative contex- tual cues? As an alternative or supplement to contextual cues, knowl- edge  seekers  may  choose  to  evaluate  the  solution  content itself.  According to information processing theories, content- based filtering is likely to occur only if the knowledge seeker possesses  the  capability  and  motivation  to  analyze  the information content (Petty and Cacioppo 1986).  Prior studies have shown that in other technology-mediated contexts, able and  motivated  knowledge  seekers  base  their  information adoption decisions primarily on the perceived quality (or lack 854 MIS Quarterly Vol. 43 No. 3/September 2019 thereof) of the information content (Sussman and Siegal 2003; Zhang and Watts 2008).  Analyzing content requires careful scrutiny of the solution semantics to identify any flaws that render the solution untenable.  Neuroscience research sug- gests  that  this  type  of  content-based  filtering  may  involve areas of the brain associated with error detection (Friederici et al. 2003), discrepancy resolution (Botvinick et al. 2004; Bush et al. 2000; Kawamoto et al. 2012), or stimulus salience (Menon 2011). Question 2:  How does content quality (high versus low)  affect  forum  information  filtering  decisions?  Are  different  neural  systems  responsible  for  pro- cessing high/low-quality content? Comparative Effects Most information filtering judgments involve some combin- ation of context and content, yet the relative influence of these elements can vary widely (Petty and Cacioppo 1986; Petty et al.  2005).    Thus,  an  important  theoretical  question  sur- rounding forum information filtering concerns the compara- tive influence of these elements on filtering judgments.  First, what are the relative effects of different types of contextual cues?  On network forums these cues can take various forms and originate from many sources, but can generally be cate- gorized as expert-based (originating from putative domain experts)  or  community-based  (originating  from  the  larger network populace).  How might these types of cues compare in  their  influence  on  filtering  decisions?    Research  on consumer  product  reviews  indicates  that  product/service consumption  decisions  are  more  heavily  influenced  by community-based  reviews  than  by  expert-based  reviews (Dellarocas et al. 2007; Zhang et al. 2010), but whether this holds for information filtering decisions is not clear.  More- over,  literature  on  the  neuroscience  of  social  influence suggests that different neural mechanisms may be responsible for processing different types of social cues.  For example, Seiler and Walden (2016) found different neural activation patterns when decision makers were prompted with decisions of domain experts versus those of peers. Question  3:    Which  types  of  contextual  cues, community-based or expert-based, are more influ- ential  in  forum  information  filtering  tasks?    Are different neural activation patterns associated with processing based on community- and expert-based cues? Second, filtering decisions can be based on a combination of contextual cues and content.  Prior work has found that infor- mation  content  is  the  primary  basis  for  judgment  among knowledge seekers who are able and motivated to examine it (Fadel  et  al.  2009;  Sussman  and  Siegal  2003;  Zhang  and Watts  2008).    However,  other  studies  in  the  context  of network forums have found that contextual cues (specifically, validation) play a more prominent role, even among those who  are  capable  of  and  motivated  to  assess  information content (Fadel et al. 2015; Meservy et al. 2014).  Although contextual cues can be quickly and readily assessed, content- based  filtering  requires  more  effortful  evaluation  of  the solution’s internal validity; thus, from a neurological perspec- tive, one might expect greater recruitment of brain regions associated  with  semantic  processing  for  content-based filtering vis-à-vis context-based filtering (Price 2010; Wagner et al. 2001).   Question 4:  How do solution content and contextual cues compare in their influence on forum informa- tion  filtering  decisions?    Do  distinct  neural  pro- cesses  underlie  filtering  based  on  content  versus filtering based on context? Congruence/Incongruence Effects Finally,  different  contextual  cues  associated  with  a  single solution may conflict in their indications, and may or may not be consistent with the actual quality of the solution.  This raises the possibility that cues may interact (either additively or  diminutively)  in  their  influence  on  filtering  judgments.  Research on digital goods consumption, for example, lends some support to this notion, finding that consistent expert- and  community-based  reviews  had  an  additive  effect  on consumers’ propensity to download and consume online soft- ware applications (Amblee and Bui 2007).  On the other hand, cue disagreement may induce a state of cognitive dissonance wherein knowledge seekers must reconcile the indications of two conflicting signals and determine which (if any) they will follow.  Resolving such discrepancies could invoke neural systems associated with cognitive dissonance (Izuma et al. 2010) or prediction error (Corlett et al. 2004; Garrison et al. 2013), which occurs when originally expected outcomes (e.g., expecting the solution to be high quality due to a positive con- textual  cue)  are  later  violated  (e.g.,  finding  flaws  in  the solution upon examining its content). Question 5:  Do cues exert an interactive effect on information filtering decisions when they are con- gruent  versus  when  they  are  incongruent?    What neural mechanisms are involved in processing con- gruent versus incongruent cues?  Meservy et al./An fMRI Exploration of Information Processing Methodology To explore our research questions, we conducted a controlled fMRI experiment to observe the cognitive processing patterns that occur as people process and filter information found on online network forums.  We followed guidelines established in  the  NeuroIS  literature  (vom  Brocke  and  Liang  2014; Dimoka 2011) for conducting an fMRI study.  Similar to prior research (Fadel et al. 2015; Meservy et al. 2014), we chose the  domain  of  software  development/programming  as  the context for our experimental task.  Software development is a  field  oriented  around  problem  solving  and  a  domain  in which network forums are commonly used as a knowledge source (Brandt et al. 2009; Hoffmann et al. 2007; Stylos and Myers 2006).  We designed a custom experimental instrument that mimicked the structure of an online programming forum and displayed a series of programming problem solutions in a controlled sequence.  Seven programming problems (one for training and six for the experimental stimuli) were selected such that they would be familiar and readily comprehensible to  most  programmers  but  also  of  adequate  complexity  to require  systematic  evaluation  to  assess  the  quality  of  a proposed  solution.    Eight  solutions  for  each  of  the  six experimental programming problems (48 total solutions) were developed  based  on  actual  forum  solutions  found  online.  Appendix  B  contains  a  description  of  the  programming problems and solutions used. To examine the cognitions associated with different types of information filtering, each solution consisted of both content and contextual cues.  Specifically, each solution had three factors that could assume one of two levels:  a rating by a purported domain expert (expert validation) showing that the solution was either endorsed by the expert (high expert vali- dation) or lacked expert endorsement (low expert validation); a rating by participants in the network (community validation) indicating that the solution was either recommended by the majority of community members (high community validation) or not recommended by the majority of community members (low community validation); and, finally, the actual solution code (content), which was either syntactically and logically correct for solving the problem (high code quality) or mani- pulated  to  contain  logic,  control  flow,  or  other  errors  that prevented  it  from  solving  the  problem  (low  code  quality).  Each problem thus contained four high/low-quality solutions, four high/low expert validation cues, and four high/low com- munity validation cues.  These factors yielded eight unique experimental treatment conditions that were coded according to  the  combination  of  expert  validation  (H/L),  community validation (H/L), and code quality (H/L), respectively.  For example, a solution with high expert validation, low commu- nity validation, and high code quality was coded as HLH. MIS Quarterly Vol. 43 No. 3/September 2019 855 Meservy et al./An fMRI Exploration of Information Processing Each of the six programming problems had eight solutions (one for each treatment condition), producing a randomized, fully factorial experimental design with 48 unique stimuli. The interface of the experimental instrument was modeled after  actual  online  programming  forums,  and  presented prospective solutions one at a time to each participant.  To maximize the face validity of the instrument, interface ele- ments were copied from actual online forums, such as the names of the experts, avatar images,2 expert join dates, and number of posts.  Appendix B contains a sample solution for one of the problems presented. To  isolate  cognitive  processing  differences  in  contextual processing (evaluation based on expert and community vali- dation) versus content processing (evaluation of the solution content itself), it was necessary to present the solutions so that each type of processing could be induced separately.  We controlled the visibility of solution components by displaying each solution in two sequential phases.  In the context phase, participants were first shown only the contextual cues with the  code  obscured.3    During  this  phase,  participants  were exposed to one of four contextual cue conditions for each solution:    high  expert  validation  and  high  community validation (HH), high expert validation and low community validation (HL), low expert validation and high community validation (LH), or low expert validation and low community validation  (LL).    The  code  was  blurred  enough  to  require participants  to  make  a  judgment  based  solely  on  the contextual cues, but it was apparent that there was actual code associated with the proposed solution.  To ensure the con- textual  cues  were  processed,  participants  were  asked  to provide a preliminary rating (on a five-point scale) indicating how likely they would be to adopt the solution based on these cues alone.  After providing the preliminary rating, partici- pants entered the content phase, in which the solution code was  unblurred.    They  were  then  given  the  opportunity  to provide a final rating of the solution that incorporated their analysis of the code itself.  Appendix B shows an example of the stimulus screen in the context phase. 2Avatar images were copied from actual online forums and may have varied in complexity.  For example, 34.6% of the avatars were human faces which have been shown to be more complex than simple objects and require several areas of the brain to process (Johnson 2005).  To mitigate the influence of varying levels of complexity, we randomly paired the extraneous interface elements (e.g., avatars, posts, join date) in each solution set, with each parti- cipant receiving different random pairings. 3Alternatively, we could have shown the code first with the contextual cues blurred.  However, we showed contextual cues first as previous studies have found that participants often use these cues as a way of filtering potential candidate solutions before scrutinizing content (Fadel et al. 2015; Meservy et al. 2014). 856 MIS Quarterly Vol. 43 No. 3/September 2019 To  test  the  experimental  instrument,  we  conducted  a  pilot study with six experienced software developers.  Based on their feedback, minor alterations were made to the interface and to some solutions to improve clarity of the process and the content.  To ensure participants could evaluate the solu- tion content, we recruited experienced software developers to participate in the main study.  Participants were required to have at least one year of programming experience and to be proficient in Java, C#, or C++.  Each participant was screened for MRI compatibility, native-English speaking, corrected- normal visual acuity, and right-handedness.  Qualified partici- pants  were  then  scheduled  for  the  experiment  at  the  MRI facility.  In total, 29 experienced software developers (93.1% male, average age 26.2 years, average of 4.0 years program- ming  experience)  were  recruited  from  local  companies  to participate in the study.4   Participants were compensated with either  $25  or  a  3D  model  of  their  brain.    Details  of  the experimental procedure, including experimental flow and task details, are provided in Appendix C. Analysis and Results We conducted two types of analysis to address our research questions.  First, we used a series of ordinal mixed effects regression  models  to  examine  how  participants’  filtering decisions (represented by their ratings of the solutions) were related to the experimental stimuli.  Mixed effects models were used because the data we collected were hierarchical, with solutions grouped by problem and each solution rated by every participant.  In addition, the dependent variable of the preliminary/final rating of each solution was ordinal in nature (measured on a scale of 1 to 5, with 5 indicating the highest probability of adoption).  Therefore, we selected cumulative link  (ordinal)  mixed  model  analysis  to  capture  both  fixed (solution-level) effects and random (grouping) effects due to participants, problems, and solutions.  Because each partici- pant rated every solution for every problem, a fully-crossed random effects design was used.  To perform the analysis, we used the cumulative link mixed models (CLMM) function of the ordinal package in R (Christensen 2015; R Core Team 2017)  to estimate ordinal mixed effects regression models with both fixed and random effects.  Appendix D provides additional details on the suitability of this approach for our data. Models were built using data from both the context and con- tent experimental phases.  During the context phase, partici- pants were shown only the contextual cues of expert valida- tion (EV) and community validation (CV) and were asked to 4Typical sample sizes in NeuroIS fMRI studies range from 15 to 25 partici- pants (Riedl et al. 2011). provide  a  preliminary  rating  (PR)  based  on  these  cues.  During the content phase, participants were shown the actual solution code (along with the same contextual cues) and had the opportunity to change their preliminary rating to a final rating  (FR)  based  on  their  assessment  of  the  code  quality (CQ).5  We therefore specified a series of ordinal regression models as shown in Table 1. The second type of analysis we conducted focused on the fMRI data of participants’ cognitions during the experimental task.  Imaging data were analyzed using the Analysis of Func- tional  Neuroimages  (AFNI)  suite  of  programs,  version AFNI_18.1.18 (Cox 1996) and the Advanced Normalization Tools (ANTs) (Avants et al. 2008; Klein et al. 2009).  All MRI imaging was done on a 3T Siemens TIM Trio scanner using a 12-channel head coil.   Structural MRI scans were collected using a T1-weighted magnetization-prepared rapid acquisition with gradient echo (MP-RAGE) sequence with the following parameters:  TR = 1900ms; TE = 2.26ms; 176 1- mm thick slices (no gap); acquisition matrix = 256 × 215; field of view = 218 × 250mm; voxel size = .97 × .97 × 1mm.  Functional  images  were  collected  using  an  echo-planar imaging (EPI) sequence with the following parameters:  TR = 2500ms; TE = 28ms; flip angle = 90°; 43 3-mm thick slices (no gap); acquisition matrix = 64 × 64; field of view = 192 × 192; voxel size = 3 × 3 × 3mm.  We collected two functional runs of 324 volumes (TRs) each (13min 30sec per scan run). We followed standard fMRI practices when analyzing neural data (Dimoka 2011).  Functional MRI data were slice-time corrected  and  motion  corrected  to  align  with  the  middle volume  of  each  run.    The  second  functional  run  was  then aligned with the first volume of the first run.  Individual-level regression  analyses  were  conducted  to  fit  the  ideal  hemo- dynamic  response  to  the  neural  data  for  each  voxel.  Parameter estimates (i.e., betas) from these individual-level models were then blurred and normalized to MNI space so that  group-level  analyses  could  be  conducted  using  multi- variate  modeling  to  answer  the  neural-related  exploratory questions.    Appendix  E  contains  additional  details  of  the fMRI analysis, including a description of the individual-level analyses  that  were  subsequently  used  for  the  group-level analyses reported below. 5Because information processing theories stipulate that motivation is a neces- sary condition for processing of content, we assessed participants’ motivation in  the  post-survey  using  three  main  questions.    These  questions  were answered using a seven-point scale ranging from not at all (1) to a great deal (7).  Motivation questions:  During your participation in the study, to what extent were you (a) trying hard to evaluate the quality of each solution pre- sented  (mean:    4.97;  SD:    1.00);  (b)  motivated  to  correctly  evaluate  the quality of each solution presented (mean:  5.17; SD:  1.00); (c) putting forth effort to evaluate the quality of each solution presented (mean:  5.23; SD:  0.83).  The results suggest that participants were sufficiently motivated to correctly complete the experimental task. Meservy et al./An fMRI Exploration of Information Processing Results Influence of Contextual Cue Valence Question  1:    How  does  contextual  cue  valence (positive versus negative) affect forum information filtering  decisions?    Are  different  neural  systems responsible for processing positive/negative contex- tual cues? To explore how contextual cue valence (positive versus nega- tive)  influences  filtering  judgments,  we  conducted  ordinal regression analyses for the context phase.  Table 2 shows the reported effects of the contextual cue variables for a baseline model  (1.0),  main  effects-only  model  (1.1),  and  a  fully specified model (1.2).   For each of the independent variables specified in our model, we calculated the odds ratio as a measure of effect size.  In ordinal regression models, the odds ratio indicates the factor by which odds of the dependent variable moving from one level to the next increases or decreases for every one-unit increase in the independent variable.  For instance, an odds ratio  of  2  would  indicate  that,  ceteris  paribus,  a  one-unit increase in the associated independent variable (e.g., commu- nity validation) would double the  odds that the dependent variable (e.g., final rating) takes on the next ordinal value (e.g., moves from 3 to 4).  Thus, the odds ratio provides an intuitive and interpretable measure of the practical effect the independent variables as well as a means for comparing their relative effect sizes. Model 1.1 results show that both expert validation (β = 1.89, p < .001) and community validation (β = 4.78, p < .001) had a significant effect on the preliminary rating; the odds of a higher rating increased when expert and community valida- tion were positive in valence. To  explore  the  neural  systems  responsible  for  processing positive and negative contextual cues, we performed repeated- measures analyses using AFNI program 3dMVM, with parti- cipant as a random factor and the factorial combinations of expert and community validation levels (HH, HL, LH, and LL) as a fixed factor.  Models investigated the main effect of expert validation valence (HH and HL versus LH and LL), the main effect of community validation valence (HH and LH versus HL and LL), and the direct comparison of consistent positive valence and consistent negative valence (HH versus LL).  Each of these models failed to reveal any significant clusters of activation; thus, our exploratory analysis did not find support for distinct neurocognitive processing associated with valence of contextual cues. MIS Quarterly Vol. 43 No. 3/September 2019 857 Meservy et al./An fMRI Exploration of Information Processing Table 1.  Ordinal Regression Models Context Phase Models Content Phase Models • Model 1.0:  Random Effects (participant and solution)  PR† • Model 1.1:  EV + CV  PR • Model 1.2:  EV + CV + [EV x CV]  PR • Model 2.0:  Random Effects (participant and solution)  FR • Model 2.1:  EV + CV + CQ  FR • Model 2.2:  EV + CV + CQ + [EV x CV x CQ] FR Notes:  EV = Expert Validation, CV = Community Validation, PR = Preliminary Rating, CQ = Code Quality, FR = Final Rating; Model 2.2 includes all two-way interactions between EV, CV, and CQ. †Random effects were also included in each subsequent model. Table 2.  Context Phase Models Model 1.0 Model 1.1 Model 1.2 Estimate (SE) Odds Ratio 1.89*** (.12) 4.78*** (.17) Fixed Effects Variables Expert Validation (EV) Community Validation (CV) EV × CV Log Likelihood AIC N (ratings) N (solutions) N (participants) *p < .05; **p < .01; ***p < .001 Notes:  All models included random intercept effects for solution and participant.  Log likelihood significance values indicate whether the LR test was significant from one model to the next. Estimate (SE) 1.71*** (.16) 4.60*** (.20) 2143.77 4299.54 1,392 48 29 .39 (.24) 1458.91 2935.82 1,392 48 29 1460.23*** 2936.45 1,392 48 29 Odds Ratio 5.53 99.97 1.47 6.62 119.10 Influence of High Versus Low Content Quality ficant in this model, though their effect sizes were smaller. Question 2:  How does content quality (high versus low)  affect  forum  information  filtering  decisions?  Are  different  neural  systems  responsible  for  pro- cessing high/low-quality content? To inspect how the quality of the content (i.e., quality of the code) impacts overall judgments of solution as a whole, we conducted ordinal regression analyses for the content phase.  These models also included expert validation and community validation, which were visible during both the context and content phase.  Table 3 shows the reported effects, including the ordinal regression coefficients and associated odds ratios, of  the  explanatory  variables  for  a  baseline  model,  main effects-only model, and a fully specified model. As shown in the results for model 2.1, code quality had a significant influence on the final rating (β = 2.46, p < .001), providing support for the notion that participants were influ- enced by the actual quality of the underlying solution.  In fact, solutions with high code quality had 11.69 times greater odds of receiving a higher final rating than solutions with low code quality.  The influence of contextual cues also remained signi- 858 MIS Quarterly Vol. 43 No. 3/September 2019 To explore whether distinct patterns of neural activation occur when knowledge seekers evaluate high-quality solutions as opposed to low-quality solutions, we performed a repeated- measures analysis contrasting activity in the content phase for trials that received a high final rating with trials that received a low final rating, controlling for the effect of context cues by collapsing across all levels of these cues.6  We observed three significant clusters of activation where activity differentiated between high and low final ratings (see Table 4).  Large clus- ters in the left and right anterior insula were more active for solutions receiving a high final rating (see Appendix F). 6A Pearson chi-squared test of independence showed that final participant ratings were highly correlated with the high and low experimental conditions for code quality (χ2 = 401.52, p < 0.001) in the content phase.  (Similar results were found for expert rating (χ2 = 166.48, p < 0.001) and community rating (χ2 = 886.66, p < 0.001) in the context phase.)  A direct comparison between models of neural activation based on subjective quality ratings versus objec- tive quality ratings did not reveal any significantly different activations. Table 3.  Content Phase Models Fixed Effects Variables Expert Validation (EV) Community Validation (CV) Code Quality (CQ) EV × CV EV × CQ CV × CQ EV × CV × CQ Log Likelihood AIC N (ratings) N (solutions) N (participants) Meservy et al./An fMRI Exploration of Information Processing Model 2.0 Model 2.1 Model 2.2 Estimate (SE) Odds Ratio Estimate (SE) Odds Ratio .31** (.10) 1.13*** (.11) 2.46*** (.21) 1.36 3.10 11.69 1892.99 3797.97 1,392 48 29 1801.76*** 3621.52 1,392 48 29 .45 (.24) 1.25*** (.23) 2.65*** (.29) -.31 (.32) -.44 (.31) -.42 (.30) 1.01* (.43) 1798.10 3622.2 1,392 48 29 1.57 3.48 14.10 .73 .64 .66 2.74 *p < .05; **p < .01; ***p < .001 Notes:  All models included random intercept effects for solution and participant.  Log likelihood significance values indicate whether the LR test was significant from one model to the next. Table 4.  Cluster Characteristics in the High Final Rating Versus Low Final Rating Contrast  R.  Anterior Insula L.  Anterior Insula #Voxels 108 97 X 50 -47 Peak Voxel Y 23 23 Z -8 -11 High FR > Low FR t(28) 4.558 4.952 p-value <.001 <.001 Notes:  As an indication of the size of the effect within each significant cluster, we provide t-test statistics, which reflect the mean activation difference between conditions collapsed across all voxels in the cluster. Comparative Effects of Community-Based Versus Expert-Based Contextual Cues Question  3:    Which  types  of  contextual  cues, community-based or expert-based, are more influen- tial in forum information filtering tasks?  Are dif- ferent  neural  activation  patterns  associated  with processing based on community- and expert-based cues? Consistent  with  the  literature  presented  earlier,  Table  2 reveals that the effects of community validation (β = 4.78, 95%  CI  =  4.45,  5.11)  were  stronger  than  those  of  expert validation (β = 1.89, 95% CI = 1.65, 2.13) as evidenced by the nonoverlapping 95% confidence intervals of the regres- sion coefficients (Cumming 2009).  Holding expert validation constant,  a  solution  with  high  community  validation  had 119.1 times higher odds of receiving a higher final rating than a solution with low community validation.  Holding  com- munity validation constant, the odds of a solution with high expert validation receiving a higher final rating were 6.62 times  higher  than  those  of  a  solution  with  low  expert validation. To examine the question of whether different neural activa- tion  patterns  are  associated  with  processing  based  on community- and expert-based cues, we contrasted trials where the expert rating was high and the community rating was low (HL)  with  trials  where  the  expert  rating  was  low  and  the community rating was high (LH).  This contrast did not yield any significant activation differences. Comparative Effects of Content Versus Contextual Cues Question 4:  How do solution content and contextual cues compare in their influence on forum informa- tion  filtering  decisions?    Do  distinct  neural processes underlie filtering based on content versus filtering based on context? Comparing the 95% confidence intervals of the regression coefficients in model 2.1 (Table 3) shows that the influence of content quality on the final ratings (β = 2.46, 95% CI = 2.04, 2.88) was stronger than that of community validation (β = 1.13, 95% CI = 0.92, 1.34) or of expert validation (β = 0.31, MIS Quarterly Vol. 43 No. 3/September 2019 859 Meservy et al./An fMRI Exploration of Information Processing Table 5.  Cluster Characteristics in the Content > Context Contrast. Peak Voxel X -38 -53 Y 8 -50 Z 59 Content > Context t(28) p-value <.001 #Voxels 1093 L. Middle Frontal Gyrus L. Middle Temporal Gyrus (anterior) L. Angular Gyrus L. Middle Temporal Gyrus (posterior) L. Lingual Gyrus Notes:  As an indication of the size of the effect within each significant cluster, we provide t-test statistics, which reflect the mean activation difference between conditions collapsed across all voxels in the cluster. 10.5973 -6.6132 -65 -74 -35 -53 7.0977 142 128 326 215 -11 38 7.3491 8.3608 <.001 <.001 <.001 <.001 8 -11 -98 -23 95% CI = 0.11, 0.52).  As noted above, a solution with high code quality was 11.69 times more likely to receive a higher final rating than one with low code quality, controlling for both expert and community validation.  In the presence of code quality, both community and expert validation exerted a weaker effect on the final ratings, with odds ratios of 3.10 and 1.36, respectively.  To measure how neural activation patterns differ when evalu- ating contextual versus content information, we contrasted neural activation in the context phase with activation in the content phase.  This analysis revealed a large cluster of signi- ficant activation encompassing much of the motor and visual systems.  This cluster was likely due to the differences in the visual stimulus size and motor responses between the two phases  of  each  block  (i.e.,  participants  made  more  button presses when responding to the content phase of the experi- ment)  and  thus  is  not  discussed  further  here.    Outside  the visual and motor systems, we observed significant activation differences in five clusters, including the left middle frontal gyrus, left angular gyrus, two distinct regions in left middle temporal  gyrus,  and  the  left  lingual  gyrus  (Table  5  and Appendix F).  Activation was greater for the content phase in each of these clusters except the more posterior cluster in the middle temporal gyrus, which was more active during the context phase. Influence of Congruent Versus Incongruent Cues Question 5:  Do cues exert an interactive effect on information filtering decisions when they are con- gruent  versus  when  they  are  incongruent?    What neural  mechanisms  are  involved  in  processing congruent versus incongruent cues?  To  test  the  effect  of  cue  congruence,  we  explored  two scenarios:  (1) when contextual cues are congruent or incon- 860 MIS Quarterly Vol. 43 No. 3/September 2019 gruent  with  each  other,  and  (2)  when  contextual  cues  are congruent or incongruent with content quality. First, do congruent contextual cues exert an interactive effect on filtering behaviors over and above the effects of the indi- vidual cues themselves?  Considering the nonsignificant inter- action term of EV × CV in model 1.2 (β = .39, p = .106), our results  are  unable  to  provide  conclusive  support  for  this notion.  However, Figure 1 shows an interesting pattern (dis- cussed later) in the probability plots derived from the cumula- tive odds for each level of expert and community validation. To test for a congruence effect of contextual cues and content quality,  we  included  two-  and  three-way  interaction  terms between the predictor variables in model 2.2.  Results show that although none of the two-way interactions between the predictor variables is significant, the three-way interaction between expert validation, community validation, and code quality is significant (β = 1.01, p < .05).  Figure 2 shows a simple-slopes diagram that represents the interaction between these  three  variables,  with  the  dependent  variable  on  the vertical  axes  representing  the  log  odds  (left  side)  and probability (right side) of a solution receiving the next-highest rating  on  the  five-point  scale.    As  shown  in  this  figure, holding expert validation and community validation constant, low-quality  solutions  have  an  overall  lower  probability  of receiving a higher rating than high-quality solutions.  How- ever, the contextual cues exert different effects at different levels of code quality.  When community validation is high, it interacts more strongly with expert validation when code quality is also high.  In other words, high expert validation magnifies  the  effect  of  high  community  validation  when solutions are perceived as being high quality.  The opposite appears to be true when community validation is low.  In this case,  low  expert  validation  seems  to  cause  judgments  of solution quality to drop more precipitously when code quality is also low.  Figure 3 shows the probability plot for this set of models. Meservy et al./An fMRI Exploration of Information Processing Figure 1.  Probability of Rating Solution Based on Contextual Cue Valence Figure 2.  Interaction of Expert Validation, Community Validation, and Code Quality Figure 3.  Probability of Rating Solution Based on All Cues MIS Quarterly Vol. 43 No. 3/September 2019 861 Meservy et al./An fMRI Exploration of Information Processing Table 6.  Cluster Characteristics for Congruent Versus Incongruent Contextual Cues  Peak Voxel Congruent vs. Incongruent Cues Region #Voxels L. Inferior Frontal Gyrus L. Ventrolateral Prefrontal Cortex Notes:  F-statistics reflect the mean activation differences collapsed across all voxels in the cluster and are provided as an indication of the size of the effect within each significant cluster. <.001 26.37 .485 72 60 .46 F(1,28) 23.857 p-value <.001 partial eta^2 X -47 -53 Y 47 32 Z -2 23 To  explore  the  neurocognitive  processing  associated  with congruent/incongruent cues, we again performed repeated- measures  analyses  using  AFNI  program  3dMVM,  with participant as a random factor and the factorial combinations of expert and community validation levels (HH, HL, LH, and LL) as a fixed factor.  The contrast of congruent and incon- gruent  contextual  cues  (HH  and  LL  versus  HL  and  LH) revealed  two  significant  clusters  of  activation,  detailed  in Table 6.  Activation in two frontal regions (located in the left ventolateral prefrontal cortex [vlPFC] and left inferior frontal gyrus [IFG]) was significantly greater when CV and EV were incongruent than when they were congruent (see Appendix F). Finally, we conducted another repeated measures analysis to compare  neural  activity  in  the  content  phase  of  each  trial when the final rating was consistent with the contextual cues (CV and EV) compared to when it was inconsistent with one or more contextual cue.  We did not observe any significant clusters of activation in this contrast.   Discussion and Theoretical Propositions Prior studies have begun to explore how people evaluate and filter  knowledge  they  receive  via  various  forms  of technology-mediated channels (Fadel et al. 2009; Sussman and Siegal 2003; Zhang and Watts 2008) and online forums in particular (Fadel et al. 2015; Meservy et al. 2014).  How- ever, despite the relative maturity of forums as a knowledge source, we have, to date, made relatively little progress in exploring the cognitive processes that underlie forum infor- mation filtering.  The purpose of this study was to take an exploratory step toward better empirical understanding of this phenomenon, with the dual objectives of building our theo- retical understanding of how online information is processed and developing practical insights that will guide the devel- opment of the platforms on which they are based.  The results of our experiment offer several interesting insights that both strengthen  and  challenge  our  nascent  theoretical  under- standing of forum information filtering in IS research.  In this 862 MIS Quarterly Vol. 43 No. 3/September 2019 section, we discuss these insights with respect to each of our research  questions,  and  we  consider  their  implications  for ongoing theoretical development.  Consistent with our theory- building approach, we employ reverse inferential reasoning (Poldrack 2006) to arrive at testable research propositions that can guide ongoing research and theory development in this area.  We note that these propositions, although supported by external theory and our experimental data, are speculative in nature and are intended as a starting point for future theori- zation in the IS domain. Q1:  Valence of Contextual Cues With respect to Question 1, our results show that the valence of  contextual  cues  influences  forum  information  filtering decisions.  Theory suggests that the role of contextual cues should be greatest when knowledge seekers lack the ability or motivation  to  analyze  the  information  content  (Petty  and Cacioppo 1986; Petty et al. 2005).  However, our results sug- gest that these cues exert an influence even for experienced knowledge seekers.  Our experimental design intentionally differs from prior studies in that participants were asked to render an initial judgment on the solution after viewing only the contextual cues; thus, it might be argued that reliance on these cues was artificially induced.  Nevertheless, because our participants were experienced programmers and knew they would be able to view the solution content before rendering a final judgment, it seems plausible that participants might disregard these cues entirely in favor of content-based eval- uation.    Instead,  we  observed  that  participants  were  more likely to select a solution when it had received positive valida- tion,  either  by  an  expert  or  by  the  community.    Although contrary to predictions of dual process theories, this result corresponds with some decision research showing that expert decision makers can be influenced by (even random) contex- tual cues presented in the decision-making context (Ariely et al. 2003; Northcraft and Neale 1987).  Moreover, the effect of contextual cues observed here is supported by recent research on forum information filtering.  For example, Meservy et al. (2014) showed that the ratings of forum solutions by knowl- edge  seekers  who  were  subject  matter  experts  tended  to correlate highly with the positive/negative indications of asso- ciated  validation  cues,  even  when  the  indications  of  these cues were inconsistent with the actual solution quality.  Taken together, these points of evidence imply that, in contrast to other  forms  of  technology-mediated  information  exchange mentioned  earlier  (Fadel  et  al.  2009;  Sussman  and  Siegal 2003), contextual cues play an important role in forum infor- mation filtering even when knowledge seekers possess the ability to evaluate solution content.  We propose: P1:  Information filtering decisions on online forums are  influenced  by  the  valence  of  contextual  cues, even among experienced knowledge seekers.  Posi- tive valence is associated with greater likelihood of solution retention. With respect to neural activity, we did not observe any brain regions  that  differentiated  between  positive  and  negative valence contextual cues.  Although we must exercise caution when  interpreting  a  null  result,  it  is  worth  noting  that  our operationalization of positive and negative valence is some- what different than what is normally used in the cognitive neuroscience literature—namely, positive and negative emo- tion (e.g., Russell 2003).  It may be that high or low expert or community validation levels themselves were not sufficiently emotion-laden  to  differentially  engage  emotional  valence processing, and thus did not result in differential activation patterns  in  our  study.    Alternatively,  our  results  could  be viewed  as  consistent  with  the  bipolarity  hypothesis  of valence, which suggests that positive and negative are pro- cessed on the same neural dimensions (Barrett and Russell 1998).  In short, contrary to our initial expectations, we failed to find evidence for distinct neural substrates responsible for processing positive and negative contextual cues.  We there- fore postulate the following: P2.  In forum information filtering, the processing of positively and negatively valenced contextual cues is neurologically non-differentiated. Q2:  Influence of Content Quality Our analysis shows that, when knowledge seekers possess the ability and motivation to do so, evaluation of content as high or low quality is highly influential in forum filtering decisions (Petty and Cacioppo 1986; Petty et al. 2005).  Experienced knowledge seekers are able use their existing mental frame- work as a sort of “conceptual scaffolding” that enables judg- ments  about  the  viability  of  a  proposed  solution.    For example, the aspiring chef may use basic food pairing prin- ciples  to  determine  if  a  recommended  recipe  is  likely  to produce  the  desired  result,  whereas  a  programmer  would Meservy et al./An fMRI Exploration of Information Processing apply understanding of basic data structures, design patterns, or algorithms to assess a proposed solution to a programming problem.    The  results  of  our  experiment  confirm  that  for experienced knowledge seekers, content-based evaluation can have a significant influence in forum information filtering, similar to that observed in other technology-mediated infor- mation  seeking  contexts  such  as  knowledge  repositories (Fadel et al. 2009), email (Sussman and Siegal 2003), and online communities (Zhang and Watts 2008).  Importantly, however, for forum information filtering, this influence does not  occur  at  the  exclusion  of  contextual  cues,  which  also appear to influence judgments of even experienced knowledge seekers. P3:  Content quality has a significant influence on forum filtering decisions (assuming motivation and ability to evaluate content). From a neurocognitive perspective, we observed activation differences between solutions receiving a high or low final rating—specifically,  large  clusters  of  activation  in  the bilateral  anterior  insula  for  high-quality  solutions.    The anterior insula, along with the dorsal anterior cingulate cortex (dACC), is a major hub in the salience network, a set of brain regions that are activated for attentional capture by stimuli that are behaviorally or biologically important (Menon 2011). The salience network is thought to integrate and mediate the interplay between emotional and executive control processes (Menon 2011).  Consistent with our findings, this network has been  shown  to  be  involved  in  engaging  central  executive functions (such as attention and working memory) (Goulden et al. 2014; Menon and Uddin 2010), which are crucial for evaluating information as in the forum filtering task.  Other evidence  suggests  that  the  anterior  insula  is  involved  in domain-specific task-level control and focal attention (Nelson et al. 2010).  Ploran et al. (2007) found that activation of the anterior insula and dACC tracked with the accumulation of evidence in a perceptual recognition paradigm.  Accumulator models of decision making posit that evidence accumulates over time, until finally reaching a threshold corresponding to a  certain  response  (van  Vugt  et  al.  2016).    Using  reverse inference of participants’ mental processes from the activation data  observed,  we  propose  that  such  a  process  may  have occurred  during  our  experiment  as  participants  evaluated potential solutions and eventually recognized those that were of high quality.  Specifically, our results suggest that content- based evaluation of forum solutions could entail an evidence accrual  process  wherein  knowledge  seekers  engage  their executive and memory-based neural faculties to effectively “build a case” in support of the solution they are evaluating. Identification of errors in low-quality solutions would essen- tially short-circuit this process, potentially explaining why these regions were less active for low-quality solutions. MIS Quarterly Vol. 43 No. 3/September 2019 863 Meservy et al./An fMRI Exploration of Information Processing P4:    Evaluating  forum  solution  content  as  high quality  involves  neural  functions  associated  with accumulation of evidence and executive functions such as attention and working memory. Q3:  Relative Influence of Expert- and Community-Based Contextual Cues Many studies of technology-mediated information processing have  examined  only  one  contextual  cue,  typically  source credibility  (Sussman  and  Siegal  2003;  Zhang  and  Watts 2008).  In this study, we extend the boundaries of prior work by examining the understudied but important contextual cue of validation, and theorizing on the comparative influence of two  types  of  validation—expert  and  community—on  the filtering process.  Our results show that community validation cues have a much larger influence on filtering decisions than do expert validation cues, a finding that corroborates literature in other domains (Dellarocas et al. 2007; Zhang et al. 2010). This finding points to a number of interesting possibilities for further theoretical development in this area, including explor- ation of how and why social, community-based cues are more influential.  For example, social identity theory suggests that people tend to place more trust in others with whom they identify as being part of a homogeneous group than those perceived  to  be  outside  the  group  (Nesje  2009;  Tanis  and Postmes 2005).  This perspective could potentially explain the elevated influence of community-based cues that originate from  fellow  knowledge  seekers  (e.g.,  “someone  like  me”) over those that originate from more removed experts.  This leads us to the following proposition: P5:  Community-based cues are more influential in forum information filtering decisions than expert- based cues, possibly due to social identification of forum knowledge seekers with other network parti- cipants. From a neural perspective, we did not find any significant activation differences for expert and community validation, possibly  indicating  a  common  neural  index  of  the  social cognition  associated  with  validation  cues  originating  from expert and community sources.  This is at least partially con- sistent  with  other  literature  that  has  examined  the  neural pathways  of  social  influence.    For  example,  Mason  et  al. (2009)  conducted  an  experiment  in  which  participants evaluated symbols that they were told had been evaluated by a  community  (defined  as  “hundreds  of  people”)  as  either preferred or not preferred.  Consistent with other studies on the neuropsychology of social influence (Amodio and Frith 2006; Gallagher and Frith 2003; Mason and Macrae 2008), their results showed that the mere presence of the social rating 864 MIS Quarterly Vol. 43 No. 3/September 2019 was associated with greater activation in the medial prefrontal cortex, suggesting a possible neural index for a normative channel of social influence in general (Deutsch and Gerard 1955).    However, our result contrasts with other research, which has shown different neural activation patterns asso- ciated with expert- and community-based cues.  For example, Seiler and Walden (2016) conducted an experiment in which participants  decided  whether  to  strategically  default  on  a mortgage loan based on either the decision of a real-estate expert, decisions of their homeowner peers, or no decision information.  Similar to other research, they found that certain brain  areas  (e.g.,  the  occipital  pole,  the  lateral  occipital complex, and the occipital fusiform gyrus) were generally more active in the presence of either expert- or community- based  recommendations.    However,  they  also  found  that decisions associated with expert opinions involved greater activations in the left inferior parietal lobe, whereas decisions associated  with  peer  opinions  were  associated  with  right inferior parietal lobe and the right visual cortex, a difference they ascribe to informational herding versus social herding, respectively.  One important distinction between these studies is  that  our  experiment  involved  rating  solutions  that  were objectively high or low quality, whereas Seiler and Walden asked participants to make mortgage default decisions that had no normatively correct answer.  The results we observed imply that in normative information filtering scenarios, the distinction  between  social  and  informational  channels  of influence may be diminished proportionally to the partici- pant’s  ability  to  evaluate  the  solution  for  themselves  and arrive at the objective “right answer.”  In short, we propose that: P6:    In  normative  information  filtering  tasks,  the neural processing of expert- and community-based contextual  cues  are  handled  by  common  neural systems responsible for processing social influence.  Q4:  Relative Influence of Content and Contextual Cues Our  results  offer  insights  into  the  relative  influence  of content- and context-based processing that both confirms and contrasts  with  prior  work.    Past  research  on  technology- mediated  information  seeking  has  pointed  to  a  more prominent role for content-based processing in some domains (Fadel  et  al.  2009;  Sussman  and  Siegal  2003;  Zhang  and Watts 2008) and contextual processing in others, including network  forums  (Fadel  et  al.  2015;  Meservy  et  al.  2014).  These  studies  reached  their  conclusions  by  allowing  for simultaneous occurrence of both types of processing and then deriving the relative importance of these channels through post hoc participant reports or in situ observational data from an eye tracking device.  Although this approach is certainly valuable for observing unconstrained information processing patterns, our experimental design in this study offers a unique perspective  by  employing  a  methodology  that  explicitly induces each type of processing separately.  Our results for model  2.1  show  that  when  participants  consume  content- based cues, they exert a larger influence on filtering decisions than does either of the context-based cues we studied (al- though contextual cues still remain influential).  This implies that experienced knowledge seekers may reference contextual cues to identify solutions worthy of further consideration, but still rely on an evaluation of the solution content to determine whether to adopt the solution.  For theoretical development, this  suggests  that  although  contextual  cues  have  been repeatedly  shown  to  influence  filtering  decisions  of  even experienced  knowledge  seekers,  content-based  processing remains  the  primary  mechanism  whereby  solutions  are ultimately adopted. P7:    When  knowledge  seekers  possess  adequate motivation and ability, evaluation of solution content has a greater influence on forum solution adoption decisions than does evaluation of contextual cues. Our fMRI analysis for Question 4 reveals robust effects for content- versus context-based processing.  For the former, we found activation of the left middle frontal gyrus, left angular gyrus, and left anterior middle temporal gyrus.  These regions are generally associated with the semantic processing net- work, which governs encoding and understanding of meaning associated with words and objects (Price 2010; Wagner et al. 2001).  For context-based processing, we found that the left posterior middle temporal gyrus (pMTG) was significantly activated.  The pMTG has also been implicated in semantic processing, although it is thought to fulfill a more regulatory function involving selective information retrieval and integra- tion  of  simple  automatic  semantic  processing  with  goal- oriented cognition (Davey et al. 2016).  These results suggest at least two qualitatively different neurological mechanisms underlying forum information filtering:  one involving effort- ful semantic encoding of solution content and one involving more automatic judgments based on contextual cues.  Such an account is consistent with predictions of dual-process theories of cognition (Eagly and Chaiken 1984; Petty and Cacioppo 1986), which posit a central (systematic) route in which the semantics of the information are carefully evaluated, and a peripheral (heuristic) processing route in which quicker judg- ments are achieved based on application of rules associated with contextual elements.  Forum contextual cues are self- evident and straightforward; the information they convey (i.e., positive or negative valence) can be consumed in fractions of a second, thus requiring a shallower level of cognitive pro- cessing.    Evaluating  solution  content,  on  the  other  hand, Meservy et al./An fMRI Exploration of Information Processing requires  the  knowledge  seeker  to  more  deeply  assess  the semantics of the  solution, carefully evaluating it against a mental representation of the solution domain to ascertain its quality.    Both  quantitative  and  qualitative  differences  in neural  activation  patterns  have  been  associated  with  deep versus shallow encoding (Galli 2014); regions such as the left middle  frontal,  left  middle  temporal,  and  left  angular  gyri have commonly been associated with deeper semantic and language-based processing that might feature more promi- nently in content-based filtering (Price 2010; Wagner et al. 2001).    Our  results  offer  additional  evidence  that  distinct types of neurological activity are indeed associated with the processing of certain forum elements, lending credence to the utility  of  dual  process  theories  of  cognition  in  explaining forum information filtering behaviors. P8a:  Content-based evaluation of forum solutions invokes  neural  systems  associated  with  deep semantic processing. P8b:  Context-based evaluation of forum solutions invokes  neural  systems  associated  with  selective information  retrieval  and  automatic  semantic processing. Q5:  Interaction of Congruent Versus Incongruent Cues Our final question explored how filtering judgments are influ- enced by the combined (interaction) effects of both contextual cues and content.  First, with respect to contextual cues alone, one  might  expect  that  the  combined  interactive  effects  of multiple cues would be greater than either cue individually. Although the results of our ordinal regression analyses do not allow us to infer statistical generalization for this idea, it is interesting to note the pattern of results observed for our par- ticular sample, as shown in Figure 1.  It is apparent from this figure that solutions with low expert and community valida- tion  levels  (LL  solutions)  had  the  greatest  probability  of receiving the lowest rating of 1, whereas solutions with high levels on both context cues (HH solutions) had the highest likelihood of receiving the highest rating of 5.  This can also be  extended  to  the  two  lowest  and  two  highest  validation levels:  LL solutions had a cumulative probability of 94.3% of receiving a rating of 1 or 2 (next highest was HL at 71.6%), whereas the probability of HH solutions receiving a rating of 4  or  5  was  93.5%  (next  highest  was  LH  at  68.4%).    One interesting pattern from this figure is that the probabilities of the two high-community-validation conditions and the two low-community-validation conditions are roughly parallel to each other (suggesting no interaction with expert validation), except at the endpoints of the rating scale.  The diverging pro- MIS Quarterly Vol. 43 No. 3/September 2019 865 Meservy et al./An fMRI Exploration of Information Processing babilities between LL and HL at the low end, and HH and LH at the high end, suggest that context cues may exhibit some interactive influence for solutions judged to fall at either of these extremes, although the effect may be tempered in the mid-range.  One interesting theoretical possibility is that deci- sion makers might initially anchor to the indication of one of the context cues (e.g., community validation) to decide on an initial rating, then adjust the anchor up or down depending on the values of the other context cue(s) available. P9:    The  interactive  effect  of  multiple  contextual cues  on  filtering  judgments  is  most  pronounced when solutions are judged to be of very high or very low quality. When community and expert validation levels were in con- flict, there was a network of brain regions that was differ- entially active, notably, the left vlPFC and IFG.  Inferring from previous research, the situation where expert and com- munity validation levels differ, or are incongruent, can be viewed as a form of prediction error where participants expect one outcome and become surprised when there is a conflict. Previous studies on prediction error using reward paradigms have shown that the striatum, anterior cingulate cortex, and lateral  prefrontal  cortex  are  reliably  activated  in  such paradigms (Garrison et al. 2013).  Other studies have demon- strated that the lateral prefrontal cortex is reliably activated when  a  prediction  error  occurs  (Corlett  et  al.  2004).    Our results are consistent with these findings.  The vlPFC has also been associated with response conflict where two different responses  are  elicited  and  in  response  inhibition  (Ridder- inkhof et al. 2004) and is part of the frontoparietal attention network (Petersen and Posner 2012).  Thus, activation here could also reflect response inhibition or increased attention in the face of incongruent cues.  For theory, our results show that disagreement between contextual cues does have a mea- surable effect on the filtering process of forum users, who seem  to  expend  some  cognitive  effort  considering  (and perhaps attempting to resolve) the discrepancy.  P10:  Evaluating incongruent contextual cues on a network forum activates neural systems associated with prediction error. Another interesting implication of our results is the interaction of  contextual  cues  and  content.    Information  processing research has long suggested that contextual and content-based processing do not operate in isolation but in tandem (Chaiken 1987; Eagly and Chaiken 1984).  Our results confirm that filtering judgments for high- and low-quality solutions are not constant but are instead swayed by the indications of contex- tual cues, particularly for low-quality solutions (see Figures 866 MIS Quarterly Vol. 43 No. 3/September 2019 2 and 3).  This is consistent with prior information processing theory,  which  has  shown  that  contextual  cues  can  bias  or attenuate later judgments based on information content (Chai- ken and Maheswaran 1994).  Importantly, our results suggest that contextual cues serve as an anchor to subsequent evalua- tion of solution content, which may lead knowledge seekers to ascribe more or less value to a solution than they otherwise would  if  relying  on  content-based  evaluation  alone.    An- choring and adjustment is a widely observed psychological phenomenon (Furnham and Boo 2011) and has been shown to operate  even  in  contexts  where  experts  make  evaluation decisions within their domain of expertise (e.g., Northcraft and Neale 1987); however, it has not been a focus of research on  technology-mediated  information  filtering.    Our  results suggest that how and under what conditions contextual cue anchoring affects information filtering judgments in online forums  is  an  important  question  for  future  theoretical development. P11:  Content-based evaluation of forum solutions is influenced by the indications of contextual cues, which  serve  as  an  anchor  to  content-based judgments. From  a  neural  perspective,  we  explored  if  there  would  be activation differences due to conflict between context- and content-based cues, possibly due to cognitive dissonance or expectation violation.  Previous research has shown that the anterior cingulate cortex and the dorsolateral prefrontal cortex demonstrate activation differences in situations of cognitive dissonance (Izuma et al. 2010).  However, we did not observe any differential activation in situations where participants’ final ratings were congruent with the community and expert validations versus when they were incongruent.  This is in contrast to the behavioral result that indicated that contextual cues did in fact influence participants’ subjective ratings of the proposed solutions.  One potential explanation for this could  be  that  when  forum  users  are  experienced,  content- based judgments are sufficiently strong so as to render any discrepancy with contextual cues of little concern.  In other words, although contextual cues may serve to nudge content- based judgments in one direction or another, forum users do not appear to expend cognitive energy trying to resolve dis- crepancies.  Instead, they simply make their filtering decisions based primarily on their evaluation of solution content regard- less of what the contextual cues indicate. P12:  When solution content quality is incongruent with the indications of contextual cues, experienced forum users do not attempt to cognitively resolve the incongruence but instead make judgments based on evaluation of content. In  summary,  the  neural  results  of  our  study  offer  several important theoretical contributions that align with proposed opportunities for NeuroIS research identified by Dimoka et al. (2011).  First, this study is the first to link localized brain areas  to  information  filtering  tasks  on  network  forums, identifying specific areas of neural activity that are associated with  forum  filtering  and  allowing  for  inference  of  the underlying cognitive mechanisms at work.  Establishing these neural generators is a critical step toward deeper theoretical understanding  of  the  cognitive  processes  that  underlie technology-mediated information filtering tasks.  Second, the fMRI  protocol  utilized  in  our  experiment  allows  for  more proximal  observation  of  underlying  mental  processes  that could not be assessed through more conventional methods such  as  participant  self-reports,  or  even  other  previously employed  physiological  techniques  such  as  eye  tracking (Fadel et al. 2015; Meservy et al. 2014).  Finally, our study offers  a  complementary  viewpoint  to  other  electronic  net- works of practice studies by both supplementing existing data sources with brain imaging data, and providing neuro-level insights that both support and challenge previous IS research.  Our neural results, although novel in the IS literature, point to brain  regions  and  underlying  cognitive  functions  that  are largely consistent with insights from broader neuroscience research.  This reaffirms the complexity of information fil- tering cognition in network forums, and the need for ongoing theoretical refinement surrounding the nuances of information filtering  in  this  context.    The  exploratory,  question-based approach taken in this study, although still uncommon in IS research, offers a useful template for future neuro-research in areas where there is little guidance about the neurocorrelates of IS stimuli.  Figure 4 presents a graphical theoretical model that summarizes the research propositions derived from our results. Implications for Practice For practitioners, this study highlights several practical impli- cations related to the design, development, and support of network forums. Confirming past research (Fadel et al. 2015; Meservy et al. 2014), this study highlights the importance of contextual cues in evaluating solutions in forums.  Not only should contextual cues  be  included,  they  should  be  employed  in  a  way  that influences the ability of knowledge seekers to find and con- sider potential solutions.  Interestingly, there are still many knowledge forums that lack useful contextual cues that can serve as a proxy for content quality. We found support for the idea that the valence of contextual cues  influences  information  filtering  decisions  of  forum Meservy et al./An fMRI Exploration of Information Processing knowledge seekers.  This finding underscores the importance of providing cues that can represent both positive and nega- tive evaluations of the content presented.  Forum owners and designers should consider contextual cues that convey both positive and negative information such as aggregate scores, percentages, and other valenced representations rather than only positive or negative indicators in isolation. Perhaps the most significant practical implication from this study related to contextual cues is the influence of different types of validation.  Previous research (Meservy et al. 2014) highlighted the importance of validation as a contextual cue and showed that it should be included in network forums.  In this study, we extend this work by investigating the effects of two different types of validation:  community and expert.  Our results suggest that community validation is more influential than  expert  validation.    Although  some  network  forums restrict the validation of content to experts or moderators, we suggest that forums also provide mechanisms to allow the community to validate content. Designers  should  also  consider  the  relative  accuracy  of various contextual cues and highlight not only those that are most influential but also those that provide the most faithful representation  of  the  underlying  content.    As  such,  forum designers need to consider which cues to display, how various contextual cues should be arranged, and how multiple solu- tions should be presented based on the relative strength of associated  cues.    In  our  observation,  most  forums  present solutions  in  reverse  chronological  order,  with  more  recent contributions listed first.  Alternatively, forum designers could consider first presenting solutions containing certain combina- tions of contextual cues (e.g., solutions validated by an expert and  highly  rated  by  the  community),  but  should  exercise caution to avoid self-reinforcing biases. Our results suggest that certain combinations of contextual cues are processed differently by the brain.  Forum designers should be aware that conflicting cues invoke different cogni- tive  processing  patterns  and  may  produce  error-detection- related processing, which might lead to users focusing on the conflict  and  having  lower  confidence  in  the  presented solutions. We suggest that more designers incorporate contextual cues as explicit filtering criteria in the knowledge acquisition pro- cess.  This recommendation not only applies to individual network forums but also extends to search engines that index multiple forums.  In addition to providing keyword terms, the ability to search, sort, and filter by contextual cues would allow knowledge seekers to form and refine their considera- tion set by focusing on the most probable content.  Although some search engines incorporate contextual cues related to MIS Quarterly Vol. 43 No. 3/September 2019 867 Meservy et al./An fMRI Exploration of Information Processing Figure 4.  Theoretical Model and Research Propositions 868 MIS Quarterly Vol. 43 No. 3/September 2019 product information (Litza 2016), to our knowledge few, if any, incorporate contextual cues related to information assets that  are  indexed  by  search  engines.    Additionally,  we  are unaware of any search engines that allow users to specify the relative importance of these cues during the search process. Limitations and Future Research This study has some limitations.  First, as with any experi- mental research, external validity may be limited due to the controls  and  context  of  the  experiment.    We  attempted  to maximize  internal  and  external  validity  by  developing  an experimental  instrument  that  was  based  on  actual  online forums and content and by recruiting experienced software developers who use network forums to solve problems.  Still, having participants evaluate forum solutions within an fMRI machine is unavoidably different than a similar task in a more natural setting.  Unlike many fMRI studies that simply display stimulus  materials  in  rapid  succession,  we  developed  an interactive instrument that allowed participants to engage in systematic processing of information.  However, we inten- tionally  separated  contextual  processing  from  content processing.  Although this design was purposeful and yielded interesting results, all of these circumstances pose potential threats to external validity; therefore, additional research is needed to corroborate our findings and generalize them to a broader context. Second,  to  preserve  internal  validity,  contextual  cues  and associated information such as expert name and information, as well as avatars, were randomized to allow us to isolate the influence of different types of network forum information. Therefore, even though certain elements might introduce a bias (e.g., more complex cognitive processing associated with faces), the influence of these cues was randomized across participants and conditions.  Further, in our experiment, the indications of the contextual cues had no correlation to the actual quality of the solutions.  Even though participants were told in verbal and written instructions that each solution had been rated by an expert and by the community members, it is still possible that participants could have doubted the validity of the expert and community ratings. Third, despite our efforts to attract a diverse population of programming professionals, our final sample was 93% male. Although this is reflective of the general skewed distribution of  males  in  high  tech  industries  (Murthy  2014),  it  may adversely affect the generalizability of our results. Finally, although the use of fMRI technology allows us to observe cognitive processing by detecting blood oxygenation Meservy et al./An fMRI Exploration of Information Processing levels relative to a baseline or comparative condition, it does not offer a perfect reflection of actual cognition.  Neverthe- less,  to  our  knowledge,  this  is  one  of  the  first  studies  to investigate cognitive processing associated with information filtering tasks on network forums.  We encourage additional research  using  fMRI  and  other  techniques  to  deepen  our understanding of how information influences decision making online.    Alternative  neuroimaging  techniques  can  provide enhanced  temporal  (e.g.,  EEG)  and  spatial  (e.g.,  PET) resolution,  which  will  add  to  our  understanding  of  these phenomena. Several additional opportunities exist for future work to build upon our findings and extend theoretical development in this area.  For example, our study used one operationalization of contextual cues, but other ways of implementing these cues might alter their relative influence.  Community votes, for instance, may take the form of raw vote counts or star ratings, while  expert  ratings  may  be  operationalized  in  similarly diverse ways.  Moreover, contextual cues can also be com- bined in different ways (i.e., solutions could be validated by experts  who,  in  turn,  are  ratified  by  the  community).    A detailed  exploration  of  the  effects  of  different  types  of contextual cues and their combinations on forum information filtering decisions is uncharted territory in the IS literature, but constitutes a critical step for ongoing theoretical develop- ment in this area.  Another interesting question concerns the circumstances under which contextual cues anchor content- based judgments and whether the sequence of exposure to different types of cues influences this anchoring effect.  In short, our results and theoretical propositions reveal a plethora of interesting avenues for additional theoretical refinement surrounding  how  forum  elements  are  operationalized  and combined and how these configurations affect the information processing patterns of knowledge seekers. Conclusion In  an  era  of  unprecedented  access  to  information,  online forums  sponsored  by  electronic  networks  of  practice  will continue to proliferate as a primary source of technology- mediated information exchange, necessitating deeper under- standing among both scholars and practitioners of how such information is evaluated, filtered, and consumed.  This study extends the nascent but growing body of literature in this area by  offering  a  NeuroIS  perspective  on  forum  information filtering.  We identify two types of contextual cues involved in network forums and confirm the importance of validation, especially community validation, in information filtering deci- sions.    Moreover,  utilizing  fMRI  data,  our  study  provides direct  empirical  evidence  of  the  diverse  neurological  pro- MIS Quarterly Vol. 43 No. 3/September 2019 869 Meservy et al./An fMRI Exploration of Information Processing cesses involved in forum information filtering, showing how evaluation of various types of context- and content-based cues engages different neurocognitive mechanisms and leads to different filtering outcomes.   We encourage future research that builds on the groundwork laid by this study to elucidate further  the  behavioral  and  neural  underpinnings  of  forum information filtering. References Amblee,  N.,  and  Bui,  T.    2007.    “Freeware  Downloads:    An Empirical  Investigation  Into  the  Impact  of  Expert  and  User Reviews On Demand for Digital Goods,” in Proceedings of the Americas Conference on Information Systems, Keystone, CO. Amodio, D. M., and Frith, C. D.  2006.  “Meeting of Minds:  The Medial Frontal Cortex and Social Cognition,” Nature Reviews Neuroscience (7:4), pp. 268-277. Anderson, J. R.  1990.  Cognitive Psychology and Its Implications (3rd ed.), New York:  W. H. Freeman. Ariely, D., Loewenstein, G., and Prelec, D.  2003.  “‘Coherent Arbi- trariness’:  Stable Demand Curves Without Stable Preferences,” The Quarterly Journal of Economics (118:1), pp. 73-106. Avants, B., Epstein, C., Grossman, M., and Gee, J.  2008.  “Sym- metric Diffeomorphic Image Registration with Cross-Correlation:  Evaluating Automated Labeling of Elderly and Neurodegener- ative Brain,” Medical Image Analysis (12:1), pp. 26-41. Barrett, L. F., and Russell, J.  1998.  “Independence and Bipolarity in  the  Structure  of  Current  Affect,”  Personality  and  Social Psychology (74:4), pp. 967-984. Beck, R., Pahlke, I., and Seebach, C.  2014.  “Knowledge Exchange and Symbolic Action in Social Media-Enabled Electronic Net- works  of  Practice:    A  Multilevel  Perspective  on  Knowledge Seekers and Contributors,” MIS Quarterly (38:4), pp. 1245-1270. Bhattacherjee, A., and Sanford, C.  2006.  “Influence Processes for Information Technology Acceptance:  An Elaboration Likelihood Model,” MIS Quarterly (30:4), pp. 805-825. Botvinick, M. M., Cohen, J. D., and Carter, C. S.  2004.  “Conflict Monitoring and Anterior Cingulate Cortex:  An Update,” Trends in Cognitive Sciences (8:12), pp. 539-546. Brandt, J., Guo, P. J., Lewenstein, J., Dontcheva, M., Klemmer, S. R., and Francisco, S.  2009.  “Two Studies of Opportunistic Programming:    Interleaving  Web  Foraging,  Learning,  and Writing  Code,”  in  Proceedings  of  the  ACM  Conference  on Human Factors in Computing Systems, pp. 1589-1598. Bush,  G.,  Luu,  P.,  and  Posner,  M.  I.    2000.    “Cognitive  and Emotional Influences in Anterior Cingulate Cortex,” Trends in Cognitive Sciences (4:6), pp. 215-222. Chaiken, S.  1987.  “The Heuristic Model of Persuasion,” in Social Influence:  The Ontario Symposium, M. P. Zanna, J. M. Olson, and C. P. Herman (eds.), Hillsdale, NJ:  Erlbaum, pp. 3-39. Chaiken, S., and Maheswaran, D.  1994.  “Heuristic Processing Can Bias  Systematic  Processing:    Effects  of  Source  Credibility, Argument Ambiguity, and Task Importance on Attitude Judg- ment,” Journal of Personality and Social Psychology (66:3), pp. 460-473. 870 MIS Quarterly Vol. 43 No. 3/September 2019 Christensen, R.  H.  B.   2015.  “Ordinal:  Regression Models for Ordinal Data” (https://cran.r-project.org/web/packages/ ordinal/ index.html). Corlett,  P.  R.,  Aitken,  M.  R.  F.,  Dickinson,  A.,  Shanks,  D.  R., Honey, G. D., Honey, R. A. E., Robbins, T. W., Bullmore, E. T., and Fletcher, P. C.  2004.  “Prediction Error During Retrospec- tive  Revaluation  of  Causal  Associations  in  Humans:    fMRI Evidence in Favor of an Associative Model of Learning,” Neuron (44:5), pp. 877-888. Cox, R. W.  1996.  “AFNI:  Software for Analysis and Visualization of Functional Magnetic Resonance Neuroimages,” Computers and Biomedical Research (29:3), pp. 162-173. Cumming, G.  2009.  “Inference by Eye:  Reading the Overlap of Independent Confidence Intervals,” Statistics in Medicine (28:2), pp. 205-220. Davey,  J.,  Thompson,  H.  E.,  Hallam,  G.,  Karapanagiotidis,  T., Murphy, C., De Caso, I., Krieger-Redwood, K., Bernhardt, B. C., Smallwood, J., and Jefferies, E.  2016.  “Exploring the Role of the Posterior Middle Temporal Gyrus in Semantic Cognition:  Integration  of  Anterior  Temporal  Lobe  with  Executive  Pro- cesses,” NeuroImage (137), pp. 165-177. Dellarocas, C., Zhang, X. M., and Awad, N. F.  2007.  “Exploring the Value of Online Product Reviews in Forecasting Sales:  The Case  of  Motion  Pictures,”  Journal  of  Interactive  Marketing (21:4), pp. 23-45. Deutsch, M., and Gerard, H. B.  1955.  “A Study of Normative and Informational Social Influences upon Individual Judgment,” The Journal of Abnormal and Social Psychology (51:3), pp. 629-636. Dimoka, A.  2011.  “How to Conduct a Functional Magnetic Reson- ance (fMRI) Study in Social Science Research,” MIS Quarterly (36:3), pp. 811-840. Dimoka,  A.,  Pavlou,  P.  A.,  and  Davis,  F.  D.    2011.    “Research Commentary—NeuroIS:    The  Potential  of  Cognitive  Neuro- science for Information Systems Research,” Information Systems Research (22:4), pp. 687-702. Eagly, A. H., and Chaiken, S.  1984.  “Cognitive Theories of Per- suasion,” Advances in Experimental Social Psychology (17), pp. 267-359. Fadel, K. J., Durcikova, A., and Cha, H. S.  2009.  “Information Influence in Mediated Knowledge Transfer:  An Experimental Test of Elaboration Likelihood,” International Journal of Knowl- edge Management (5:4), pp. 26-42. Fadel, K. J., Meservy, T. O., and Jensen, M. L.  2015.  “Exploring Knowledge Filtering Processes in Electronic Networks of Prac- tice,” Journal of Management Information Systems (31:4), pp. 158-181. Friederici, A. D., Rüschemeyer, S.-A., Hahne, A., and Fiebach, C. J.  2003.  “The Role of Left Inferior Frontal and Superior Temporal Cortex in Sentence Comprehension:  Localizing Syntactic and Semantic Processes,” Cerebral Cortex (13:2), pp. 170-177. Furnham, A., and Boo, H. C.  2011.  “A Literature Review of the Anchoring Effect,” The Journal of Socio-Economics (40:1), pp. 35-42. Gallagher, H. L., and Frith, C. D.  2003.  “Functional Imaging of ‘Theory  of  Mind,’”  Trends  in  Cognitive  Sciences  (7:2),  pp. 77-83. Galli, G.  2014.  “What Makes Deeply Encoded Items Memorable?  Insights into the Levels of Processing Framework from Neuro- imaging and Neuromodulation,” Frontiers in Psychiatry (5:61). Garrison, J., Erdeniz, B., and Done, J.  2013.  “Neuroscience and Biobehavioral  Reviews  Prediction  Error  in  Reinforcement Learning:  A Meta-Analysis of Neuroimaging Studies,” Neuro- science and Biobehavioral Reviews (37:7), pp. 1297-1310. Gazzaniga, M.  2004.  The Cognitive Neurosciences, Cambridge, MA:  MIT Press. Goulden, N., Khusnulina, A., Davis, N., Bracewell, R., Bokde, A., and Mullins, P.  2014.  “The Salience Network Is Responsible for Switching between the Default Mode Network and the Central Executive Network:  Replication from DCM,” Neuroimage (99), pp. 180-190. Hoffmann, R., Fogarty, J., and Weld, D.  2007.  “Assieme:  Finding and Leveraging Implicit References in a Web Search Interface for Programmers,” in Proceedings of the 20th Annual ACM Sym- posium on User Interface Software and Technology, pp. 13-22. Izuma,  K.,  Matsumoto,  M.,  Murayama,  K.,  Samejima,  K., Sadato, N., and Matsumoto, K.  2010.  “Neural Correlates of Cognitive Dissonance and Choice-Induced Preference Change,” Proceedings of the National Academy of Sciences of the United States of America (107:51), pp. 22014-22019. Johnson,  M.  H.    2005.    “Subcortical  Face  Processing,”  Nature Reviews Neuroscience (6:10), pp. 766-774. Kawamoto,  T.,  Onoda,  K.,  Nakashima,  K.,  Nittono,  H.,  Yama- guchi, S., and Ura, M.  2012.  “Is Dorsal Anterior Cingulate Cortex Activation in Response to Social Exclusion Due to Expec- tancy Violation?  An fMRI Study,” Frontiers in Evolutionary Neuroscience (4), pp. 1-10. Klein, A., Andersson, J., Ardekani, B. A., Ashburner, J., Avants, B., Chiang,  M.-C.,  Christensen,  G.  E.,  Collins,  D.  L.,  Gee,  J., Hellier, P., Song, J. H., Jenkinson, M., Lepage, C., Rueckert, D., Thompson, P., Vercauteren, T., Woods, R. P., Mann, J. J., and Parsey, R. V.  2009.  “Evaluation of 14 Nonlinear Deformation Algorithms Applied to Human Brain MRI Registration,” Neuro- Image (46:3), pp. 786-802. Kolling, N., Behrens, T. E. J., Mars, R. B., and Rushworth, M. F. S.  2012.  “Neural Mechanisms of Foraging,” Science (336:6077), pp. 95-8. Lindquist,  K.  A.,  Satpute,  A.  B.,  Wager,  T.  D.,  Weber,  J.,  and Barrett, L. F.  2015.  “The Brain Basis of Positive and Negative Affect:  Evidence from a Meta-Analysis of the Human Neuro- imaging Literature,” Cerebral Cortex (26:5), pp. 1910-1922. Litza, T.  2016.  “How a Customer Reviews Strategy Can Impact SEO,”  Search  Engine  Watch,  September  6  (https:// searchenginewatch.com/2016/09/06/how-a-strategy-for- customer-reviews-can-impact-seo-brightonseo/;  accessed February 6, 2017). Mason, M. F., Dyer, R., and Norton, M. I.  2009.  “Neural Mech- anisms  of  Social  Influence,”  Organizational  Behavior  and Human Decision Processes (110:2), pp. 152-159. Mason, M. F., and Macrae, C. N.  2008.  “Perspective-Taking from a Social Neuroscience Standpoint,” Group Processes & Inter- group Relations (11:2), pp. 215-232. Meservy et al./An fMRI Exploration of Information Processing Menon, V.  2011.  “Large-Scale Brain Networks and Psychopath- ology:  A Unifying Triple Network Model,” Trends in Cognitive Sciences (15:10), pp. 483-506. Menon, V., and Uddin, L.  2010.  “Saliency, Switching, Attention and  Control:    A  Network  Model  of  Insula  Function,”  Brain Structure and Function (214:5-6), pp. 655-67. Meservy, T. O., Jensen, M. L., and Fadel, K. J.  2014.  “Evaluation of  Competing  Candidate  Solutions  in  Electronic  Networks  of Practice,” Information Systems Research (25:1), pp. 15-34. Meyer-Gossner, M.  2013.  “Study:  Online Forums Still Popular and Leading Community Option (Infographic),” The Strategy Web, October 11 (http://www.thestrategyweb.com/study-online- forums-still-popular-and-leading-community-option-infographic; accessed April 19, 2017). Murthy, S.  2014.  “Women in Software Engineering:  The Sobering Stats,”  LinkedIn  Talent  Blog,  March  20    (https://business. linkedin.com/talent-solutions/blog/2014/03/women-in- engineering-the-sobering-stats; accessed May 2, 2018). Nelson, S. M., Dosenbach, N. U. F., Cohen, A. L., Wheeler, M. E., Schlaggar, B. L., and Petersen, S. E.  2010.  “Role of the Anterior Insula  in  Task-Level  Control  and  Focal  Attention,”  Brain Structure and Function (214:5-6), pp. 669-680. Nesje, K.  2009.  “Social Identity, Group Membership and Trust,” Thesis,  Master  of  Philosophy  in  Psychology,  Department  of Psychology, University of Oslo. Northcraft, G. B., and Neale, M. A.  1987.  “Experts, Amateurs, and Real Estate:  An Anchoring-and-Adjustment Perspective on Pro- perty Pricing Decisions,” Organizational Behavior and Human Decision Processes (39), pp. 84-97. Petersen, S. E., and Posner, M. I.  2012.  “The Attention System of the Human Brain:  20 Years After,” Annual Review of Neuro- science (35), pp. 73-89. Petty, R. E., and Cacioppo, J. T.  1986.  “The Elaboration Likeli- hood Model of Persuasion,” Advances in Experimental Social Psychology (19), pp. 123-205. Petty, R. E., Cacioppo, J. T., Strathman, A. J., and Priester, J. R.  2005.  “To Think or Not to Think:  Exploring Two Routes to Persuasion,” in Persuasion:  Psychological Insights and Perspec- tives, T. C. Brock and M. C. Green (eds.), Thousand Oaks, CA:  SAGE Publications, pp. 81-116. Ploran,  E.  J.,  Nelson,  S.  M.,  Velanova,  K.,  Donaldson,  D.  I., Petersen, S. E., and Wheeler, M. E.  2007.  “Evidence Accumula- tion and the Moment of Recognition:  Dissociating Perceptual Recognition Processes Using fMRI,” Journal of Neuroscience (27:44), pp. 11912-11924. Poldrack, R. A.  2006.  “Can Cognitive Processes Be Inferred from Neuroimaging Data?,” Trends in Cognitive Sciences (10:2), pp. 59-63. Price, C. J.  2010.  “The Anatomy of Language:  A Review of 100 fMRI  Studies  Published  in  2009,”  Annals  of  the  New  York Academy of Sciences (1191:1), pp. 62-88. R Core Team.  2017.  R:  A Language and Environment for Statis- tical Computing, Vienna Austria:  R Foundation for Statistical Computing. Ridderinkhof, K. R., van den Wildenberg, W. P. M., Segalowitz, S. J., and Carter, C. S.  2004.  “Neurocognitive Mechanisms of MIS Quarterly Vol. 43 No. 3/September 2019 871 Meservy et al./An fMRI Exploration of Information Processing Cognitive  Control:    The  Role  of  Prefrontal  Cortex  in  Action Selection,  Response  Inhibition,  Performance  Monitoring,  and Reward-Based  Learning,”  Brain  and  Cognition  (56:2),  pp. 129-140. Riedl, R., Davis, F., and Hevner, A.  2014.  “Towards a NeuroIS Research Methodology:  Intensifying the Discussion on Methods, Tools, and Measurement,” Journal of the Association for Infor- mation Systems (15:Special Issue), pp. i-xxxv. Riedl,  R.,  and  Léger,  P.-M.    2016.    Fundamentals  of  NeuroIS, Berlin:  Springer. Riedl, R., Mohr, P. N. C., Kenning, P. H., and Davis, F. D.  2011.  “Trusting  Humans  and  Avatars:    Behavioral  and  Neural  Evi- dence,” in Proceedings of the 32nd International Conference on Information Systems, Shanghai, China. Russell, J. A.  2003.  “Core Affect and the Psychological Construc- tion of Emotion,” Psychological Review (110:1), pp. 145-172. Seiler, M. J., and Walden, E.  2016.  “Using Neurological Evidence to  Differentiate  between  Informational  and  Social  Herding among Strategic Mortgage Defaulters,” Journal of Real Estate Research (38:3), pp. 453-471. Stylos, J., and Myers, B. A.  2006.  “Mica:  A Web-Search Tool for Finding API Components and Examples,” in Proceedings of the IEEE  Symposium  on  Visual  Languages  and  Human-Centric Computing, Brighton, UK, pp. 195-202. Sussman, S. W., and Siegal, W. S.  2003.  “Informational Influence in Organizations:  An Integrated Approach to Knowledge Adop- tion,” Information Systems Research (14:1), pp. 47-65. Tanis, M., and Postmes, T.  2005.  “A Social Identity Approach to Trust:  Interpersonal Perception, Group Membership and Trusting Behaviour,” European Journal of Social Psychology (35:3), pp. 413-424. “The Biggest Boards.”  2017.  (http://www.thebiggestboards.com/; accessed July 1, 2017). van Vugt, M. K., Beulen, M. A., and Taatgen, N. A.  2016.  “Is There Neural Evidence for an Evidence Accumulation Process in Memory Decisions?,” Frontiers in Human Neuroscience (10:93). vom Brocke, J., and Liang, T. P.  2014.  “Guidelines for Neuro- science Studies in Information Systems Research,” Journal of Management Information Systems (30:4), pp. 211-233. Wagner, A. D., Paré-Blagoev, E. J., Clark, J., and Poldrack, R. A.  2001.  “Recovering Meaning:  Left  Prefrontal Cortex Guides Controlled Semantic Retrieval,” Neuron (31:2), pp. 329-38. Wasko, M. M., and Faraj, S.  2005.  “Why Should I Share?  Exam- ining Social Capital and Knowledge Contribution in Electronic Networks of Practice,” MIS Quarterly (29:1), pp. 35-57. Zhang,  W.,  and  Watts,  S.  A.    2008.    “Capitalizing  on  Content:  Information Adoption in Two Online Communities,” Journal of the Association for Information Systems (9:2), pp. 73-94. Zhang, Z., Ye, Q., Law, R., and Li, Y.  2010.  “The Impact of E- Word-of-Mouth  on  the  Online  Popularity  of  Restaurants:    A Comparison  of  Consumer  Reviews  and  Editor  Reviews,” International Journal of Hospitality (29:4), pp. 694-700. 872 MIS Quarterly Vol. 43 No. 3/September 2019 About the Authors Thomas O. Meservy is an associate professor of Information Sys- tems at Brigham Young University.  He received a Bachelor’s in Management and a Master’s in Information Systems Management in 2001 from BYU and then worked in industry as a software devel- oper and architect.  In 2007 he received a Ph.D. in Management and a minor in Cognitive Science from the University of Arizona.  His research looks at how technology can be used to augment human abilities to generate, share, and evaluate information.  Tom uses a variety of research methods/tools including computer vision tech- niques, eyetracking, and fMRI.  His work has been published in the top Information Systems journals and conferences and much of his research has been funded. Tom is an experienced software developer and architect and has numerous industry certifications. Kelly J. Fadel is an associate professor of management information systems at the Jon M. Huntsman School of Business at Utah State University.  He received his Ph.D. from the University of Arizona in 2007.  His research areas include knowledge management, end- user learning, and cognitive aspects of information processing.  His research  has  appeared  in  journals  such  as  Information  Systems Research, Journal of Management Information Systems, Information & Management, Journal of Computer Information Systems.  His work has also been presented and recognized at several international information systems conferences. C.  Brock  Kirwan  is  an  associate  professor  of  Psychology  and Neuroscience at Brigham Young University.  He received his Ph.D. in Psychological and Brain Sciences from Johns Hopkins University in 2006.  Brock has a decade of experience conducting fMRI scans with patient populations at Johns Hopkins University, the University of California, San Diego, the University of Utah, and BYU. He has published numerous papers reporting fMRI and neuropsychological results  in  journals  such  as  Science,  Proceedings  of  the  National Academy of Sciences, Neuron, and Journal of Neuroscience, as well as  journals  in  the  field  of  information  systems  such  as  MIS Quarterly, Information Systems Research, Journal of Management Information  Systems,  Journal  of  the  Association  for  Information Systems, and European Journal of Information Systems. Rayman  D.  Meservy  is  an  associate  professor  of  Information Systems at Brigham Young University.  He received a Bachelor’s and a Master’s in 1977 from the BYU Marriott School of Accoun- tancy, and then worked as an internal auditor.  In 1985 he received his Ph.D. from the University of Minnesota in accounting with an emphasis in Information Systems and taught at Carnegie-Mellon before coming to BYU.  His research has involved various types of artificial intelligence, from expert systems to genetic algorithms. Publications  outlets  include  The  Accounting  Review,  Decision Support Systems, Auditing: A Journal of Practice and Theory, IEEE Transactions on Knowledge and Data Engineering, International Journal of Intelligent Systems in Accounting Finance & Manage- ment.  He served nine years as  treasurer for the Association for Information Systems. RESEARCH ARTICLE AN FMRI EXPLORATION OF INFORMATION PROCESSING IN ELECTRONIC NETWORKS OF PRACTICE Thomas O. Meservy Information Systems Department, Marriott School of Business, Brigham Young University, Provo, UT  84602  U.S.A.  {tmeservy@byu.edu} Kelly J. Fadel Department of Management Information Systems, Utah State University, Logan, UT  84322  U.S.A.  {Kelly.Fadel@usu.edu} C. Brock Kirwan Department of Psychology and Neuroscience Center, Brigham Young University, Provo, UT  84602  U.S.A.  {kirwan@byu.edu} Rayman D. Meservy Information Systems Department, Marriott School of Business, Brigham Young University, Provo, UT  84602  U.S.A.  {meservy@byu.edu} Appendix A Prior IS Research on Electronic Network of Practice Forums Recent IS research has begun to explore behavioral filtering patterns associated with content and contextual cues on a network forum.  Using eye-tracking technology, this work has shed light on the cues attended to during filtering (Meservy et al. 2014) and how the attentional switching patterns between these cues (e.g., evaluating all cues of a single solution versus comparing a single cue across multiple solutions) affects filtering accuracy (Fadel et al. 2015).  In the present study, we extend this prior work while making note of two important observations.  First, although these studies have shed light on the role of different types of cues in forum information filtering, they are limited with respect to their ability to elucidate the actual cognitive processes that underlie this filtering.  Gaze data from an eye-tracker can prompt inferences about the types of information attended to during the filtering process, but it is silent on the neurocognitive processes that occur.  This leaves several important questions for ongoing theory development.  For example, are different types of cues (e.g., content versus contextual) processed by different cognitive centers in the brain, which, depending on their relative activation levels, could produce more or less accurate filtering decisions? Or do similar neural mechanisms underlie both content and context-based processing, and any difference lies only in the type of information evaluated? Moreover, which types of cues are most important when filtering solutions, and how do combinations of cues affect this filtering process on both a behavioral and a cognitive level?  Second, prior studies have relied on dual process theories of cognition (Chaiken 1987; Petty and Cacioppo 1986) as a theoretical frame for examining information filtering on a network forum.  Originating in the domain of persuasion psychology, dual process theories posit that persuasion can occur via two primary cognitive routes:  the central (systematic) route, in which the arguments of the message itself are carefully evaluated, and the peripheral (heuristic) route, in which judgments are made primarily based on surrounding peripheral cues (Chaiken 1980; Petty et al. 2005; Petty and Cacioppo 1986).  Applying this framing to the context of solutions on a network forum, central route processing would entail evaluation of solution content, and peripheral route processing would rely on evaluation of surrounding contextual cues such as source expertise and validation (Fadel et al. 2015; Meservy et al. 2014).  We believe this conceptualization offers a useful lens for characterizing MIS Quarterly Vol. 43 No. 3—Appendices/September 2019 A1 Meservy et al./An fMRI Exploration of Information Processing different types of information filtering behaviors; however, dual process theorists have noted that cues themselves are not categorically central or peripheral, but instead can play a dualistic role, influencing judgments either centrally or peripherally depending on their context and relevance to the information content being evaluated (Chaiken and Trope 1999).  As observed by Petty et al. (2005, p.  110), “certain variables have a chameleon quality in that they induce different processes in different situations.  Therefore, any given variable should not be thought of as exclusively fulfilling any one role.” In this paper, our objective is not to label specific cues as strictly central or peripheral per se, but rather to explore the cognitive differences between filtering based on these cues.  We therefore employ the terms content and context to refer, respectively, to solution content and surrounding contextual cues such as expert and community validation. Appendix B Experimental Instrument Table B1.  Problem Descriptions Phase Training Problem Split a string on spaces Experiment Concatenate two lists Experiment Experiment Experiment Calculate the factorial of a number Identify the greatest element in an array Sum the values of an array Experiment Split array Experiment Check for palindrome Description Write a block of code that splits a string into separate strings everywhere there is a space. Write a block of code that takes two lists or arrays of integers and concatenates them together into a single new list or array. Write a block of code that calculates the factorial of an integer (the product of the integer and all the integers below it). Write a block of code that determines the largest value in an array of integers. Write a block of code that computes the sum of all the values in an integer array. Write a block of code that splits an array of integers into two separate arrays or lists at a predetermined point. Write a block of code that determines whether a string is a palindrome (a word is spelled the same forward or backward). Eight solutions for each problem written in C#, Java, or C++ were gathered from programming forums, standardized to C#, and validated for use in the experiment.  These languages were selected because they are syntactically similar to each other and are among the most popular modern  programming  languages  (Cass  2016;  TIOBE  2016).    The  figures  below  show  examples  of  these  solutions  in  the  experimental instrument. A2 MIS Quarterly Vol. 43 No. 3—Appendices/September 2019 Meservy et al./An fMRI Exploration of Information Processing Figure B1.  Sample Stimulus Figure B2.  Sample Blurred Stimulus (Context Phase) MIS Quarterly Vol. 43 No. 3—Appendices/September 2019 A3 Meservy et al./An fMRI Exploration of Information Processing Appendix C Experimental Procedure A high-level overview of the experimental procedure is shown in Figure C1.  When participants arrived at the MRI facility, they were presented with a consent form and again completed an MRI screening form to ensure their safety inside the scanner.  Participants were then shown an introductory video to acclimate them to the scanner and to explain the experimental instrument and associated task.  The video explained that each participant would be shown solutions to several programming problems and would be asked to rate each solution using a hand-held controller that operated the custom experimental instrument while in the scanner.  After the video, the researchers answered any questions related to the task, the experimental instrument, the programming solutions, or any safety concerns associated with the scanner.  Figure C1.  High-Level Overview of Experiment After the introductory/consent process, each participant was taken to the scanner room and prepared for the experiment.  The participant was first outfitted with headphones and a microphone to enable periodic communication with the researchers during the experiment.  This ensured the participant’s safety and ongoing comprehension of what s/he was asked to do.  The participant was then situated in the scanner, and an initial standard-resolution localization and structural scan (approximately 7 minutes) was conducted to capture the participant’s brain structure so that it could be co-registered with the functional MRI data.  Following the structural scan, a training run was conducted to familiarize the participant with the experimental instrument.  In this run, the participant was presented with four different solutions to a single programming problem.  Each solution was presented for a total of 30 seconds, comprising both the context and content phases described above.  Between each presented solution, there was a short,two-second break during which the participant was shown a baseline block (a gray screen with a black cross in the middle), as is common in fMRI experiments (Huettel et al. 2003; Jenkins et al. 2016).  At the conclusion of the training run, researchers an- swered any remaining participant questions before proceeding to the experimental task.  Figure C2 shows the timings for each block presented.  During the primary experimental task (27 minutes), the participant was shown each of the 48 programming solutions in sequence.  Participants viewed the experimental stimuli on a large MR-compatible monitor at the opening of the MRI scanner by means of a mirror attached to the head coil.  The participant used a four-button handheld controller to interact with the instrument and provide ratings of the likelihood of adopting the presented solutions.  Each solution was presented for a total of 30 seconds, comprising both the context and content phase described above, followed by a two-second break during which the participant was shown the baseline block.  As each context and content phase was self-terminated when the participant locked in a rating (see Figure C2), each of these events had a variable duration.  Consequently, in our fMRI individual-level (first-level) regression analyses described below, we modeled the context phase and content phase as variable- length events.  The time remaining in each 30-second block after participants had locked in their content rating was included with the 2-second inter-trial interval in the model’s baseline, thus accomplishing a random temporal jitter between trials in the model.  This represents a mixed blocked/event-related design (Petersen and Dubis 2012) where the task occurred in extended periods (as in a block design) but were of a variable duration and had a variable delay between them (as in an event-related design).  This design more closely mimics what a participant might do when seeking information from an online forum. To minimize cognitive burden and participant fatigue, solutions were grouped by problem, and the six problems were randomly grouped into two 3-problem blocks so that the participant could rest between blocks.  To avoid any confounding effects due to ordering, all other aspects of stimulus presentation were randomized, including problem order, solution order within each problem, expert and community validation levels, and information about the expert who validated the solution.  After concluding the primary experimental task, the participants were escorted out of the scanner to an adjoining room, where they completed a short survey that captured demographic information and perceptions about the experimental task.   A4 MIS Quarterly Vol. 43 No. 3—Appendices/September 2019 Meservy et al./An fMRI Exploration of Information Processing Figure C2.  Overview of Each Block Appendix D Ordinal Mixed Effects Regression Models Suitability   Before employing ordinal mixed effects regression models with both fixed and random effects, we estimated a series of preliminary models to determine whether multilevel analysis was appropriate for our data (i.e., whether the higher-order variables of solution, problem, and participant exerted discernable random effects on the dependent variable).  We began by estimating a single intercept-only baseline model with final rating as the dependent variable.  We then estimated a random-effects-only model with final rating as the dependent variable and random intercept effects for solution, problem, and participant.  A log likelihood comparison test revealed that the fit of the random-effects-only model improved significantly over that of the baseline (χ2 = 434.32, p < .001), indicating some explanatory power of the grouping variables.  To ascertain the magnitude of the individual random effects, we calculated an intraclass correlation (ICC) for each higher-order variable (Snijders and Bosker 2012), which indicates the proportion of total variance in the final rating explained by each higher-order variable.  Solution had the largest ICC (.34), followed by participant (.04) and problem (.00).  We tested the significance of these effects by comparing the fit of models that included each random effect independently against the fit of the baseline model.  Results showed no significant improvement in fit for problem, indicating that the problems into which the solutions were grouped did not affect the final ratings.  Effects for both solution (χ2 = 404.11, p < .001) and participant (χ2 = 13.989, p < .001) were significant, indicating that average final rating did vary somewhat by both participant and solution.  However, although participant effects were entirely random in our design, solutions were experimentally manipulated by altering their code quality, which could account for at least some of the between-solution variance in final ratings.  We therefore estimated an additional mixed-effects model that included code quality as a fixed-effect covariate.  As expected, the ICC of solution (.09) dropped substantially under this model; however, a log likelihood comparison still showed a significant random effect for solution (χ2 = 56.741, p < .001), indicating that final ratings may have been higher (or lower) for some solutions than for others due to experimentally exogenous factors.  Therefore, although the ICC values indicate relatively modest random effect sizes, we retained both participant and solution as higher- order random effects variables in our analyses to account for their potential explained variance in the solution ratings.  MIS Quarterly Vol. 43 No. 3—Appendices/September 2019 A5 Meservy et al./An fMRI Exploration of Information Processing Appendix E fMRI Analysis Two individual-level regression analyses were conducted to fit the ideal hemodynamic response to the brain data.  Both used six motion regressors (for roll, pitch, yaw, and translations in the X, Y, and Z directions) and seven polynomial regressors per run to account for scanner drift in addition to behavioral regressors coding for task conditions.  All behavioral regressors were modeled as a boxcar function with variable duration according to the participants’ latency to respond convolved with the canonical hemodynamic response. The first regression analysis separately modeled the four factorial combinations of high/low community and high/low expert validation levels in the context phase of each trial in order to test the effect of context cues on the preliminary ratings in the context phase.  To test the effect of the consistency between context cues and final subjective rating, the regression model also contained two regressors coding for whether the final subjective rating of the solution was consistent with both the expert and community validation (i.e., all high levels or all low levels).  Two more regressors coded for final ratings that were high or low but where the expert and community validation levels were mixed (one high and the other low).   The second regression analysis modeled four regressors according to whether the subjective participant rating was high or low in either the context phase (preliminary rating) or the content phase (final rating), regardless of the community or expert validation or the objective code quality.  These models, which were used to test processing in the content phase, were included under the rationale that participants’ neural activation patterns would correspond more closely with their perceptions of the information being presented (i.e., a solution believed by the participant to be high quality) than with the actual treatment condition.1  For these models, subjective ratings of 4 or 5 were collapsed as “high” and ratings of 1 or 2 were collapsed as “low.”  Structural data were first co-registered to the functional scans and then normalized to MNI template space using ANTs.  The results of the single-subject regression analyses (known as beta maps or parameter estimates) were blurred using an 8mm FWHM Gaussian and then normalized to MNI space using the transformation calculated from the structural scan alignment.  All group-level analyses described below were performed in MNI space and were masked for regions where we had spatial coverage in the functional scan for all participants in the sample, resulting in the exclusion of the more inferior aspect of the cerebellum since coverage of the cortex was prioritized.   We corrected for multiple comparisons using the AFNI 3dClustSim program, which uses Monte Carlo simulations to calculate the appropriate clusters of voxels that are large enough to be statistically significant (Forman et al. 1995; Xiong et al. 1995).  Spatial smoothness was estimated for each subject using AFNI program 3dFWHMx based on the residuals resulting from the individual-level regression analyses described above (see Cox et al. 2017).  The mean smoothness parameters for the group were used in the 3dClustSim program as the estimate of overall spatial smoothness when simulating the noise distribution.  Based on the Monte Carlo simulations, we used a voxel-wise threshold p < .001 and minimum cluster threshold of 58 voxels. 1As noted in the paper, a Pearson chi-squared test of independence showed that final ratings were closely associated with the high and low experimental conditions for expert rating (χ2 = 166.48, p < 0.001) and community rating (χ2 = 886.66, p < 0.001) in the context phase and code quality (χ2 = 401.52, p < 0.001) in the content phase. A6 MIS Quarterly Vol. 43 No. 3—Appendices/September 2019 Meservy et al./An fMRI Exploration of Information Processing Appendix F fMRI Results Figure F1.  Clusters of Significant Activation in the Contrast of High Final Rating > Low Final Rating Included in the Bilateral Anterior Insula.  R = right As this contrast resulted in large activation differences, all results are presented with voxel-wise p < .0001 and a spatial extent threshold of k > 58 contiguous voxels.   Figure F2.  Clusters of Significant Activation in the Contrast of Content Phase > Context Phase.  R = right MIS Quarterly Vol. 43 No. 3—Appendices/September 2019 A7 Meservy et al./An fMRI Exploration of Information Processing Figure F3.  Clusters of Significant Activation for Congruent (Top) Versus Incongruent (Bottom) Contextual Cues References Cass,  S.    2016.    “The  2016  Top  Programming  Languages,”  IEEE  Spectrum  (http://spectrum.ieee.org/computing/software/the-2016-top- Chaiken, S.  1980.  “Heuristic Versus Systematic Information Processing and the Use of Source Versus Message Cues in Persuasion,” Journal Chaiken, S.  1987.  “The Heuristic Model of Persuasion,” in Social Influence:  The Ontario Symposium, M. P. Zanna, J. M. Olson, and C. P. programming-languages). of Personality and Social Psychology (39:5), pp. 752-766. Herman (eds.), Hillsdale, NJ:  Erlbaum, pp. 3-39. Chaiken, S., and Trope, Y.  1999.  Dual-Process Theories in Social Psychology, New York:  Guilford Press. Cox, R. W., Chen, G., Glen, D. R., Reynolds, R.C., and Taylor, P. A.  2017.  “FMRI Clustering in AFNI:  False-Positive Rates Redux,” Brain Connectivity (7:3), pp. 152-171. Fadel, K. J., Meservy, T. O., and Jensen, M. L.  2015.  “Exploring Knowledge Filtering Processes in Electronic Networks of Practice,” Journal of Management Information Systems (31:4), pp. 158-181. Forman, S. D., Cohen, J. D., Fitzgerald, M., Eddy, W. F., Mintun, M. A., and Noll, D. C.  1995.  “Improved Assessment of Significant Activation in Functional Magnetic Resonance Imaging (FMRI):  Use of a Cluster-Size Threshold,” Magnetic Resonance in Medicine (33:5), pp. 636-647. Huettel, S. A., Song, A. W., and McCarthy, G.  2003.  Functional Magnetic Resonance Imaging., Sunderland, MA:  Sinauer Associates, Inc. Jenkins, J. L., Anderson, B. B., Vance, A., Kirwan, C. B., and Eargle, D.  2016.  “More Harm Than Good?  How Messages That Interrupt Can Make Us Vulnerable,” Information Systems Research (27:4), pp. 880-896. Meservy, T. O., Jensen, M. L., and Fadel, K. J.  2014.  “Evaluation of Competing Candidate Solutions in Electronic Networks of Practice,” Information Systems Research (25:1), pp. 15-34. Petersen, S. E., and Dubis, J. W.  2012.  “The Mixed Block/Event-Related Design,” NeuroImage (62:2), pp. 1177-84. Petty, R. E., and Cacioppo, J. T.  1986.  “The Elaboration Likelihood Model of Persuasion,” Advances in Experimental Social Psychology (19), pp. 123-205. Petty, R. E., Cacioppo, J. T., Strathman, A. J., and Priester, J. R.  2005.  “To Think or Not to Think:  Exploring Two Routes to Persuasion,” in Persuasion:  Psychological Insights and Perspectives, T. C. Brock and M. C. Green (eds.), Thousand Oaks, CA:  SAGE Publications, pp. 81-116. Snijders, T. A. B., and Bosker, R. J.  2012.  Multilevel Analysis:  An Introduction to Basic and Advanced Multilevel Modeling (2nd ed.), Los Angeles:  SAGE Publications. TIOBE.  2016.  “TIOBE Index for October 2016” (http://www.tiobe.com/tiobe-index/). Xiong, J., Gao, J. H., Lancaster, J. L., and Fox, P. T.  1995.  “Clustered Pixels Analysis for Functional MRI Activation Studies of the Human Brain,” Human Brain Mapping (3:4), pp. 287-301. A8 MIS Quarterly Vol. 43 No. 3—Appendices/September 2019 Copyright of MIS Quarterly is the property of MIS Quarterly and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. 